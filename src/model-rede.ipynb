{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'league',\n",
       "       'shotsOngoal_home', 'fouls_home', 'fouls_away', 'tackles_home',\n",
       "       'tackles_away', 'result', 'match_id', 'possessiontime_away',\n",
       "       'possessiontime_home', 'defensive_pressure_home',\n",
       "       'attack_efficiency_home', 'attack_efficiency_away', 'game_control_away',\n",
       "       'attack_intensity_home', 'attack_intensity_away',\n",
       "       'defensive_performance_home', 'defensive_performance_away',\n",
       "       'game_momentum_home', 'total_fouls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.5824 - accuracy: 0.7549 - recall_13: 0.7630 - precision_13: 0.7512 - val_loss: 0.5260 - val_accuracy: 0.7764 - val_recall_13: 0.7879 - val_precision_13: 0.7688\n",
      "Epoch 2/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7736 - recall_13: 0.7702 - precision_13: 0.7758 - val_loss: 0.5013 - val_accuracy: 0.7859 - val_recall_13: 0.7682 - val_precision_13: 0.7950\n",
      "Epoch 3/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.5141 - accuracy: 0.7827 - recall_13: 0.7570 - precision_13: 0.7983 - val_loss: 0.4847 - val_accuracy: 0.7899 - val_recall_13: 0.7587 - val_precision_13: 0.8077\n",
      "Epoch 4/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4994 - accuracy: 0.7863 - recall_13: 0.7468 - precision_13: 0.8112 - val_loss: 0.4710 - val_accuracy: 0.7952 - val_recall_13: 0.7446 - val_precision_13: 0.8270\n",
      "Epoch 5/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4888 - accuracy: 0.7902 - recall_13: 0.7401 - precision_13: 0.8228 - val_loss: 0.4617 - val_accuracy: 0.7981 - val_recall_13: 0.7400 - val_precision_13: 0.8357\n",
      "Epoch 6/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4789 - accuracy: 0.7935 - recall_13: 0.7333 - precision_13: 0.8342 - val_loss: 0.4535 - val_accuracy: 0.8012 - val_recall_13: 0.7350 - val_precision_13: 0.8456\n",
      "Epoch 7/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4695 - accuracy: 0.7960 - recall_13: 0.7276 - precision_13: 0.8433 - val_loss: 0.4465 - val_accuracy: 0.8026 - val_recall_13: 0.7281 - val_precision_13: 0.8541\n",
      "Epoch 8/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4624 - accuracy: 0.7985 - recall_13: 0.7230 - precision_13: 0.8521 - val_loss: 0.4406 - val_accuracy: 0.8048 - val_recall_13: 0.7246 - val_precision_13: 0.8615\n",
      "Epoch 9/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.7993 - recall_13: 0.7168 - precision_13: 0.8589 - val_loss: 0.4351 - val_accuracy: 0.8065 - val_recall_13: 0.7204 - val_precision_13: 0.8685\n",
      "Epoch 10/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.8015 - recall_13: 0.7142 - precision_13: 0.8656 - val_loss: 0.4304 - val_accuracy: 0.8077 - val_recall_13: 0.7162 - val_precision_13: 0.8749\n",
      "Epoch 11/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4452 - accuracy: 0.8033 - recall_13: 0.7102 - precision_13: 0.8732 - val_loss: 0.4262 - val_accuracy: 0.8091 - val_recall_13: 0.7104 - val_precision_13: 0.8835\n",
      "Epoch 12/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4399 - accuracy: 0.8046 - recall_13: 0.7070 - precision_13: 0.8789 - val_loss: 0.4226 - val_accuracy: 0.8095 - val_recall_13: 0.7079 - val_precision_13: 0.8868\n",
      "Epoch 13/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4353 - accuracy: 0.8056 - recall_13: 0.7031 - precision_13: 0.8848 - val_loss: 0.4191 - val_accuracy: 0.8112 - val_recall_13: 0.7049 - val_precision_13: 0.8934\n",
      "Epoch 14/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4325 - accuracy: 0.8071 - recall_13: 0.7009 - precision_13: 0.8904 - val_loss: 0.4165 - val_accuracy: 0.8114 - val_recall_13: 0.7026 - val_precision_13: 0.8962\n",
      "Epoch 15/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4291 - accuracy: 0.8073 - recall_13: 0.6980 - precision_13: 0.8937 - val_loss: 0.4134 - val_accuracy: 0.8124 - val_recall_13: 0.7000 - val_precision_13: 0.9013\n",
      "Epoch 16/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4256 - accuracy: 0.8085 - recall_13: 0.6960 - precision_13: 0.8984 - val_loss: 0.4111 - val_accuracy: 0.8128 - val_recall_13: 0.6982 - val_precision_13: 0.9040\n",
      "Epoch 17/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4229 - accuracy: 0.8087 - recall_13: 0.6941 - precision_13: 0.9010 - val_loss: 0.4086 - val_accuracy: 0.8130 - val_recall_13: 0.6948 - val_precision_13: 0.9081\n",
      "Epoch 18/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.8094 - recall_13: 0.6927 - precision_13: 0.9041 - val_loss: 0.4071 - val_accuracy: 0.8135 - val_recall_13: 0.6944 - val_precision_13: 0.9097\n",
      "Epoch 19/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4188 - accuracy: 0.8096 - recall_13: 0.6906 - precision_13: 0.9067 - val_loss: 0.4051 - val_accuracy: 0.8135 - val_recall_13: 0.6922 - val_precision_13: 0.9121\n",
      "Epoch 20/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4155 - accuracy: 0.8107 - recall_13: 0.6885 - precision_13: 0.9116 - val_loss: 0.4033 - val_accuracy: 0.8140 - val_recall_13: 0.6903 - val_precision_13: 0.9153\n",
      "Epoch 21/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4142 - accuracy: 0.8106 - recall_13: 0.6870 - precision_13: 0.9132 - val_loss: 0.4017 - val_accuracy: 0.8139 - val_recall_13: 0.6889 - val_precision_13: 0.9168\n",
      "Epoch 22/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4122 - accuracy: 0.8117 - recall_13: 0.6870 - precision_13: 0.9156 - val_loss: 0.4003 - val_accuracy: 0.8146 - val_recall_13: 0.6880 - val_precision_13: 0.9194\n",
      "Epoch 23/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4107 - accuracy: 0.8115 - recall_13: 0.6849 - precision_13: 0.9175 - val_loss: 0.3990 - val_accuracy: 0.8147 - val_recall_13: 0.6878 - val_precision_13: 0.9198\n",
      "Epoch 24/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4087 - accuracy: 0.8119 - recall_13: 0.6840 - precision_13: 0.9196 - val_loss: 0.3987 - val_accuracy: 0.8143 - val_recall_13: 0.6894 - val_precision_13: 0.9173\n",
      "Epoch 25/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4079 - accuracy: 0.8122 - recall_13: 0.6844 - precision_13: 0.9198 - val_loss: 0.3966 - val_accuracy: 0.8152 - val_recall_13: 0.6855 - val_precision_13: 0.9238\n",
      "Epoch 26/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8121 - recall_13: 0.6824 - precision_13: 0.9218 - val_loss: 0.3957 - val_accuracy: 0.8153 - val_recall_13: 0.6854 - val_precision_13: 0.9241\n",
      "Epoch 27/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4048 - accuracy: 0.8121 - recall_13: 0.6810 - precision_13: 0.9236 - val_loss: 0.3950 - val_accuracy: 0.8156 - val_recall_13: 0.6861 - val_precision_13: 0.9240\n",
      "Epoch 28/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4047 - accuracy: 0.8127 - recall_13: 0.6808 - precision_13: 0.9253 - val_loss: 0.3944 - val_accuracy: 0.8158 - val_recall_13: 0.6864 - val_precision_13: 0.9242\n",
      "Epoch 29/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4035 - accuracy: 0.8124 - recall_13: 0.6808 - precision_13: 0.9246 - val_loss: 0.3934 - val_accuracy: 0.8156 - val_recall_13: 0.6848 - val_precision_13: 0.9256\n",
      "Epoch 30/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4028 - accuracy: 0.8125 - recall_13: 0.6797 - precision_13: 0.9260 - val_loss: 0.3933 - val_accuracy: 0.8156 - val_recall_13: 0.6864 - val_precision_13: 0.9235\n",
      "Epoch 31/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4019 - accuracy: 0.8129 - recall_13: 0.6793 - precision_13: 0.9273 - val_loss: 0.3920 - val_accuracy: 0.8154 - val_recall_13: 0.6845 - val_precision_13: 0.9254\n",
      "Epoch 32/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4006 - accuracy: 0.8135 - recall_13: 0.6799 - precision_13: 0.9282 - val_loss: 0.3914 - val_accuracy: 0.8158 - val_recall_13: 0.6839 - val_precision_13: 0.9271\n",
      "Epoch 33/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3999 - accuracy: 0.8125 - recall_13: 0.6791 - precision_13: 0.9266 - val_loss: 0.3911 - val_accuracy: 0.8157 - val_recall_13: 0.6844 - val_precision_13: 0.9262\n",
      "Epoch 34/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3987 - accuracy: 0.8134 - recall_13: 0.6793 - precision_13: 0.9286 - val_loss: 0.3901 - val_accuracy: 0.8160 - val_recall_13: 0.6813 - val_precision_13: 0.9305\n",
      "Epoch 35/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3983 - accuracy: 0.8137 - recall_13: 0.6783 - precision_13: 0.9305 - val_loss: 0.3895 - val_accuracy: 0.8160 - val_recall_13: 0.6819 - val_precision_13: 0.9299\n",
      "Epoch 36/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3977 - accuracy: 0.8133 - recall_13: 0.6780 - precision_13: 0.9299 - val_loss: 0.3890 - val_accuracy: 0.8163 - val_recall_13: 0.6818 - val_precision_13: 0.9309\n",
      "Epoch 37/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3971 - accuracy: 0.8133 - recall_13: 0.6774 - precision_13: 0.9307 - val_loss: 0.3885 - val_accuracy: 0.8163 - val_recall_13: 0.6813 - val_precision_13: 0.9315\n",
      "Epoch 38/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3971 - accuracy: 0.8132 - recall_13: 0.6776 - precision_13: 0.9303 - val_loss: 0.3882 - val_accuracy: 0.8161 - val_recall_13: 0.6814 - val_precision_13: 0.9308\n",
      "Epoch 39/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3955 - accuracy: 0.8138 - recall_13: 0.6778 - precision_13: 0.9315 - val_loss: 0.3876 - val_accuracy: 0.8162 - val_recall_13: 0.6794 - val_precision_13: 0.9333\n",
      "Epoch 40/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3958 - accuracy: 0.8136 - recall_13: 0.6775 - precision_13: 0.9314 - val_loss: 0.3874 - val_accuracy: 0.8162 - val_recall_13: 0.6818 - val_precision_13: 0.9305\n",
      "Epoch 41/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3952 - accuracy: 0.8139 - recall_13: 0.6786 - precision_13: 0.9308 - val_loss: 0.3868 - val_accuracy: 0.8165 - val_recall_13: 0.6806 - val_precision_13: 0.9328\n",
      "Epoch 42/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3952 - accuracy: 0.8140 - recall_13: 0.6786 - precision_13: 0.9310 - val_loss: 0.3864 - val_accuracy: 0.8163 - val_recall_13: 0.6789 - val_precision_13: 0.9343\n",
      "Epoch 43/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8138 - recall_13: 0.6781 - precision_13: 0.9311 - val_loss: 0.3860 - val_accuracy: 0.8162 - val_recall_13: 0.6799 - val_precision_13: 0.9327\n",
      "Epoch 44/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8135 - recall_13: 0.6765 - precision_13: 0.9322 - val_loss: 0.3861 - val_accuracy: 0.8165 - val_recall_13: 0.6815 - val_precision_13: 0.9318\n",
      "Epoch 45/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3933 - accuracy: 0.8141 - recall_13: 0.6773 - precision_13: 0.9328 - val_loss: 0.3855 - val_accuracy: 0.8165 - val_recall_13: 0.6797 - val_precision_13: 0.9337\n",
      "Epoch 46/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3931 - accuracy: 0.8140 - recall_13: 0.6765 - precision_13: 0.9336 - val_loss: 0.3856 - val_accuracy: 0.8164 - val_recall_13: 0.6821 - val_precision_13: 0.9306\n",
      "Epoch 47/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8143 - recall_13: 0.6782 - precision_13: 0.9322 - val_loss: 0.3850 - val_accuracy: 0.8164 - val_recall_13: 0.6803 - val_precision_13: 0.9329\n",
      "Epoch 48/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8142 - recall_13: 0.6777 - precision_13: 0.9328 - val_loss: 0.3847 - val_accuracy: 0.8165 - val_recall_13: 0.6802 - val_precision_13: 0.9332\n",
      "Epoch 49/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8146 - recall_13: 0.6782 - precision_13: 0.9330 - val_loss: 0.3844 - val_accuracy: 0.8161 - val_recall_13: 0.6811 - val_precision_13: 0.9311\n",
      "Epoch 50/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3916 - accuracy: 0.8141 - recall_13: 0.6785 - precision_13: 0.9314 - val_loss: 0.3842 - val_accuracy: 0.8162 - val_recall_13: 0.6795 - val_precision_13: 0.9332\n",
      "Epoch 51/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3921 - accuracy: 0.8140 - recall_13: 0.6779 - precision_13: 0.9320 - val_loss: 0.3841 - val_accuracy: 0.8162 - val_recall_13: 0.6798 - val_precision_13: 0.9329\n",
      "Epoch 52/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3915 - accuracy: 0.8142 - recall_13: 0.6782 - precision_13: 0.9320 - val_loss: 0.3837 - val_accuracy: 0.8164 - val_recall_13: 0.6799 - val_precision_13: 0.9334\n",
      "Epoch 53/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8142 - recall_13: 0.6779 - precision_13: 0.9324 - val_loss: 0.3837 - val_accuracy: 0.8164 - val_recall_13: 0.6807 - val_precision_13: 0.9324\n",
      "Epoch 54/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3908 - accuracy: 0.8142 - recall_13: 0.6782 - precision_13: 0.9322 - val_loss: 0.3834 - val_accuracy: 0.8161 - val_recall_13: 0.6811 - val_precision_13: 0.9311\n",
      "Epoch 55/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3899 - accuracy: 0.8146 - recall_13: 0.6789 - precision_13: 0.9323 - val_loss: 0.3831 - val_accuracy: 0.8166 - val_recall_13: 0.6823 - val_precision_13: 0.9311\n",
      "Epoch 56/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3901 - accuracy: 0.8140 - recall_13: 0.6793 - precision_13: 0.9303 - val_loss: 0.3828 - val_accuracy: 0.8161 - val_recall_13: 0.6794 - val_precision_13: 0.9331\n",
      "Epoch 57/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8144 - recall_13: 0.6788 - precision_13: 0.9318 - val_loss: 0.3826 - val_accuracy: 0.8163 - val_recall_13: 0.6798 - val_precision_13: 0.9332\n",
      "Epoch 58/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3890 - accuracy: 0.8145 - recall_13: 0.6794 - precision_13: 0.9315 - val_loss: 0.3824 - val_accuracy: 0.8162 - val_recall_13: 0.6803 - val_precision_13: 0.9323\n",
      "Epoch 59/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8144 - recall_13: 0.6785 - precision_13: 0.9323 - val_loss: 0.3823 - val_accuracy: 0.8163 - val_recall_13: 0.6813 - val_precision_13: 0.9314\n",
      "Epoch 60/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.3889 - accuracy: 0.8151 - recall_13: 0.6804 - precision_13: 0.9318 - val_loss: 0.3821 - val_accuracy: 0.8161 - val_recall_13: 0.6830 - val_precision_13: 0.9289\n",
      "Epoch 61/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8149 - recall_13: 0.6803 - precision_13: 0.9314 - val_loss: 0.3819 - val_accuracy: 0.8163 - val_recall_13: 0.6822 - val_precision_13: 0.9303\n",
      "Epoch 62/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3884 - accuracy: 0.8151 - recall_13: 0.6801 - precision_13: 0.9321 - val_loss: 0.3818 - val_accuracy: 0.8165 - val_recall_13: 0.6807 - val_precision_13: 0.9326\n",
      "Epoch 63/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3885 - accuracy: 0.8147 - recall_13: 0.6796 - precision_13: 0.9318 - val_loss: 0.3815 - val_accuracy: 0.8165 - val_recall_13: 0.6819 - val_precision_13: 0.9311\n",
      "Epoch 64/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3880 - accuracy: 0.8149 - recall_13: 0.6802 - precision_13: 0.9315 - val_loss: 0.3813 - val_accuracy: 0.8168 - val_recall_13: 0.6812 - val_precision_13: 0.9327\n",
      "Epoch 65/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3879 - accuracy: 0.8149 - recall_13: 0.6797 - precision_13: 0.9320 - val_loss: 0.3813 - val_accuracy: 0.8167 - val_recall_13: 0.6850 - val_precision_13: 0.9282\n",
      "Epoch 66/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3874 - accuracy: 0.8155 - recall_13: 0.6815 - precision_13: 0.9314 - val_loss: 0.3809 - val_accuracy: 0.8164 - val_recall_13: 0.6818 - val_precision_13: 0.9310\n",
      "Epoch 67/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3869 - accuracy: 0.8149 - recall_13: 0.6813 - precision_13: 0.9302 - val_loss: 0.3807 - val_accuracy: 0.8166 - val_recall_13: 0.6804 - val_precision_13: 0.9332\n",
      "Epoch 68/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8153 - recall_13: 0.6816 - precision_13: 0.9308 - val_loss: 0.3806 - val_accuracy: 0.8165 - val_recall_13: 0.6811 - val_precision_13: 0.9322\n",
      "Epoch 69/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3868 - accuracy: 0.8155 - recall_13: 0.6816 - precision_13: 0.9314 - val_loss: 0.3807 - val_accuracy: 0.8171 - val_recall_13: 0.6846 - val_precision_13: 0.9294\n",
      "Epoch 70/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3868 - accuracy: 0.8153 - recall_13: 0.6827 - precision_13: 0.9296 - val_loss: 0.3806 - val_accuracy: 0.8165 - val_recall_13: 0.6837 - val_precision_13: 0.9290\n",
      "Epoch 71/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3863 - accuracy: 0.8154 - recall_13: 0.6815 - precision_13: 0.9311 - val_loss: 0.3801 - val_accuracy: 0.8171 - val_recall_13: 0.6827 - val_precision_13: 0.9318\n",
      "Epoch 72/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3860 - accuracy: 0.8155 - recall_13: 0.6824 - precision_13: 0.9305 - val_loss: 0.3803 - val_accuracy: 0.8172 - val_recall_13: 0.6865 - val_precision_13: 0.9277\n",
      "Epoch 73/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3864 - accuracy: 0.8153 - recall_13: 0.6830 - precision_13: 0.9292 - val_loss: 0.3798 - val_accuracy: 0.8174 - val_recall_13: 0.6827 - val_precision_13: 0.9326\n",
      "Epoch 74/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3865 - accuracy: 0.8155 - recall_13: 0.6815 - precision_13: 0.9316 - val_loss: 0.3795 - val_accuracy: 0.8174 - val_recall_13: 0.6804 - val_precision_13: 0.9354\n",
      "Epoch 75/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3860 - accuracy: 0.8155 - recall_13: 0.6832 - precision_13: 0.9294 - val_loss: 0.3795 - val_accuracy: 0.8177 - val_recall_13: 0.6836 - val_precision_13: 0.9322\n",
      "Epoch 76/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8164 - recall_13: 0.6851 - precision_13: 0.9296 - val_loss: 0.3794 - val_accuracy: 0.8173 - val_recall_13: 0.6829 - val_precision_13: 0.9321\n",
      "Epoch 77/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3857 - accuracy: 0.8156 - recall_13: 0.6823 - precision_13: 0.9308 - val_loss: 0.3791 - val_accuracy: 0.8175 - val_recall_13: 0.6820 - val_precision_13: 0.9337\n",
      "Epoch 78/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3855 - accuracy: 0.8163 - recall_13: 0.6838 - precision_13: 0.9309 - val_loss: 0.3795 - val_accuracy: 0.8174 - val_recall_13: 0.6856 - val_precision_13: 0.9292\n",
      "Epoch 79/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3853 - accuracy: 0.8162 - recall_13: 0.6854 - precision_13: 0.9287 - val_loss: 0.3789 - val_accuracy: 0.8174 - val_recall_13: 0.6798 - val_precision_13: 0.9360\n",
      "Epoch 80/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3852 - accuracy: 0.8161 - recall_13: 0.6839 - precision_13: 0.9302 - val_loss: 0.3787 - val_accuracy: 0.8177 - val_recall_13: 0.6837 - val_precision_13: 0.9322\n",
      "Epoch 81/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3848 - accuracy: 0.8163 - recall_13: 0.6839 - precision_13: 0.9306 - val_loss: 0.3786 - val_accuracy: 0.8178 - val_recall_13: 0.6839 - val_precision_13: 0.9321\n",
      "Epoch 82/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3852 - accuracy: 0.8159 - recall_13: 0.6840 - precision_13: 0.9295 - val_loss: 0.3787 - val_accuracy: 0.8176 - val_recall_13: 0.6848 - val_precision_13: 0.9306\n",
      "Epoch 83/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3844 - accuracy: 0.8161 - recall_13: 0.6845 - precision_13: 0.9294 - val_loss: 0.3784 - val_accuracy: 0.8175 - val_recall_13: 0.6810 - val_precision_13: 0.9348\n",
      "Epoch 84/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3843 - accuracy: 0.8166 - recall_13: 0.6843 - precision_13: 0.9309 - val_loss: 0.3784 - val_accuracy: 0.8179 - val_recall_13: 0.6870 - val_precision_13: 0.9289\n",
      "Epoch 85/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3843 - accuracy: 0.8170 - recall_13: 0.6861 - precision_13: 0.9299 - val_loss: 0.3782 - val_accuracy: 0.8178 - val_recall_13: 0.6874 - val_precision_13: 0.9282\n",
      "Epoch 86/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3845 - accuracy: 0.8162 - recall_13: 0.6867 - precision_13: 0.9273 - val_loss: 0.3782 - val_accuracy: 0.8173 - val_recall_13: 0.6868 - val_precision_13: 0.9276\n",
      "Epoch 87/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3842 - accuracy: 0.8166 - recall_13: 0.6864 - precision_13: 0.9286 - val_loss: 0.3779 - val_accuracy: 0.8177 - val_recall_13: 0.6860 - val_precision_13: 0.9293\n",
      "Epoch 88/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8162 - recall_13: 0.6863 - precision_13: 0.9277 - val_loss: 0.3780 - val_accuracy: 0.8172 - val_recall_13: 0.6894 - val_precision_13: 0.9243\n",
      "Epoch 89/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.8170 - recall_13: 0.6885 - precision_13: 0.9271 - val_loss: 0.3777 - val_accuracy: 0.8180 - val_recall_13: 0.6871 - val_precision_13: 0.9288\n",
      "Epoch 90/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3835 - accuracy: 0.8175 - recall_13: 0.6879 - precision_13: 0.9290 - val_loss: 0.3777 - val_accuracy: 0.8181 - val_recall_13: 0.6858 - val_precision_13: 0.9306\n",
      "Epoch 91/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3833 - accuracy: 0.8165 - recall_13: 0.6870 - precision_13: 0.9277 - val_loss: 0.3774 - val_accuracy: 0.8187 - val_recall_13: 0.6847 - val_precision_13: 0.9334\n",
      "Epoch 92/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8168 - recall_13: 0.6875 - precision_13: 0.9279 - val_loss: 0.3774 - val_accuracy: 0.8182 - val_recall_13: 0.6884 - val_precision_13: 0.9279\n",
      "Epoch 93/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8173 - recall_13: 0.6885 - precision_13: 0.9278 - val_loss: 0.3773 - val_accuracy: 0.8184 - val_recall_13: 0.6860 - val_precision_13: 0.9312\n",
      "Epoch 94/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8176 - recall_13: 0.6889 - precision_13: 0.9280 - val_loss: 0.3771 - val_accuracy: 0.8187 - val_recall_13: 0.6867 - val_precision_13: 0.9313\n",
      "Epoch 95/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8168 - recall_13: 0.6884 - precision_13: 0.9266 - val_loss: 0.3769 - val_accuracy: 0.8187 - val_recall_13: 0.6846 - val_precision_13: 0.9336\n",
      "Epoch 96/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3824 - accuracy: 0.8173 - recall_13: 0.6886 - precision_13: 0.9277 - val_loss: 0.3767 - val_accuracy: 0.8187 - val_recall_13: 0.6834 - val_precision_13: 0.9349\n",
      "Epoch 97/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3822 - accuracy: 0.8177 - recall_13: 0.6886 - precision_13: 0.9287 - val_loss: 0.3766 - val_accuracy: 0.8189 - val_recall_13: 0.6871 - val_precision_13: 0.9312\n",
      "Epoch 98/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8173 - recall_13: 0.6893 - precision_13: 0.9270 - val_loss: 0.3764 - val_accuracy: 0.8188 - val_recall_13: 0.6868 - val_precision_13: 0.9314\n",
      "Epoch 99/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8164 - recall_13: 0.6876 - precision_13: 0.9267 - val_loss: 0.3762 - val_accuracy: 0.8188 - val_recall_13: 0.6856 - val_precision_13: 0.9328\n",
      "Epoch 100/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3821 - accuracy: 0.8174 - recall_13: 0.6892 - precision_13: 0.9271 - val_loss: 0.3765 - val_accuracy: 0.8184 - val_recall_13: 0.6854 - val_precision_13: 0.9320\n",
      "Epoch 101/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3814 - accuracy: 0.8172 - recall_13: 0.6891 - precision_13: 0.9270 - val_loss: 0.3762 - val_accuracy: 0.8186 - val_recall_13: 0.6840 - val_precision_13: 0.9341\n",
      "Epoch 102/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3818 - accuracy: 0.8176 - recall_13: 0.6884 - precision_13: 0.9288 - val_loss: 0.3763 - val_accuracy: 0.8189 - val_recall_13: 0.6883 - val_precision_13: 0.9297\n",
      "Epoch 103/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3814 - accuracy: 0.8175 - recall_13: 0.6901 - precision_13: 0.9266 - val_loss: 0.3759 - val_accuracy: 0.8197 - val_recall_13: 0.6883 - val_precision_13: 0.9317\n",
      "Epoch 104/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3817 - accuracy: 0.8173 - recall_13: 0.6892 - precision_13: 0.9270 - val_loss: 0.3758 - val_accuracy: 0.8198 - val_recall_13: 0.6877 - val_precision_13: 0.9328\n",
      "Epoch 105/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3812 - accuracy: 0.8171 - recall_13: 0.6890 - precision_13: 0.9268 - val_loss: 0.3756 - val_accuracy: 0.8189 - val_recall_13: 0.6871 - val_precision_13: 0.9312\n",
      "Epoch 106/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8185 - recall_13: 0.6914 - precision_13: 0.9274 - val_loss: 0.3760 - val_accuracy: 0.8186 - val_recall_13: 0.6873 - val_precision_13: 0.9301\n",
      "Epoch 107/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3813 - accuracy: 0.8177 - recall_13: 0.6907 - precision_13: 0.9265 - val_loss: 0.3756 - val_accuracy: 0.8196 - val_recall_13: 0.6899 - val_precision_13: 0.9296\n",
      "Epoch 108/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3811 - accuracy: 0.8172 - recall_13: 0.6902 - precision_13: 0.9255 - val_loss: 0.3754 - val_accuracy: 0.8188 - val_recall_13: 0.6842 - val_precision_13: 0.9343\n",
      "Epoch 109/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3812 - accuracy: 0.8180 - recall_13: 0.6909 - precision_13: 0.9268 - val_loss: 0.3756 - val_accuracy: 0.8189 - val_recall_13: 0.6866 - val_precision_13: 0.9317\n",
      "Epoch 110/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3812 - accuracy: 0.8179 - recall_13: 0.6910 - precision_13: 0.9263 - val_loss: 0.3754 - val_accuracy: 0.8190 - val_recall_13: 0.6890 - val_precision_13: 0.9294\n",
      "Epoch 111/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3801 - accuracy: 0.8182 - recall_13: 0.6922 - precision_13: 0.9258 - val_loss: 0.3754 - val_accuracy: 0.8191 - val_recall_13: 0.6886 - val_precision_13: 0.9299\n",
      "Epoch 112/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3805 - accuracy: 0.8182 - recall_13: 0.6933 - precision_13: 0.9245 - val_loss: 0.3754 - val_accuracy: 0.8195 - val_recall_13: 0.6937 - val_precision_13: 0.9251\n",
      "Epoch 113/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8184 - recall_13: 0.6931 - precision_13: 0.9252 - val_loss: 0.3750 - val_accuracy: 0.8191 - val_recall_13: 0.6877 - val_precision_13: 0.9309\n",
      "Epoch 114/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3805 - accuracy: 0.8180 - recall_13: 0.6920 - precision_13: 0.9256 - val_loss: 0.3751 - val_accuracy: 0.8194 - val_recall_13: 0.6901 - val_precision_13: 0.9290\n",
      "Epoch 115/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3799 - accuracy: 0.8184 - recall_13: 0.6936 - precision_13: 0.9249 - val_loss: 0.3749 - val_accuracy: 0.8196 - val_recall_13: 0.6925 - val_precision_13: 0.9266\n",
      "Epoch 116/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3796 - accuracy: 0.8188 - recall_13: 0.6942 - precision_13: 0.9250 - val_loss: 0.3748 - val_accuracy: 0.8193 - val_recall_13: 0.6941 - val_precision_13: 0.9243\n",
      "Epoch 117/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8188 - recall_13: 0.6947 - precision_13: 0.9244 - val_loss: 0.3750 - val_accuracy: 0.8195 - val_recall_13: 0.6935 - val_precision_13: 0.9254\n",
      "Epoch 118/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3797 - accuracy: 0.8185 - recall_13: 0.6947 - precision_13: 0.9238 - val_loss: 0.3747 - val_accuracy: 0.8190 - val_recall_13: 0.6899 - val_precision_13: 0.9283\n",
      "Epoch 119/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3798 - accuracy: 0.8190 - recall_13: 0.6949 - precision_13: 0.9247 - val_loss: 0.3746 - val_accuracy: 0.8193 - val_recall_13: 0.6922 - val_precision_13: 0.9263\n",
      "Epoch 120/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3800 - accuracy: 0.8187 - recall_13: 0.6940 - precision_13: 0.9251 - val_loss: 0.3745 - val_accuracy: 0.8196 - val_recall_13: 0.6922 - val_precision_13: 0.9270\n",
      "Epoch 121/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3794 - accuracy: 0.8186 - recall_13: 0.6949 - precision_13: 0.9237 - val_loss: 0.3743 - val_accuracy: 0.8191 - val_recall_13: 0.6896 - val_precision_13: 0.9289\n",
      "Epoch 122/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3790 - accuracy: 0.8196 - recall_13: 0.6961 - precision_13: 0.9247 - val_loss: 0.3742 - val_accuracy: 0.8195 - val_recall_13: 0.6869 - val_precision_13: 0.9329\n",
      "Epoch 123/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3793 - accuracy: 0.8190 - recall_13: 0.6951 - precision_13: 0.9245 - val_loss: 0.3743 - val_accuracy: 0.8196 - val_recall_13: 0.6866 - val_precision_13: 0.9336\n",
      "Epoch 124/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3790 - accuracy: 0.8191 - recall_13: 0.6949 - precision_13: 0.9250 - val_loss: 0.3742 - val_accuracy: 0.8201 - val_recall_13: 0.6959 - val_precision_13: 0.9241\n",
      "Epoch 125/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3784 - accuracy: 0.8191 - recall_13: 0.6966 - precision_13: 0.9230 - val_loss: 0.3738 - val_accuracy: 0.8200 - val_recall_13: 0.6922 - val_precision_13: 0.9281\n",
      "Epoch 126/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3791 - accuracy: 0.8194 - recall_13: 0.6964 - precision_13: 0.9242 - val_loss: 0.3738 - val_accuracy: 0.8198 - val_recall_13: 0.6905 - val_precision_13: 0.9294\n",
      "Epoch 127/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3790 - accuracy: 0.8189 - recall_13: 0.6961 - precision_13: 0.9231 - val_loss: 0.3735 - val_accuracy: 0.8196 - val_recall_13: 0.6857 - val_precision_13: 0.9347\n",
      "Epoch 128/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3787 - accuracy: 0.8187 - recall_13: 0.6956 - precision_13: 0.9232 - val_loss: 0.3735 - val_accuracy: 0.8197 - val_recall_13: 0.6875 - val_precision_13: 0.9328\n",
      "Epoch 129/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3787 - accuracy: 0.8190 - recall_13: 0.6963 - precision_13: 0.9231 - val_loss: 0.3738 - val_accuracy: 0.8200 - val_recall_13: 0.6950 - val_precision_13: 0.9249\n",
      "Epoch 130/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3789 - accuracy: 0.8192 - recall_13: 0.6968 - precision_13: 0.9232 - val_loss: 0.3735 - val_accuracy: 0.8208 - val_recall_13: 0.6938 - val_precision_13: 0.9284\n",
      "Epoch 131/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3783 - accuracy: 0.8192 - recall_13: 0.6965 - precision_13: 0.9234 - val_loss: 0.3735 - val_accuracy: 0.8199 - val_recall_13: 0.6925 - val_precision_13: 0.9275\n",
      "Epoch 132/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3780 - accuracy: 0.8190 - recall_13: 0.6947 - precision_13: 0.9249 - val_loss: 0.3736 - val_accuracy: 0.8199 - val_recall_13: 0.6995 - val_precision_13: 0.9196\n",
      "Epoch 133/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3779 - accuracy: 0.8197 - recall_13: 0.6979 - precision_13: 0.9232 - val_loss: 0.3733 - val_accuracy: 0.8205 - val_recall_13: 0.6912 - val_precision_13: 0.9305\n",
      "Epoch 134/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3786 - accuracy: 0.8195 - recall_13: 0.6977 - precision_13: 0.9229 - val_loss: 0.3733 - val_accuracy: 0.8212 - val_recall_13: 0.6950 - val_precision_13: 0.9277\n",
      "Epoch 135/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3778 - accuracy: 0.8203 - recall_13: 0.6989 - precision_13: 0.9234 - val_loss: 0.3732 - val_accuracy: 0.8211 - val_recall_13: 0.6957 - val_precision_13: 0.9267\n",
      "Epoch 136/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3783 - accuracy: 0.8199 - recall_13: 0.6986 - precision_13: 0.9227 - val_loss: 0.3733 - val_accuracy: 0.8194 - val_recall_13: 0.6896 - val_precision_13: 0.9297\n",
      "Epoch 137/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3770 - accuracy: 0.8201 - recall_13: 0.6981 - precision_13: 0.9238 - val_loss: 0.3728 - val_accuracy: 0.8211 - val_recall_13: 0.6935 - val_precision_13: 0.9293\n",
      "Epoch 138/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8204 - recall_13: 0.6998 - precision_13: 0.9227 - val_loss: 0.3732 - val_accuracy: 0.8214 - val_recall_13: 0.6986 - val_precision_13: 0.9241\n",
      "Epoch 139/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8211 - recall_13: 0.7022 - precision_13: 0.9217 - val_loss: 0.3730 - val_accuracy: 0.8209 - val_recall_13: 0.6969 - val_precision_13: 0.9250\n",
      "Epoch 140/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8198 - recall_13: 0.6993 - precision_13: 0.9217 - val_loss: 0.3727 - val_accuracy: 0.8213 - val_recall_13: 0.6974 - val_precision_13: 0.9253\n",
      "Epoch 141/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8200 - recall_13: 0.7003 - precision_13: 0.9210 - val_loss: 0.3732 - val_accuracy: 0.8207 - val_recall_13: 0.6898 - val_precision_13: 0.9325\n",
      "Epoch 142/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3778 - accuracy: 0.8197 - recall_13: 0.6989 - precision_13: 0.9218 - val_loss: 0.3727 - val_accuracy: 0.8206 - val_recall_13: 0.6928 - val_precision_13: 0.9289\n",
      "Epoch 143/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3770 - accuracy: 0.8199 - recall_13: 0.6990 - precision_13: 0.9225 - val_loss: 0.3725 - val_accuracy: 0.8221 - val_recall_13: 0.7005 - val_precision_13: 0.9240\n",
      "Epoch 144/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3771 - accuracy: 0.8203 - recall_13: 0.7004 - precision_13: 0.9218 - val_loss: 0.3725 - val_accuracy: 0.8208 - val_recall_13: 0.6913 - val_precision_13: 0.9310\n",
      "Epoch 145/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8203 - recall_13: 0.7023 - precision_13: 0.9197 - val_loss: 0.3724 - val_accuracy: 0.8202 - val_recall_13: 0.6900 - val_precision_13: 0.9312\n",
      "Epoch 146/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3772 - accuracy: 0.8194 - recall_13: 0.6983 - precision_13: 0.9220 - val_loss: 0.3722 - val_accuracy: 0.8218 - val_recall_13: 0.6980 - val_precision_13: 0.9260\n",
      "Epoch 147/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3767 - accuracy: 0.8200 - recall_13: 0.7003 - precision_13: 0.9212 - val_loss: 0.3724 - val_accuracy: 0.8217 - val_recall_13: 0.6993 - val_precision_13: 0.9241\n",
      "Epoch 148/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3769 - accuracy: 0.8200 - recall_13: 0.7014 - precision_13: 0.9198 - val_loss: 0.3718 - val_accuracy: 0.8214 - val_recall_13: 0.6940 - val_precision_13: 0.9294\n",
      "Epoch 149/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3758 - accuracy: 0.8208 - recall_13: 0.7021 - precision_13: 0.9210 - val_loss: 0.3718 - val_accuracy: 0.8214 - val_recall_13: 0.6947 - val_precision_13: 0.9288\n",
      "Epoch 150/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3771 - accuracy: 0.8210 - recall_13: 0.7042 - precision_13: 0.9193 - val_loss: 0.3719 - val_accuracy: 0.8214 - val_recall_13: 0.6963 - val_precision_13: 0.9268\n",
      "Epoch 151/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3765 - accuracy: 0.8210 - recall_13: 0.7033 - precision_13: 0.9202 - val_loss: 0.3718 - val_accuracy: 0.8215 - val_recall_13: 0.6973 - val_precision_13: 0.9259\n",
      "Epoch 152/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3764 - accuracy: 0.8206 - recall_13: 0.7017 - precision_13: 0.9211 - val_loss: 0.3721 - val_accuracy: 0.8218 - val_recall_13: 0.6998 - val_precision_13: 0.9240\n",
      "Epoch 153/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3772 - accuracy: 0.8203 - recall_13: 0.7027 - precision_13: 0.9193 - val_loss: 0.3714 - val_accuracy: 0.8217 - val_recall_13: 0.6929 - val_precision_13: 0.9315\n",
      "Epoch 154/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3766 - accuracy: 0.8201 - recall_13: 0.7006 - precision_13: 0.9210 - val_loss: 0.3716 - val_accuracy: 0.8215 - val_recall_13: 0.6971 - val_precision_13: 0.9262\n",
      "Epoch 155/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3767 - accuracy: 0.8212 - recall_13: 0.7019 - precision_13: 0.9222 - val_loss: 0.3713 - val_accuracy: 0.8217 - val_recall_13: 0.6958 - val_precision_13: 0.9281\n",
      "Epoch 156/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3755 - accuracy: 0.8208 - recall_13: 0.7041 - precision_13: 0.9188 - val_loss: 0.3715 - val_accuracy: 0.8217 - val_recall_13: 0.6916 - val_precision_13: 0.9329\n",
      "Epoch 157/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3763 - accuracy: 0.8206 - recall_13: 0.7012 - precision_13: 0.9215 - val_loss: 0.3716 - val_accuracy: 0.8211 - val_recall_13: 0.6982 - val_precision_13: 0.9240\n",
      "Epoch 158/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3766 - accuracy: 0.8206 - recall_13: 0.7023 - precision_13: 0.9204 - val_loss: 0.3713 - val_accuracy: 0.8217 - val_recall_13: 0.6902 - val_precision_13: 0.9346\n",
      "Epoch 159/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3758 - accuracy: 0.8214 - recall_13: 0.7034 - precision_13: 0.9212 - val_loss: 0.3715 - val_accuracy: 0.8218 - val_recall_13: 0.6978 - val_precision_13: 0.9261\n",
      "Epoch 160/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3755 - accuracy: 0.8215 - recall_13: 0.7039 - precision_13: 0.9207 - val_loss: 0.3716 - val_accuracy: 0.8218 - val_recall_13: 0.6990 - val_precision_13: 0.9249\n",
      "Epoch 161/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3753 - accuracy: 0.8208 - recall_13: 0.7027 - precision_13: 0.9204 - val_loss: 0.3713 - val_accuracy: 0.8213 - val_recall_13: 0.6930 - val_precision_13: 0.9303\n",
      "Epoch 162/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3752 - accuracy: 0.8218 - recall_13: 0.7043 - precision_13: 0.9210 - val_loss: 0.3709 - val_accuracy: 0.8217 - val_recall_13: 0.6934 - val_precision_13: 0.9310\n",
      "Epoch 163/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3759 - accuracy: 0.8210 - recall_13: 0.7028 - precision_13: 0.9208 - val_loss: 0.3711 - val_accuracy: 0.8213 - val_recall_13: 0.6955 - val_precision_13: 0.9275\n",
      "Epoch 164/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3755 - accuracy: 0.8207 - recall_13: 0.7040 - precision_13: 0.9187 - val_loss: 0.3711 - val_accuracy: 0.8214 - val_recall_13: 0.6967 - val_precision_13: 0.9264\n",
      "Epoch 165/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3752 - accuracy: 0.8219 - recall_13: 0.7038 - precision_13: 0.9220 - val_loss: 0.3711 - val_accuracy: 0.8231 - val_recall_13: 0.7021 - val_precision_13: 0.9245\n",
      "Epoch 166/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3750 - accuracy: 0.8218 - recall_13: 0.7044 - precision_13: 0.9211 - val_loss: 0.3707 - val_accuracy: 0.8224 - val_recall_13: 0.6984 - val_precision_13: 0.9269\n",
      "Epoch 167/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3756 - accuracy: 0.8215 - recall_13: 0.7045 - precision_13: 0.9203 - val_loss: 0.3707 - val_accuracy: 0.8217 - val_recall_13: 0.6931 - val_precision_13: 0.9312\n",
      "Epoch 168/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3753 - accuracy: 0.8218 - recall_13: 0.7053 - precision_13: 0.9200 - val_loss: 0.3706 - val_accuracy: 0.8226 - val_recall_13: 0.6967 - val_precision_13: 0.9294\n",
      "Epoch 169/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3747 - accuracy: 0.8217 - recall_13: 0.7058 - precision_13: 0.9191 - val_loss: 0.3704 - val_accuracy: 0.8217 - val_recall_13: 0.6941 - val_precision_13: 0.9302\n",
      "Epoch 170/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3751 - accuracy: 0.8221 - recall_13: 0.7075 - precision_13: 0.9182 - val_loss: 0.3702 - val_accuracy: 0.8219 - val_recall_13: 0.6950 - val_precision_13: 0.9297\n",
      "Epoch 171/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3747 - accuracy: 0.8216 - recall_13: 0.7069 - precision_13: 0.9177 - val_loss: 0.3702 - val_accuracy: 0.8224 - val_recall_13: 0.6970 - val_precision_13: 0.9284\n",
      "Epoch 172/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3746 - accuracy: 0.8220 - recall_13: 0.7067 - precision_13: 0.9189 - val_loss: 0.3705 - val_accuracy: 0.8215 - val_recall_13: 0.6954 - val_precision_13: 0.9280\n",
      "Epoch 173/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3751 - accuracy: 0.8220 - recall_13: 0.7060 - precision_13: 0.9198 - val_loss: 0.3703 - val_accuracy: 0.8228 - val_recall_13: 0.6981 - val_precision_13: 0.9282\n",
      "Epoch 174/500\n",
      "1451/1451 [==============================] - 4s 2ms/step - loss: 0.3740 - accuracy: 0.8218 - recall_13: 0.7068 - precision_13: 0.9183 - val_loss: 0.3699 - val_accuracy: 0.8226 - val_recall_13: 0.6948 - val_precision_13: 0.9315\n",
      "Epoch 175/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3739 - accuracy: 0.8218 - recall_13: 0.7085 - precision_13: 0.9164 - val_loss: 0.3700 - val_accuracy: 0.8221 - val_recall_13: 0.6923 - val_precision_13: 0.9333\n",
      "Epoch 176/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.3746 - accuracy: 0.8215 - recall_13: 0.7065 - precision_13: 0.9179 - val_loss: 0.3701 - val_accuracy: 0.8237 - val_recall_13: 0.6994 - val_precision_13: 0.9290\n",
      "Epoch 177/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3741 - accuracy: 0.8219 - recall_13: 0.7058 - precision_13: 0.9198 - val_loss: 0.3698 - val_accuracy: 0.8232 - val_recall_13: 0.7031 - val_precision_13: 0.9237\n",
      "Epoch 178/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3740 - accuracy: 0.8226 - recall_13: 0.7089 - precision_13: 0.9179 - val_loss: 0.3694 - val_accuracy: 0.8233 - val_recall_13: 0.6977 - val_precision_13: 0.9299\n",
      "Epoch 179/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3741 - accuracy: 0.8220 - recall_13: 0.7072 - precision_13: 0.9184 - val_loss: 0.3693 - val_accuracy: 0.8229 - val_recall_13: 0.6938 - val_precision_13: 0.9334\n",
      "Epoch 180/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8241 - recall_13: 0.7115 - precision_13: 0.9188 - val_loss: 0.3694 - val_accuracy: 0.8233 - val_recall_13: 0.6977 - val_precision_13: 0.9301\n",
      "Epoch 181/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8223 - recall_13: 0.7086 - precision_13: 0.9176 - val_loss: 0.3692 - val_accuracy: 0.8236 - val_recall_13: 0.7012 - val_precision_13: 0.9269\n",
      "Epoch 182/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8225 - recall_13: 0.7102 - precision_13: 0.9162 - val_loss: 0.3693 - val_accuracy: 0.8231 - val_recall_13: 0.6980 - val_precision_13: 0.9292\n",
      "Epoch 183/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3736 - accuracy: 0.8228 - recall_13: 0.7107 - precision_13: 0.9166 - val_loss: 0.3692 - val_accuracy: 0.8233 - val_recall_13: 0.6967 - val_precision_13: 0.9312\n",
      "Epoch 184/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3739 - accuracy: 0.8221 - recall_13: 0.7080 - precision_13: 0.9179 - val_loss: 0.3691 - val_accuracy: 0.8236 - val_recall_13: 0.6986 - val_precision_13: 0.9298\n",
      "Epoch 185/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8226 - recall_13: 0.7092 - precision_13: 0.9177 - val_loss: 0.3689 - val_accuracy: 0.8233 - val_recall_13: 0.6986 - val_precision_13: 0.9290\n",
      "Epoch 186/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3733 - accuracy: 0.8220 - recall_13: 0.7093 - precision_13: 0.9161 - val_loss: 0.3691 - val_accuracy: 0.8243 - val_recall_13: 0.7013 - val_precision_13: 0.9284\n",
      "Epoch 187/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3742 - accuracy: 0.8228 - recall_13: 0.7090 - precision_13: 0.9183 - val_loss: 0.3693 - val_accuracy: 0.8247 - val_recall_13: 0.7109 - val_precision_13: 0.9186\n",
      "Epoch 188/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3729 - accuracy: 0.8231 - recall_13: 0.7112 - precision_13: 0.9168 - val_loss: 0.3687 - val_accuracy: 0.8234 - val_recall_13: 0.6986 - val_precision_13: 0.9293\n",
      "Epoch 189/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8236 - recall_13: 0.7108 - precision_13: 0.9182 - val_loss: 0.3687 - val_accuracy: 0.8227 - val_recall_13: 0.6957 - val_precision_13: 0.9307\n",
      "Epoch 190/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3734 - accuracy: 0.8226 - recall_13: 0.7090 - precision_13: 0.9179 - val_loss: 0.3688 - val_accuracy: 0.8222 - val_recall_13: 0.6961 - val_precision_13: 0.9291\n",
      "Epoch 191/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3737 - accuracy: 0.8228 - recall_13: 0.7115 - precision_13: 0.9156 - val_loss: 0.3685 - val_accuracy: 0.8239 - val_recall_13: 0.6986 - val_precision_13: 0.9305\n",
      "Epoch 192/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8232 - recall_13: 0.7100 - precision_13: 0.9182 - val_loss: 0.3682 - val_accuracy: 0.8253 - val_recall_13: 0.7067 - val_precision_13: 0.9248\n",
      "Epoch 193/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3733 - accuracy: 0.8227 - recall_13: 0.7113 - precision_13: 0.9156 - val_loss: 0.3685 - val_accuracy: 0.8228 - val_recall_13: 0.6969 - val_precision_13: 0.9297\n",
      "Epoch 194/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3731 - accuracy: 0.8238 - recall_13: 0.7118 - precision_13: 0.9176 - val_loss: 0.3684 - val_accuracy: 0.8238 - val_recall_13: 0.7012 - val_precision_13: 0.9273\n",
      "Epoch 195/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8228 - recall_13: 0.7115 - precision_13: 0.9157 - val_loss: 0.3684 - val_accuracy: 0.8239 - val_recall_13: 0.7029 - val_precision_13: 0.9256\n",
      "Epoch 196/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3725 - accuracy: 0.8234 - recall_13: 0.7124 - precision_13: 0.9161 - val_loss: 0.3682 - val_accuracy: 0.8228 - val_recall_13: 0.6962 - val_precision_13: 0.9304\n",
      "Epoch 197/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8234 - recall_13: 0.7114 - precision_13: 0.9172 - val_loss: 0.3682 - val_accuracy: 0.8250 - val_recall_13: 0.7050 - val_precision_13: 0.9260\n",
      "Epoch 198/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8238 - recall_13: 0.7134 - precision_13: 0.9160 - val_loss: 0.3681 - val_accuracy: 0.8244 - val_recall_13: 0.7029 - val_precision_13: 0.9268\n",
      "Epoch 199/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3730 - accuracy: 0.8236 - recall_13: 0.7120 - precision_13: 0.9171 - val_loss: 0.3684 - val_accuracy: 0.8250 - val_recall_13: 0.7111 - val_precision_13: 0.9192\n",
      "Epoch 200/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3728 - accuracy: 0.8225 - recall_13: 0.7114 - precision_13: 0.9152 - val_loss: 0.3678 - val_accuracy: 0.8238 - val_recall_13: 0.7040 - val_precision_13: 0.9242\n",
      "Epoch 201/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3719 - accuracy: 0.8239 - recall_13: 0.7134 - precision_13: 0.9163 - val_loss: 0.3682 - val_accuracy: 0.8261 - val_recall_13: 0.7172 - val_precision_13: 0.9152\n",
      "Epoch 202/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3715 - accuracy: 0.8238 - recall_13: 0.7146 - precision_13: 0.9146 - val_loss: 0.3682 - val_accuracy: 0.8244 - val_recall_13: 0.7072 - val_precision_13: 0.9220\n",
      "Epoch 203/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8229 - recall_13: 0.7112 - precision_13: 0.9163 - val_loss: 0.3680 - val_accuracy: 0.8239 - val_recall_13: 0.7021 - val_precision_13: 0.9265\n",
      "Epoch 204/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3720 - accuracy: 0.8236 - recall_13: 0.7131 - precision_13: 0.9158 - val_loss: 0.3682 - val_accuracy: 0.8227 - val_recall_13: 0.6936 - val_precision_13: 0.9332\n",
      "Epoch 205/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8235 - recall_13: 0.7128 - precision_13: 0.9159 - val_loss: 0.3677 - val_accuracy: 0.8240 - val_recall_13: 0.7031 - val_precision_13: 0.9254\n",
      "Epoch 206/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8233 - recall_13: 0.7140 - precision_13: 0.9141 - val_loss: 0.3677 - val_accuracy: 0.8236 - val_recall_13: 0.7031 - val_precision_13: 0.9247\n",
      "Epoch 207/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8231 - recall_13: 0.7121 - precision_13: 0.9157 - val_loss: 0.3678 - val_accuracy: 0.8252 - val_recall_13: 0.7140 - val_precision_13: 0.9166\n",
      "Epoch 208/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3717 - accuracy: 0.8241 - recall_13: 0.7148 - precision_13: 0.9153 - val_loss: 0.3676 - val_accuracy: 0.8249 - val_recall_13: 0.7071 - val_precision_13: 0.9233\n",
      "Epoch 209/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3718 - accuracy: 0.8248 - recall_13: 0.7172 - precision_13: 0.9143 - val_loss: 0.3673 - val_accuracy: 0.8247 - val_recall_13: 0.7022 - val_precision_13: 0.9284\n",
      "Epoch 210/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3721 - accuracy: 0.8244 - recall_13: 0.7144 - precision_13: 0.9163 - val_loss: 0.3672 - val_accuracy: 0.8244 - val_recall_13: 0.7043 - val_precision_13: 0.9252\n",
      "Epoch 211/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.8238 - recall_13: 0.7146 - precision_13: 0.9147 - val_loss: 0.3671 - val_accuracy: 0.8244 - val_recall_13: 0.7031 - val_precision_13: 0.9266\n",
      "Epoch 212/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3719 - accuracy: 0.8228 - recall_13: 0.7120 - precision_13: 0.9152 - val_loss: 0.3673 - val_accuracy: 0.8249 - val_recall_13: 0.7064 - val_precision_13: 0.9240\n",
      "Epoch 213/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.8240 - recall_13: 0.7159 - precision_13: 0.9139 - val_loss: 0.3671 - val_accuracy: 0.8246 - val_recall_13: 0.7068 - val_precision_13: 0.9229\n",
      "Epoch 214/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8245 - recall_13: 0.7152 - precision_13: 0.9158 - val_loss: 0.3672 - val_accuracy: 0.8249 - val_recall_13: 0.7054 - val_precision_13: 0.9251\n",
      "Epoch 215/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3715 - accuracy: 0.8243 - recall_13: 0.7159 - precision_13: 0.9145 - val_loss: 0.3670 - val_accuracy: 0.8247 - val_recall_13: 0.7037 - val_precision_13: 0.9266\n",
      "Epoch 216/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.8235 - recall_13: 0.7140 - precision_13: 0.9147 - val_loss: 0.3669 - val_accuracy: 0.8251 - val_recall_13: 0.7089 - val_precision_13: 0.9217\n",
      "Epoch 217/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3711 - accuracy: 0.8243 - recall_13: 0.7150 - precision_13: 0.9155 - val_loss: 0.3669 - val_accuracy: 0.8260 - val_recall_13: 0.7106 - val_precision_13: 0.9221\n",
      "Epoch 218/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3714 - accuracy: 0.8247 - recall_13: 0.7149 - precision_13: 0.9164 - val_loss: 0.3671 - val_accuracy: 0.8258 - val_recall_13: 0.7154 - val_precision_13: 0.9165\n",
      "Epoch 219/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8254 - recall_13: 0.7172 - precision_13: 0.9156 - val_loss: 0.3668 - val_accuracy: 0.8250 - val_recall_13: 0.7101 - val_precision_13: 0.9204\n",
      "Epoch 220/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.8251 - recall_13: 0.7184 - precision_13: 0.9138 - val_loss: 0.3667 - val_accuracy: 0.8249 - val_recall_13: 0.7018 - val_precision_13: 0.9292\n",
      "Epoch 221/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8241 - recall_13: 0.7158 - precision_13: 0.9140 - val_loss: 0.3667 - val_accuracy: 0.8243 - val_recall_13: 0.7006 - val_precision_13: 0.9292\n",
      "Epoch 222/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3706 - accuracy: 0.8248 - recall_13: 0.7178 - precision_13: 0.9136 - val_loss: 0.3663 - val_accuracy: 0.8253 - val_recall_13: 0.7089 - val_precision_13: 0.9222\n",
      "Epoch 223/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3711 - accuracy: 0.8241 - recall_13: 0.7172 - precision_13: 0.9127 - val_loss: 0.3667 - val_accuracy: 0.8254 - val_recall_13: 0.7118 - val_precision_13: 0.9194\n",
      "Epoch 224/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3714 - accuracy: 0.8246 - recall_13: 0.7179 - precision_13: 0.9132 - val_loss: 0.3664 - val_accuracy: 0.8250 - val_recall_13: 0.7041 - val_precision_13: 0.9270\n",
      "Epoch 225/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.8255 - recall_13: 0.7173 - precision_13: 0.9158 - val_loss: 0.3664 - val_accuracy: 0.8251 - val_recall_13: 0.7061 - val_precision_13: 0.9249\n",
      "Epoch 226/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3712 - accuracy: 0.8242 - recall_13: 0.7166 - precision_13: 0.9134 - val_loss: 0.3663 - val_accuracy: 0.8243 - val_recall_13: 0.7047 - val_precision_13: 0.9245\n",
      "Epoch 227/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8241 - recall_13: 0.7168 - precision_13: 0.9131 - val_loss: 0.3660 - val_accuracy: 0.8254 - val_recall_13: 0.7062 - val_precision_13: 0.9256\n",
      "Epoch 228/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3704 - accuracy: 0.8254 - recall_13: 0.7184 - precision_13: 0.9145 - val_loss: 0.3660 - val_accuracy: 0.8252 - val_recall_13: 0.7094 - val_precision_13: 0.9217\n",
      "Epoch 229/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3703 - accuracy: 0.8253 - recall_13: 0.7178 - precision_13: 0.9147 - val_loss: 0.3663 - val_accuracy: 0.8254 - val_recall_13: 0.7077 - val_precision_13: 0.9238\n",
      "Epoch 230/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8249 - recall_13: 0.7190 - precision_13: 0.9127 - val_loss: 0.3664 - val_accuracy: 0.8252 - val_recall_13: 0.7088 - val_precision_13: 0.9222\n",
      "Epoch 231/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8249 - recall_13: 0.7176 - precision_13: 0.9142 - val_loss: 0.3659 - val_accuracy: 0.8263 - val_recall_13: 0.7125 - val_precision_13: 0.9207\n",
      "Epoch 232/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3706 - accuracy: 0.8248 - recall_13: 0.7185 - precision_13: 0.9128 - val_loss: 0.3663 - val_accuracy: 0.8242 - val_recall_13: 0.7045 - val_precision_13: 0.9245\n",
      "Epoch 233/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3712 - accuracy: 0.8244 - recall_13: 0.7166 - precision_13: 0.9139 - val_loss: 0.3666 - val_accuracy: 0.8251 - val_recall_13: 0.7109 - val_precision_13: 0.9196\n",
      "Epoch 234/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3713 - accuracy: 0.8243 - recall_13: 0.7181 - precision_13: 0.9121 - val_loss: 0.3660 - val_accuracy: 0.8265 - val_recall_13: 0.7122 - val_precision_13: 0.9216\n",
      "Epoch 235/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3700 - accuracy: 0.8265 - recall_13: 0.7190 - precision_13: 0.9163 - val_loss: 0.3662 - val_accuracy: 0.8265 - val_recall_13: 0.7164 - val_precision_13: 0.9171\n",
      "Epoch 236/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3706 - accuracy: 0.8257 - recall_13: 0.7209 - precision_13: 0.9125 - val_loss: 0.3658 - val_accuracy: 0.8258 - val_recall_13: 0.7071 - val_precision_13: 0.9254\n",
      "Epoch 237/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3701 - accuracy: 0.8254 - recall_13: 0.7177 - precision_13: 0.9152 - val_loss: 0.3662 - val_accuracy: 0.8273 - val_recall_13: 0.7191 - val_precision_13: 0.9160\n",
      "Epoch 238/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3699 - accuracy: 0.8248 - recall_13: 0.7194 - precision_13: 0.9121 - val_loss: 0.3655 - val_accuracy: 0.8265 - val_recall_13: 0.7137 - val_precision_13: 0.9199\n",
      "Epoch 239/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3687 - accuracy: 0.8263 - recall_13: 0.7213 - precision_13: 0.9135 - val_loss: 0.3652 - val_accuracy: 0.8267 - val_recall_13: 0.7148 - val_precision_13: 0.9192\n",
      "Epoch 240/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3707 - accuracy: 0.8244 - recall_13: 0.7192 - precision_13: 0.9114 - val_loss: 0.3652 - val_accuracy: 0.8269 - val_recall_13: 0.7097 - val_precision_13: 0.9253\n",
      "Epoch 241/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3697 - accuracy: 0.8250 - recall_13: 0.7204 - precision_13: 0.9113 - val_loss: 0.3653 - val_accuracy: 0.8267 - val_recall_13: 0.7125 - val_precision_13: 0.9217\n",
      "Epoch 242/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3704 - accuracy: 0.8249 - recall_13: 0.7194 - precision_13: 0.9122 - val_loss: 0.3652 - val_accuracy: 0.8250 - val_recall_13: 0.7013 - val_precision_13: 0.9301\n",
      "Epoch 243/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8249 - recall_13: 0.7186 - precision_13: 0.9131 - val_loss: 0.3648 - val_accuracy: 0.8261 - val_recall_13: 0.7070 - val_precision_13: 0.9262\n",
      "Epoch 244/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3700 - accuracy: 0.8258 - recall_13: 0.7199 - precision_13: 0.9137 - val_loss: 0.3650 - val_accuracy: 0.8265 - val_recall_13: 0.7110 - val_precision_13: 0.9230\n",
      "Epoch 245/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8258 - recall_13: 0.7191 - precision_13: 0.9146 - val_loss: 0.3655 - val_accuracy: 0.8264 - val_recall_13: 0.7130 - val_precision_13: 0.9205\n",
      "Epoch 246/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3693 - accuracy: 0.8263 - recall_13: 0.7204 - precision_13: 0.9144 - val_loss: 0.3652 - val_accuracy: 0.8251 - val_recall_13: 0.7037 - val_precision_13: 0.9276\n",
      "Epoch 247/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3692 - accuracy: 0.8258 - recall_13: 0.7207 - precision_13: 0.9129 - val_loss: 0.3651 - val_accuracy: 0.8247 - val_recall_13: 0.7040 - val_precision_13: 0.9263\n",
      "Epoch 248/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8256 - recall_13: 0.7199 - precision_13: 0.9133 - val_loss: 0.3651 - val_accuracy: 0.8255 - val_recall_13: 0.7108 - val_precision_13: 0.9207\n",
      "Epoch 249/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3690 - accuracy: 0.8256 - recall_13: 0.7212 - precision_13: 0.9120 - val_loss: 0.3649 - val_accuracy: 0.8261 - val_recall_13: 0.7087 - val_precision_13: 0.9245\n",
      "Epoch 250/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3689 - accuracy: 0.8262 - recall_13: 0.7226 - precision_13: 0.9118 - val_loss: 0.3654 - val_accuracy: 0.8252 - val_recall_13: 0.7021 - val_precision_13: 0.9297\n",
      "Epoch 251/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8266 - recall_13: 0.7231 - precision_13: 0.9123 - val_loss: 0.3652 - val_accuracy: 0.8256 - val_recall_13: 0.7053 - val_precision_13: 0.9270\n",
      "Epoch 252/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8267 - recall_13: 0.7231 - precision_13: 0.9125 - val_loss: 0.3650 - val_accuracy: 0.8267 - val_recall_13: 0.7076 - val_precision_13: 0.9270\n",
      "Epoch 253/500\n",
      "1451/1451 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8254 - recall_13: 0.7202 - precision_13: 0.9124 - val_loss: 0.3648 - val_accuracy: 0.8263 - val_recall_13: 0.7076 - val_precision_13: 0.9261\n",
      "2902/2902 [==============================] - 2s 734us/step\n",
      "726/726 [==============================] - 1s 787us/step\n",
      "Acurácia no conjunto de treinamento: 0.8295156955718994\n",
      "Acurácia no conjunto de teste: 0.8260607123374939\n",
      "AUC no conjunto de treinamento: 0.9215135896591237\n",
      "AUC no conjunto de teste: 0.9157634383140194\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.0005)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.0005)))\n",
    "# model.add(Dropout(0.25)) \n",
    "# model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.00005)))  \n",
    "# model.add(Dropout(0.25)) \n",
    "# model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.00005)))  \n",
    "# model.add(Dropout(0.25)) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Mantendo a taxa de aprendizado e o tamanho do batch do último ajuste\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Aumentando a paciência no EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Paciência aumentada para permitir mais treinamento\n",
    "\n",
    "# Treinando o modelo com mais épocas\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64,  # Aumento do número de épocas\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/726 [..............................] - ETA: 13s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 750us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.76      0.94      0.84     11654\n",
      "    Classe 1       0.93      0.71      0.80     11561\n",
      "\n",
      "    accuracy                           0.83     23215\n",
      "   macro avg       0.85      0.83      0.82     23215\n",
      "weighted avg       0.85      0.83      0.82     23215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 769us/step\n",
      "Threshold: 0.10, Precision: 0.597, Recall: 0.987, F1 Score: 0.744, Accuracy: 0.662\n",
      "Threshold: 0.11, Precision: 0.601, Recall: 0.986, F1 Score: 0.747, Accuracy: 0.667\n",
      "Threshold: 0.12, Precision: 0.605, Recall: 0.985, F1 Score: 0.749, Accuracy: 0.672\n",
      "Threshold: 0.13, Precision: 0.608, Recall: 0.984, F1 Score: 0.751, Accuracy: 0.676\n",
      "Threshold: 0.14, Precision: 0.612, Recall: 0.983, F1 Score: 0.754, Accuracy: 0.681\n",
      "Threshold: 0.15, Precision: 0.615, Recall: 0.982, F1 Score: 0.757, Accuracy: 0.685\n",
      "Threshold: 0.16, Precision: 0.620, Recall: 0.980, F1 Score: 0.759, Accuracy: 0.690\n",
      "Threshold: 0.17, Precision: 0.625, Recall: 0.977, F1 Score: 0.762, Accuracy: 0.696\n",
      "Threshold: 0.18, Precision: 0.629, Recall: 0.974, F1 Score: 0.765, Accuracy: 0.701\n",
      "Threshold: 0.19, Precision: 0.635, Recall: 0.972, F1 Score: 0.768, Accuracy: 0.708\n",
      "Threshold: 0.20, Precision: 0.641, Recall: 0.970, F1 Score: 0.772, Accuracy: 0.714\n",
      "Threshold: 0.21, Precision: 0.647, Recall: 0.967, F1 Score: 0.775, Accuracy: 0.721\n",
      "Threshold: 0.22, Precision: 0.653, Recall: 0.964, F1 Score: 0.778, Accuracy: 0.727\n",
      "Threshold: 0.23, Precision: 0.659, Recall: 0.960, F1 Score: 0.781, Accuracy: 0.732\n",
      "Threshold: 0.24, Precision: 0.666, Recall: 0.956, F1 Score: 0.785, Accuracy: 0.739\n",
      "Threshold: 0.25, Precision: 0.672, Recall: 0.951, F1 Score: 0.788, Accuracy: 0.745\n",
      "Threshold: 0.26, Precision: 0.679, Recall: 0.945, F1 Score: 0.790, Accuracy: 0.750\n",
      "Threshold: 0.27, Precision: 0.686, Recall: 0.939, F1 Score: 0.793, Accuracy: 0.756\n",
      "Threshold: 0.28, Precision: 0.695, Recall: 0.933, F1 Score: 0.796, Accuracy: 0.763\n",
      "Threshold: 0.29, Precision: 0.704, Recall: 0.927, F1 Score: 0.800, Accuracy: 0.770\n",
      "Threshold: 0.30, Precision: 0.714, Recall: 0.918, F1 Score: 0.803, Accuracy: 0.776\n",
      "Threshold: 0.31, Precision: 0.727, Recall: 0.911, F1 Score: 0.809, Accuracy: 0.785\n",
      "Threshold: 0.32, Precision: 0.739, Recall: 0.903, F1 Score: 0.813, Accuracy: 0.793\n",
      "Threshold: 0.33, Precision: 0.749, Recall: 0.894, F1 Score: 0.815, Accuracy: 0.798\n",
      "Threshold: 0.34, Precision: 0.761, Recall: 0.885, F1 Score: 0.818, Accuracy: 0.805\n",
      "Threshold: 0.35, Precision: 0.775, Recall: 0.873, F1 Score: 0.821, Accuracy: 0.811\n",
      "Threshold: 0.36, Precision: 0.786, Recall: 0.863, F1 Score: 0.823, Accuracy: 0.815\n",
      "Threshold: 0.37, Precision: 0.798, Recall: 0.851, F1 Score: 0.824, Accuracy: 0.819\n",
      "Threshold: 0.38, Precision: 0.810, Recall: 0.840, F1 Score: 0.825, Accuracy: 0.822\n",
      "Threshold: 0.39, Precision: 0.822, Recall: 0.824, F1 Score: 0.823, Accuracy: 0.824\n",
      "Threshold: 0.40, Precision: 0.834, Recall: 0.810, F1 Score: 0.822, Accuracy: 0.825\n",
      "Threshold: 0.41, Precision: 0.847, Recall: 0.798, F1 Score: 0.822, Accuracy: 0.828\n",
      "Threshold: 0.42, Precision: 0.859, Recall: 0.786, F1 Score: 0.821, Accuracy: 0.829\n",
      "Threshold: 0.43, Precision: 0.871, Recall: 0.775, F1 Score: 0.820, Accuracy: 0.831\n",
      "Threshold: 0.44, Precision: 0.882, Recall: 0.763, F1 Score: 0.818, Accuracy: 0.831\n",
      "Threshold: 0.45, Precision: 0.893, Recall: 0.752, F1 Score: 0.817, Accuracy: 0.832\n",
      "Threshold: 0.46, Precision: 0.902, Recall: 0.741, F1 Score: 0.814, Accuracy: 0.831\n",
      "Threshold: 0.47, Precision: 0.910, Recall: 0.731, F1 Score: 0.811, Accuracy: 0.830\n",
      "Threshold: 0.48, Precision: 0.915, Recall: 0.722, F1 Score: 0.807, Accuracy: 0.828\n",
      "Threshold: 0.49, Precision: 0.921, Recall: 0.714, F1 Score: 0.805, Accuracy: 0.827\n",
      "Threshold: 0.50, Precision: 0.926, Recall: 0.707, F1 Score: 0.802, Accuracy: 0.826\n",
      "Threshold: 0.51, Precision: 0.932, Recall: 0.700, F1 Score: 0.800, Accuracy: 0.825\n",
      "Threshold: 0.52, Precision: 0.936, Recall: 0.696, F1 Score: 0.798, Accuracy: 0.825\n",
      "Threshold: 0.53, Precision: 0.939, Recall: 0.691, F1 Score: 0.797, Accuracy: 0.824\n",
      "Threshold: 0.54, Precision: 0.943, Recall: 0.686, F1 Score: 0.794, Accuracy: 0.823\n",
      "Threshold: 0.55, Precision: 0.946, Recall: 0.683, F1 Score: 0.793, Accuracy: 0.823\n",
      "Threshold: 0.56, Precision: 0.948, Recall: 0.679, F1 Score: 0.791, Accuracy: 0.822\n",
      "Threshold: 0.57, Precision: 0.949, Recall: 0.675, F1 Score: 0.789, Accuracy: 0.820\n",
      "Threshold: 0.58, Precision: 0.952, Recall: 0.672, F1 Score: 0.788, Accuracy: 0.820\n",
      "Threshold: 0.59, Precision: 0.953, Recall: 0.670, F1 Score: 0.787, Accuracy: 0.820\n",
      "Threshold: 0.60, Precision: 0.954, Recall: 0.668, F1 Score: 0.786, Accuracy: 0.819\n",
      "Threshold: 0.61, Precision: 0.956, Recall: 0.666, F1 Score: 0.785, Accuracy: 0.818\n",
      "Threshold: 0.62, Precision: 0.958, Recall: 0.663, F1 Score: 0.784, Accuracy: 0.818\n",
      "Threshold: 0.63, Precision: 0.959, Recall: 0.661, F1 Score: 0.783, Accuracy: 0.817\n",
      "Threshold: 0.64, Precision: 0.959, Recall: 0.659, F1 Score: 0.782, Accuracy: 0.816\n",
      "Threshold: 0.65, Precision: 0.961, Recall: 0.658, F1 Score: 0.781, Accuracy: 0.817\n",
      "Threshold: 0.66, Precision: 0.963, Recall: 0.657, F1 Score: 0.781, Accuracy: 0.816\n",
      "Threshold: 0.67, Precision: 0.964, Recall: 0.656, F1 Score: 0.780, Accuracy: 0.816\n",
      "Threshold: 0.68, Precision: 0.964, Recall: 0.654, F1 Score: 0.779, Accuracy: 0.815\n",
      "Threshold: 0.69, Precision: 0.965, Recall: 0.652, F1 Score: 0.778, Accuracy: 0.815\n",
      "Threshold: 0.70, Precision: 0.966, Recall: 0.650, F1 Score: 0.777, Accuracy: 0.814\n",
      "Threshold: 0.71, Precision: 0.967, Recall: 0.649, F1 Score: 0.777, Accuracy: 0.814\n",
      "Threshold: 0.72, Precision: 0.968, Recall: 0.648, F1 Score: 0.776, Accuracy: 0.814\n",
      "Threshold: 0.73, Precision: 0.968, Recall: 0.646, F1 Score: 0.775, Accuracy: 0.813\n",
      "Threshold: 0.74, Precision: 0.969, Recall: 0.645, F1 Score: 0.774, Accuracy: 0.813\n",
      "Threshold: 0.75, Precision: 0.970, Recall: 0.643, F1 Score: 0.774, Accuracy: 0.812\n",
      "Threshold: 0.76, Precision: 0.971, Recall: 0.641, F1 Score: 0.772, Accuracy: 0.812\n",
      "Threshold: 0.77, Precision: 0.972, Recall: 0.638, F1 Score: 0.771, Accuracy: 0.811\n",
      "Threshold: 0.78, Precision: 0.973, Recall: 0.636, F1 Score: 0.769, Accuracy: 0.810\n",
      "Threshold: 0.79, Precision: 0.974, Recall: 0.634, F1 Score: 0.768, Accuracy: 0.809\n",
      "Threshold: 0.80, Precision: 0.975, Recall: 0.631, F1 Score: 0.766, Accuracy: 0.808\n",
      "Threshold: 0.81, Precision: 0.976, Recall: 0.630, F1 Score: 0.765, Accuracy: 0.808\n",
      "Threshold: 0.82, Precision: 0.976, Recall: 0.627, F1 Score: 0.764, Accuracy: 0.807\n",
      "Threshold: 0.83, Precision: 0.977, Recall: 0.623, F1 Score: 0.761, Accuracy: 0.805\n",
      "Threshold: 0.84, Precision: 0.977, Recall: 0.619, F1 Score: 0.758, Accuracy: 0.803\n",
      "Threshold: 0.85, Precision: 0.978, Recall: 0.616, F1 Score: 0.756, Accuracy: 0.802\n",
      "Threshold: 0.86, Precision: 0.979, Recall: 0.612, F1 Score: 0.753, Accuracy: 0.800\n",
      "Threshold: 0.87, Precision: 0.979, Recall: 0.608, F1 Score: 0.750, Accuracy: 0.798\n",
      "Threshold: 0.88, Precision: 0.980, Recall: 0.603, F1 Score: 0.747, Accuracy: 0.796\n",
      "Threshold: 0.89, Precision: 0.982, Recall: 0.599, F1 Score: 0.744, Accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
