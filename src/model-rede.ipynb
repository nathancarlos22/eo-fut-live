{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'league',\n",
       "       'corners_home', 'corners_away', 'shotsOffgoal_home',\n",
       "       'shotsOffgoal_away', 'shotsOngoal_home', 'shotsOngoal_away',\n",
       "       'fouls_home', 'fouls_away', 'tackles_home', 'tackles_away', 'result',\n",
       "       'match_id', 'possessiontime_away', 'possessiontime_home',\n",
       "       'defensive_efficiency_home', 'defensive_efficiency_away',\n",
       "       'possession_efficiency_home', 'possession_efficiency_away',\n",
       "       'defensive_stability_home', 'defensive_stability_away',\n",
       "       'attack_intensity_home', 'attack_intensity_away',\n",
       "       'defensive_performance_home', 'defensive_performance_away',\n",
       "       'game_progress_efficiency_home', 'game_progress_efficiency_away',\n",
       "       'game_momentum_home', 'game_momentum_away', 'total_fouls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1451/1451 [==============================] - 4s 2ms/step - loss: 0.5013 - accuracy: 0.7676 - recall_8: 0.7600 - precision_8: 0.7722 - val_loss: 0.4408 - val_accuracy: 0.7940 - val_recall_8: 0.7486 - val_precision_8: 0.8219\n",
      "Epoch 2/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4457 - accuracy: 0.7946 - recall_8: 0.7368 - precision_8: 0.8336 - val_loss: 0.4190 - val_accuracy: 0.8031 - val_recall_8: 0.7286 - val_precision_8: 0.8546\n",
      "Epoch 3/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4325 - accuracy: 0.8011 - recall_8: 0.7206 - precision_8: 0.8594 - val_loss: 0.4123 - val_accuracy: 0.8052 - val_recall_8: 0.7188 - val_precision_8: 0.8673\n",
      "Epoch 4/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4231 - accuracy: 0.8047 - recall_8: 0.7098 - precision_8: 0.8764 - val_loss: 0.4060 - val_accuracy: 0.8087 - val_recall_8: 0.7082 - val_precision_8: 0.8847\n",
      "Epoch 5/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4175 - accuracy: 0.8066 - recall_8: 0.7037 - precision_8: 0.8865 - val_loss: 0.4001 - val_accuracy: 0.8118 - val_recall_8: 0.6990 - val_precision_8: 0.9009\n",
      "Epoch 6/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4134 - accuracy: 0.8081 - recall_8: 0.6975 - precision_8: 0.8962 - val_loss: 0.3977 - val_accuracy: 0.8128 - val_recall_8: 0.6959 - val_precision_8: 0.9065\n",
      "Epoch 7/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4099 - accuracy: 0.8093 - recall_8: 0.6939 - precision_8: 0.9026 - val_loss: 0.3966 - val_accuracy: 0.8128 - val_recall_8: 0.6937 - val_precision_8: 0.9089\n",
      "Epoch 8/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4081 - accuracy: 0.8099 - recall_8: 0.6900 - precision_8: 0.9082 - val_loss: 0.3930 - val_accuracy: 0.8151 - val_recall_8: 0.6883 - val_precision_8: 0.9204\n",
      "Epoch 9/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4057 - accuracy: 0.8111 - recall_8: 0.6882 - precision_8: 0.9130 - val_loss: 0.3932 - val_accuracy: 0.8149 - val_recall_8: 0.6905 - val_precision_8: 0.9175\n",
      "Epoch 10/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4034 - accuracy: 0.8108 - recall_8: 0.6872 - precision_8: 0.9134 - val_loss: 0.3907 - val_accuracy: 0.8158 - val_recall_8: 0.6863 - val_precision_8: 0.9243\n",
      "Epoch 11/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4020 - accuracy: 0.8122 - recall_8: 0.6854 - precision_8: 0.9186 - val_loss: 0.3895 - val_accuracy: 0.8161 - val_recall_8: 0.6840 - val_precision_8: 0.9276\n",
      "Epoch 12/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4005 - accuracy: 0.8119 - recall_8: 0.6854 - precision_8: 0.9180 - val_loss: 0.3892 - val_accuracy: 0.8171 - val_recall_8: 0.6845 - val_precision_8: 0.9295\n",
      "Epoch 13/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3989 - accuracy: 0.8127 - recall_8: 0.6834 - precision_8: 0.9224 - val_loss: 0.3893 - val_accuracy: 0.8165 - val_recall_8: 0.6890 - val_precision_8: 0.9228\n",
      "Epoch 14/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3984 - accuracy: 0.8128 - recall_8: 0.6831 - precision_8: 0.9228 - val_loss: 0.3872 - val_accuracy: 0.8172 - val_recall_8: 0.6833 - val_precision_8: 0.9314\n",
      "Epoch 15/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3971 - accuracy: 0.8133 - recall_8: 0.6832 - precision_8: 0.9239 - val_loss: 0.3873 - val_accuracy: 0.8171 - val_recall_8: 0.6856 - val_precision_8: 0.9285\n",
      "Epoch 16/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3960 - accuracy: 0.8136 - recall_8: 0.6826 - precision_8: 0.9253 - val_loss: 0.3867 - val_accuracy: 0.8176 - val_recall_8: 0.6867 - val_precision_8: 0.9284\n",
      "Epoch 17/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3946 - accuracy: 0.8135 - recall_8: 0.6827 - precision_8: 0.9250 - val_loss: 0.3854 - val_accuracy: 0.8182 - val_recall_8: 0.6842 - val_precision_8: 0.9328\n",
      "Epoch 18/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3940 - accuracy: 0.8139 - recall_8: 0.6824 - precision_8: 0.9265 - val_loss: 0.3857 - val_accuracy: 0.8176 - val_recall_8: 0.6872 - val_precision_8: 0.9277\n",
      "Epoch 19/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3926 - accuracy: 0.8141 - recall_8: 0.6834 - precision_8: 0.9258 - val_loss: 0.3838 - val_accuracy: 0.8185 - val_recall_8: 0.6837 - val_precision_8: 0.9342\n",
      "Epoch 20/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3915 - accuracy: 0.8144 - recall_8: 0.6826 - precision_8: 0.9276 - val_loss: 0.3841 - val_accuracy: 0.8175 - val_recall_8: 0.6882 - val_precision_8: 0.9265\n",
      "Epoch 21/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3908 - accuracy: 0.8147 - recall_8: 0.6842 - precision_8: 0.9261 - val_loss: 0.3828 - val_accuracy: 0.8178 - val_recall_8: 0.6874 - val_precision_8: 0.9282\n",
      "Epoch 22/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3900 - accuracy: 0.8152 - recall_8: 0.6847 - precision_8: 0.9271 - val_loss: 0.3825 - val_accuracy: 0.8184 - val_recall_8: 0.6916 - val_precision_8: 0.9248\n",
      "Epoch 23/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3888 - accuracy: 0.8154 - recall_8: 0.6860 - precision_8: 0.9260 - val_loss: 0.3817 - val_accuracy: 0.8190 - val_recall_8: 0.6887 - val_precision_8: 0.9297\n",
      "Epoch 24/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3894 - accuracy: 0.8153 - recall_8: 0.6861 - precision_8: 0.9256 - val_loss: 0.3815 - val_accuracy: 0.8184 - val_recall_8: 0.6896 - val_precision_8: 0.9271\n",
      "Epoch 25/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3877 - accuracy: 0.8164 - recall_8: 0.6873 - precision_8: 0.9271 - val_loss: 0.3818 - val_accuracy: 0.8189 - val_recall_8: 0.6945 - val_precision_8: 0.9227\n",
      "Epoch 26/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3870 - accuracy: 0.8159 - recall_8: 0.6868 - precision_8: 0.9262 - val_loss: 0.3792 - val_accuracy: 0.8193 - val_recall_8: 0.6875 - val_precision_8: 0.9317\n",
      "Epoch 27/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3868 - accuracy: 0.8161 - recall_8: 0.6887 - precision_8: 0.9248 - val_loss: 0.3802 - val_accuracy: 0.8188 - val_recall_8: 0.7018 - val_precision_8: 0.9145\n",
      "Epoch 28/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3851 - accuracy: 0.8167 - recall_8: 0.6911 - precision_8: 0.9233 - val_loss: 0.3787 - val_accuracy: 0.8197 - val_recall_8: 0.6968 - val_precision_8: 0.9221\n",
      "Epoch 29/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3848 - accuracy: 0.8163 - recall_8: 0.6914 - precision_8: 0.9222 - val_loss: 0.3778 - val_accuracy: 0.8187 - val_recall_8: 0.6916 - val_precision_8: 0.9256\n",
      "Epoch 30/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3833 - accuracy: 0.8177 - recall_8: 0.6913 - precision_8: 0.9256 - val_loss: 0.3782 - val_accuracy: 0.8196 - val_recall_8: 0.7005 - val_precision_8: 0.9176\n",
      "Epoch 31/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3831 - accuracy: 0.8169 - recall_8: 0.6945 - precision_8: 0.9200 - val_loss: 0.3769 - val_accuracy: 0.8198 - val_recall_8: 0.6974 - val_precision_8: 0.9217\n",
      "Epoch 32/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3825 - accuracy: 0.8173 - recall_8: 0.6953 - precision_8: 0.9202 - val_loss: 0.3764 - val_accuracy: 0.8207 - val_recall_8: 0.6969 - val_precision_8: 0.9245\n",
      "Epoch 33/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3812 - accuracy: 0.8174 - recall_8: 0.6956 - precision_8: 0.9201 - val_loss: 0.3747 - val_accuracy: 0.8218 - val_recall_8: 0.7029 - val_precision_8: 0.9206\n",
      "Epoch 34/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3799 - accuracy: 0.8193 - recall_8: 0.7007 - precision_8: 0.9190 - val_loss: 0.3756 - val_accuracy: 0.8215 - val_recall_8: 0.7086 - val_precision_8: 0.9135\n",
      "Epoch 35/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3802 - accuracy: 0.8187 - recall_8: 0.7006 - precision_8: 0.9177 - val_loss: 0.3754 - val_accuracy: 0.8215 - val_recall_8: 0.7069 - val_precision_8: 0.9152\n",
      "Epoch 36/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3792 - accuracy: 0.8183 - recall_8: 0.7011 - precision_8: 0.9161 - val_loss: 0.3732 - val_accuracy: 0.8223 - val_recall_8: 0.7058 - val_precision_8: 0.9185\n",
      "Epoch 37/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3786 - accuracy: 0.8195 - recall_8: 0.7047 - precision_8: 0.9151 - val_loss: 0.3725 - val_accuracy: 0.8227 - val_recall_8: 0.7056 - val_precision_8: 0.9196\n",
      "Epoch 38/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3764 - accuracy: 0.8203 - recall_8: 0.7071 - precision_8: 0.9145 - val_loss: 0.3718 - val_accuracy: 0.8216 - val_recall_8: 0.7113 - val_precision_8: 0.9110\n",
      "Epoch 39/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3774 - accuracy: 0.8199 - recall_8: 0.7080 - precision_8: 0.9126 - val_loss: 0.3712 - val_accuracy: 0.8236 - val_recall_8: 0.7184 - val_precision_8: 0.9083\n",
      "Epoch 40/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3760 - accuracy: 0.8218 - recall_8: 0.7125 - precision_8: 0.9122 - val_loss: 0.3720 - val_accuracy: 0.8243 - val_recall_8: 0.7287 - val_precision_8: 0.8993\n",
      "Epoch 41/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3751 - accuracy: 0.8212 - recall_8: 0.7123 - precision_8: 0.9112 - val_loss: 0.3697 - val_accuracy: 0.8240 - val_recall_8: 0.7191 - val_precision_8: 0.9085\n",
      "Epoch 42/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3740 - accuracy: 0.8218 - recall_8: 0.7156 - precision_8: 0.9090 - val_loss: 0.3692 - val_accuracy: 0.8261 - val_recall_8: 0.7300 - val_precision_8: 0.9021\n",
      "Epoch 43/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3730 - accuracy: 0.8228 - recall_8: 0.7190 - precision_8: 0.9078 - val_loss: 0.3675 - val_accuracy: 0.8259 - val_recall_8: 0.7268 - val_precision_8: 0.9050\n",
      "Epoch 44/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3726 - accuracy: 0.8226 - recall_8: 0.7194 - precision_8: 0.9069 - val_loss: 0.3691 - val_accuracy: 0.8283 - val_recall_8: 0.7449 - val_precision_8: 0.8926\n",
      "Epoch 45/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3720 - accuracy: 0.8229 - recall_8: 0.7239 - precision_8: 0.9029 - val_loss: 0.3674 - val_accuracy: 0.8264 - val_recall_8: 0.7221 - val_precision_8: 0.9109\n",
      "Epoch 46/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3710 - accuracy: 0.8235 - recall_8: 0.7248 - precision_8: 0.9034 - val_loss: 0.3653 - val_accuracy: 0.8271 - val_recall_8: 0.7260 - val_precision_8: 0.9084\n",
      "Epoch 47/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3700 - accuracy: 0.8246 - recall_8: 0.7270 - precision_8: 0.9037 - val_loss: 0.3652 - val_accuracy: 0.8290 - val_recall_8: 0.7453 - val_precision_8: 0.8938\n",
      "Epoch 48/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3700 - accuracy: 0.8246 - recall_8: 0.7324 - precision_8: 0.8984 - val_loss: 0.3656 - val_accuracy: 0.8286 - val_recall_8: 0.7471 - val_precision_8: 0.8911\n",
      "Epoch 49/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3686 - accuracy: 0.8265 - recall_8: 0.7363 - precision_8: 0.8988 - val_loss: 0.3632 - val_accuracy: 0.8303 - val_recall_8: 0.7396 - val_precision_8: 0.9019\n",
      "Epoch 50/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3671 - accuracy: 0.8275 - recall_8: 0.7350 - precision_8: 0.9021 - val_loss: 0.3635 - val_accuracy: 0.8299 - val_recall_8: 0.7502 - val_precision_8: 0.8910\n",
      "Epoch 51/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3667 - accuracy: 0.8269 - recall_8: 0.7392 - precision_8: 0.8969 - val_loss: 0.3636 - val_accuracy: 0.8326 - val_recall_8: 0.7588 - val_precision_8: 0.8888\n",
      "Epoch 52/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3651 - accuracy: 0.8283 - recall_8: 0.7404 - precision_8: 0.8988 - val_loss: 0.3616 - val_accuracy: 0.8320 - val_recall_8: 0.7581 - val_precision_8: 0.8882\n",
      "Epoch 53/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3645 - accuracy: 0.8287 - recall_8: 0.7441 - precision_8: 0.8959 - val_loss: 0.3603 - val_accuracy: 0.8327 - val_recall_8: 0.7443 - val_precision_8: 0.9027\n",
      "Epoch 54/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3636 - accuracy: 0.8300 - recall_8: 0.7462 - precision_8: 0.8968 - val_loss: 0.3591 - val_accuracy: 0.8325 - val_recall_8: 0.7590 - val_precision_8: 0.8884\n",
      "Epoch 55/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3633 - accuracy: 0.8291 - recall_8: 0.7488 - precision_8: 0.8925 - val_loss: 0.3585 - val_accuracy: 0.8345 - val_recall_8: 0.7666 - val_precision_8: 0.8856\n",
      "Epoch 56/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3621 - accuracy: 0.8306 - recall_8: 0.7504 - precision_8: 0.8941 - val_loss: 0.3577 - val_accuracy: 0.8355 - val_recall_8: 0.7644 - val_precision_8: 0.8898\n",
      "Epoch 57/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3614 - accuracy: 0.8310 - recall_8: 0.7516 - precision_8: 0.8938 - val_loss: 0.3573 - val_accuracy: 0.8350 - val_recall_8: 0.7676 - val_precision_8: 0.8859\n",
      "Epoch 58/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3596 - accuracy: 0.8329 - recall_8: 0.7569 - precision_8: 0.8929 - val_loss: 0.3567 - val_accuracy: 0.8352 - val_recall_8: 0.7677 - val_precision_8: 0.8863\n",
      "Epoch 59/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3598 - accuracy: 0.8332 - recall_8: 0.7598 - precision_8: 0.8909 - val_loss: 0.3567 - val_accuracy: 0.8373 - val_recall_8: 0.7799 - val_precision_8: 0.8797\n",
      "Epoch 60/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3583 - accuracy: 0.8325 - recall_8: 0.7581 - precision_8: 0.8910 - val_loss: 0.3556 - val_accuracy: 0.8388 - val_recall_8: 0.7899 - val_precision_8: 0.8742\n",
      "Epoch 61/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3578 - accuracy: 0.8345 - recall_8: 0.7648 - precision_8: 0.8890 - val_loss: 0.3555 - val_accuracy: 0.8378 - val_recall_8: 0.7886 - val_precision_8: 0.8734\n",
      "Epoch 62/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3564 - accuracy: 0.8347 - recall_8: 0.7637 - precision_8: 0.8906 - val_loss: 0.3519 - val_accuracy: 0.8390 - val_recall_8: 0.7798 - val_precision_8: 0.8832\n",
      "Epoch 63/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3566 - accuracy: 0.8359 - recall_8: 0.7677 - precision_8: 0.8894 - val_loss: 0.3519 - val_accuracy: 0.8388 - val_recall_8: 0.7738 - val_precision_8: 0.8881\n",
      "Epoch 64/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3553 - accuracy: 0.8364 - recall_8: 0.7680 - precision_8: 0.8901 - val_loss: 0.3500 - val_accuracy: 0.8416 - val_recall_8: 0.7855 - val_precision_8: 0.8835\n",
      "Epoch 65/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3541 - accuracy: 0.8362 - recall_8: 0.7704 - precision_8: 0.8875 - val_loss: 0.3492 - val_accuracy: 0.8437 - val_recall_8: 0.7863 - val_precision_8: 0.8871\n",
      "Epoch 66/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8378 - recall_8: 0.7742 - precision_8: 0.8872 - val_loss: 0.3486 - val_accuracy: 0.8444 - val_recall_8: 0.7960 - val_precision_8: 0.8801\n",
      "Epoch 67/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3518 - accuracy: 0.8379 - recall_8: 0.7756 - precision_8: 0.8864 - val_loss: 0.3467 - val_accuracy: 0.8440 - val_recall_8: 0.7903 - val_precision_8: 0.8841\n",
      "Epoch 68/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3508 - accuracy: 0.8391 - recall_8: 0.7788 - precision_8: 0.8859 - val_loss: 0.3469 - val_accuracy: 0.8448 - val_recall_8: 0.7962 - val_precision_8: 0.8806\n",
      "Epoch 69/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8399 - recall_8: 0.7811 - precision_8: 0.8854 - val_loss: 0.3453 - val_accuracy: 0.8468 - val_recall_8: 0.8013 - val_precision_8: 0.8803\n",
      "Epoch 70/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3487 - accuracy: 0.8407 - recall_8: 0.7834 - precision_8: 0.8852 - val_loss: 0.3463 - val_accuracy: 0.8485 - val_recall_8: 0.8171 - val_precision_8: 0.8707\n",
      "Epoch 71/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3480 - accuracy: 0.8425 - recall_8: 0.7865 - precision_8: 0.8859 - val_loss: 0.3435 - val_accuracy: 0.8487 - val_recall_8: 0.8044 - val_precision_8: 0.8814\n",
      "Epoch 72/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3479 - accuracy: 0.8420 - recall_8: 0.7865 - precision_8: 0.8850 - val_loss: 0.3426 - val_accuracy: 0.8496 - val_recall_8: 0.8033 - val_precision_8: 0.8841\n",
      "Epoch 73/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3453 - accuracy: 0.8433 - recall_8: 0.7885 - precision_8: 0.8859 - val_loss: 0.3419 - val_accuracy: 0.8500 - val_recall_8: 0.8155 - val_precision_8: 0.8748\n",
      "Epoch 74/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3452 - accuracy: 0.8441 - recall_8: 0.7908 - precision_8: 0.8854 - val_loss: 0.3403 - val_accuracy: 0.8522 - val_recall_8: 0.8100 - val_precision_8: 0.8836\n",
      "Epoch 75/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3438 - accuracy: 0.8447 - recall_8: 0.7935 - precision_8: 0.8844 - val_loss: 0.3390 - val_accuracy: 0.8512 - val_recall_8: 0.8126 - val_precision_8: 0.8795\n",
      "Epoch 76/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3444 - accuracy: 0.8443 - recall_8: 0.7924 - precision_8: 0.8844 - val_loss: 0.3396 - val_accuracy: 0.8532 - val_recall_8: 0.8131 - val_precision_8: 0.8829\n",
      "Epoch 77/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3426 - accuracy: 0.8447 - recall_8: 0.7947 - precision_8: 0.8833 - val_loss: 0.3370 - val_accuracy: 0.8547 - val_recall_8: 0.8109 - val_precision_8: 0.8877\n",
      "Epoch 78/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3409 - accuracy: 0.8467 - recall_8: 0.7977 - precision_8: 0.8846 - val_loss: 0.3365 - val_accuracy: 0.8549 - val_recall_8: 0.8230 - val_precision_8: 0.8779\n",
      "Epoch 79/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3411 - accuracy: 0.8465 - recall_8: 0.8001 - precision_8: 0.8824 - val_loss: 0.3340 - val_accuracy: 0.8551 - val_recall_8: 0.8107 - val_precision_8: 0.8885\n",
      "Epoch 80/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3398 - accuracy: 0.8481 - recall_8: 0.8019 - precision_8: 0.8840 - val_loss: 0.3347 - val_accuracy: 0.8582 - val_recall_8: 0.8292 - val_precision_8: 0.8791\n",
      "Epoch 81/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3380 - accuracy: 0.8487 - recall_8: 0.8034 - precision_8: 0.8837 - val_loss: 0.3346 - val_accuracy: 0.8588 - val_recall_8: 0.8344 - val_precision_8: 0.8760\n",
      "Epoch 82/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3375 - accuracy: 0.8482 - recall_8: 0.8043 - precision_8: 0.8819 - val_loss: 0.3335 - val_accuracy: 0.8575 - val_recall_8: 0.8384 - val_precision_8: 0.8707\n",
      "Epoch 83/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8507 - recall_8: 0.8078 - precision_8: 0.8840 - val_loss: 0.3302 - val_accuracy: 0.8593 - val_recall_8: 0.8292 - val_precision_8: 0.8813\n",
      "Epoch 84/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3355 - accuracy: 0.8519 - recall_8: 0.8102 - precision_8: 0.8843 - val_loss: 0.3289 - val_accuracy: 0.8590 - val_recall_8: 0.8169 - val_precision_8: 0.8909\n",
      "Epoch 85/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3344 - accuracy: 0.8514 - recall_8: 0.8086 - precision_8: 0.8845 - val_loss: 0.3282 - val_accuracy: 0.8608 - val_recall_8: 0.8254 - val_precision_8: 0.8871\n",
      "Epoch 86/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3325 - accuracy: 0.8535 - recall_8: 0.8122 - precision_8: 0.8855 - val_loss: 0.3304 - val_accuracy: 0.8607 - val_recall_8: 0.8470 - val_precision_8: 0.8699\n",
      "Epoch 87/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3329 - accuracy: 0.8516 - recall_8: 0.8105 - precision_8: 0.8833 - val_loss: 0.3277 - val_accuracy: 0.8624 - val_recall_8: 0.8329 - val_precision_8: 0.8841\n",
      "Epoch 88/500\n",
      "1451/1451 [==============================] - 5s 4ms/step - loss: 0.3310 - accuracy: 0.8542 - recall_8: 0.8145 - precision_8: 0.8851 - val_loss: 0.3246 - val_accuracy: 0.8634 - val_recall_8: 0.8299 - val_precision_8: 0.8884\n",
      "Epoch 89/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3314 - accuracy: 0.8537 - recall_8: 0.8144 - precision_8: 0.8841 - val_loss: 0.3276 - val_accuracy: 0.8644 - val_recall_8: 0.8530 - val_precision_8: 0.8719\n",
      "Epoch 90/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3301 - accuracy: 0.8553 - recall_8: 0.8173 - precision_8: 0.8849 - val_loss: 0.3242 - val_accuracy: 0.8647 - val_recall_8: 0.8421 - val_precision_8: 0.8808\n",
      "Epoch 91/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8550 - recall_8: 0.8169 - precision_8: 0.8846 - val_loss: 0.3235 - val_accuracy: 0.8659 - val_recall_8: 0.8505 - val_precision_8: 0.8766\n",
      "Epoch 92/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3276 - accuracy: 0.8568 - recall_8: 0.8208 - precision_8: 0.8848 - val_loss: 0.3236 - val_accuracy: 0.8662 - val_recall_8: 0.8480 - val_precision_8: 0.8790\n",
      "Epoch 93/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3272 - accuracy: 0.8566 - recall_8: 0.8205 - precision_8: 0.8847 - val_loss: 0.3200 - val_accuracy: 0.8661 - val_recall_8: 0.8336 - val_precision_8: 0.8905\n",
      "Epoch 94/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3263 - accuracy: 0.8581 - recall_8: 0.8225 - precision_8: 0.8858 - val_loss: 0.3235 - val_accuracy: 0.8667 - val_recall_8: 0.8701 - val_precision_8: 0.8633\n",
      "Epoch 95/500\n",
      "1451/1451 [==============================] - 4s 2ms/step - loss: 0.3252 - accuracy: 0.8589 - recall_8: 0.8254 - precision_8: 0.8849 - val_loss: 0.3226 - val_accuracy: 0.8678 - val_recall_8: 0.8596 - val_precision_8: 0.8729\n",
      "Epoch 96/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3238 - accuracy: 0.8585 - recall_8: 0.8240 - precision_8: 0.8853 - val_loss: 0.3205 - val_accuracy: 0.8686 - val_recall_8: 0.8661 - val_precision_8: 0.8695\n",
      "Epoch 97/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3226 - accuracy: 0.8611 - recall_8: 0.8282 - precision_8: 0.8868 - val_loss: 0.3154 - val_accuracy: 0.8692 - val_recall_8: 0.8468 - val_precision_8: 0.8856\n",
      "Epoch 98/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3218 - accuracy: 0.8595 - recall_8: 0.8273 - precision_8: 0.8846 - val_loss: 0.3165 - val_accuracy: 0.8708 - val_recall_8: 0.8532 - val_precision_8: 0.8834\n",
      "Epoch 99/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3204 - accuracy: 0.8610 - recall_8: 0.8289 - precision_8: 0.8860 - val_loss: 0.3150 - val_accuracy: 0.8703 - val_recall_8: 0.8555 - val_precision_8: 0.8805\n",
      "Epoch 100/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8618 - recall_8: 0.8302 - precision_8: 0.8866 - val_loss: 0.3138 - val_accuracy: 0.8723 - val_recall_8: 0.8561 - val_precision_8: 0.8838\n",
      "Epoch 101/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3194 - accuracy: 0.8621 - recall_8: 0.8312 - precision_8: 0.8862 - val_loss: 0.3140 - val_accuracy: 0.8726 - val_recall_8: 0.8606 - val_precision_8: 0.8809\n",
      "Epoch 102/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3192 - accuracy: 0.8620 - recall_8: 0.8315 - precision_8: 0.8858 - val_loss: 0.3105 - val_accuracy: 0.8733 - val_recall_8: 0.8516 - val_precision_8: 0.8893\n",
      "Epoch 103/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3167 - accuracy: 0.8643 - recall_8: 0.8343 - precision_8: 0.8878 - val_loss: 0.3110 - val_accuracy: 0.8743 - val_recall_8: 0.8690 - val_precision_8: 0.8773\n",
      "Epoch 104/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3169 - accuracy: 0.8641 - recall_8: 0.8356 - precision_8: 0.8864 - val_loss: 0.3091 - val_accuracy: 0.8750 - val_recall_8: 0.8579 - val_precision_8: 0.8873\n",
      "Epoch 105/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3158 - accuracy: 0.8645 - recall_8: 0.8363 - precision_8: 0.8865 - val_loss: 0.3089 - val_accuracy: 0.8758 - val_recall_8: 0.8654 - val_precision_8: 0.8829\n",
      "Epoch 106/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8648 - recall_8: 0.8370 - precision_8: 0.8866 - val_loss: 0.3086 - val_accuracy: 0.8766 - val_recall_8: 0.8631 - val_precision_8: 0.8861\n",
      "Epoch 107/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3141 - accuracy: 0.8654 - recall_8: 0.8376 - precision_8: 0.8872 - val_loss: 0.3082 - val_accuracy: 0.8774 - val_recall_8: 0.8745 - val_precision_8: 0.8787\n",
      "Epoch 108/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3123 - accuracy: 0.8667 - recall_8: 0.8404 - precision_8: 0.8874 - val_loss: 0.3088 - val_accuracy: 0.8768 - val_recall_8: 0.8780 - val_precision_8: 0.8750\n",
      "Epoch 109/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.3122 - accuracy: 0.8671 - recall_8: 0.8406 - precision_8: 0.8879 - val_loss: 0.3074 - val_accuracy: 0.8778 - val_recall_8: 0.8768 - val_precision_8: 0.8777\n",
      "Epoch 110/500\n",
      "1451/1451 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.8663 - recall_8: 0.8395 - precision_8: 0.8873 - val_loss: 0.3060 - val_accuracy: 0.8790 - val_recall_8: 0.8706 - val_precision_8: 0.8847\n",
      "Epoch 111/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3116 - accuracy: 0.8673 - recall_8: 0.8405 - precision_8: 0.8884 - val_loss: 0.3040 - val_accuracy: 0.8795 - val_recall_8: 0.8748 - val_precision_8: 0.8823\n",
      "Epoch 112/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8677 - recall_8: 0.8431 - precision_8: 0.8869 - val_loss: 0.3017 - val_accuracy: 0.8795 - val_recall_8: 0.8644 - val_precision_8: 0.8905\n",
      "Epoch 113/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8697 - recall_8: 0.8454 - precision_8: 0.8887 - val_loss: 0.3034 - val_accuracy: 0.8797 - val_recall_8: 0.8819 - val_precision_8: 0.8772\n",
      "Epoch 114/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3083 - accuracy: 0.8709 - recall_8: 0.8468 - precision_8: 0.8898 - val_loss: 0.3004 - val_accuracy: 0.8815 - val_recall_8: 0.8747 - val_precision_8: 0.8859\n",
      "Epoch 115/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8696 - recall_8: 0.8462 - precision_8: 0.8880 - val_loss: 0.3016 - val_accuracy: 0.8823 - val_recall_8: 0.8819 - val_precision_8: 0.8817\n",
      "Epoch 116/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3070 - accuracy: 0.8706 - recall_8: 0.8467 - precision_8: 0.8894 - val_loss: 0.3003 - val_accuracy: 0.8827 - val_recall_8: 0.8848 - val_precision_8: 0.8804\n",
      "Epoch 117/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3053 - accuracy: 0.8719 - recall_8: 0.8485 - precision_8: 0.8904 - val_loss: 0.3014 - val_accuracy: 0.8828 - val_recall_8: 0.8888 - val_precision_8: 0.8775\n",
      "Epoch 118/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8718 - recall_8: 0.8490 - precision_8: 0.8899 - val_loss: 0.2999 - val_accuracy: 0.8840 - val_recall_8: 0.8896 - val_precision_8: 0.8790\n",
      "Epoch 119/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3045 - accuracy: 0.8717 - recall_8: 0.8485 - precision_8: 0.8900 - val_loss: 0.2979 - val_accuracy: 0.8844 - val_recall_8: 0.8849 - val_precision_8: 0.8833\n",
      "Epoch 120/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8732 - recall_8: 0.8516 - precision_8: 0.8902 - val_loss: 0.2977 - val_accuracy: 0.8842 - val_recall_8: 0.8885 - val_precision_8: 0.8801\n",
      "Epoch 121/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3025 - accuracy: 0.8741 - recall_8: 0.8526 - precision_8: 0.8911 - val_loss: 0.2976 - val_accuracy: 0.8848 - val_recall_8: 0.8941 - val_precision_8: 0.8770\n",
      "Epoch 122/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.8743 - recall_8: 0.8542 - precision_8: 0.8902 - val_loss: 0.2957 - val_accuracy: 0.8862 - val_recall_8: 0.8893 - val_precision_8: 0.8831\n",
      "Epoch 123/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8763 - recall_8: 0.8548 - precision_8: 0.8934 - val_loss: 0.2937 - val_accuracy: 0.8863 - val_recall_8: 0.8869 - val_precision_8: 0.8850\n",
      "Epoch 124/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2991 - accuracy: 0.8745 - recall_8: 0.8546 - precision_8: 0.8903 - val_loss: 0.2927 - val_accuracy: 0.8886 - val_recall_8: 0.8868 - val_precision_8: 0.8893\n",
      "Epoch 125/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.3002 - accuracy: 0.8745 - recall_8: 0.8531 - precision_8: 0.8914 - val_loss: 0.2933 - val_accuracy: 0.8883 - val_recall_8: 0.8933 - val_precision_8: 0.8838\n",
      "Epoch 126/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2988 - accuracy: 0.8751 - recall_8: 0.8555 - precision_8: 0.8907 - val_loss: 0.2911 - val_accuracy: 0.8890 - val_recall_8: 0.8933 - val_precision_8: 0.8848\n",
      "Epoch 127/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8758 - recall_8: 0.8562 - precision_8: 0.8914 - val_loss: 0.2930 - val_accuracy: 0.8890 - val_recall_8: 0.9010 - val_precision_8: 0.8791\n",
      "Epoch 128/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2975 - accuracy: 0.8759 - recall_8: 0.8572 - precision_8: 0.8907 - val_loss: 0.2918 - val_accuracy: 0.8882 - val_recall_8: 0.8996 - val_precision_8: 0.8787\n",
      "Epoch 129/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2966 - accuracy: 0.8768 - recall_8: 0.8584 - precision_8: 0.8914 - val_loss: 0.2887 - val_accuracy: 0.8906 - val_recall_8: 0.8973 - val_precision_8: 0.8847\n",
      "Epoch 130/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2957 - accuracy: 0.8768 - recall_8: 0.8589 - precision_8: 0.8909 - val_loss: 0.2900 - val_accuracy: 0.8902 - val_recall_8: 0.8985 - val_precision_8: 0.8830\n",
      "Epoch 131/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2950 - accuracy: 0.8784 - recall_8: 0.8592 - precision_8: 0.8938 - val_loss: 0.2889 - val_accuracy: 0.8906 - val_recall_8: 0.9036 - val_precision_8: 0.8799\n",
      "Epoch 132/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2940 - accuracy: 0.8786 - recall_8: 0.8611 - precision_8: 0.8925 - val_loss: 0.2865 - val_accuracy: 0.8922 - val_recall_8: 0.9011 - val_precision_8: 0.8846\n",
      "Epoch 133/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2924 - accuracy: 0.8808 - recall_8: 0.8642 - precision_8: 0.8941 - val_loss: 0.2869 - val_accuracy: 0.8922 - val_recall_8: 0.9061 - val_precision_8: 0.8809\n",
      "Epoch 134/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8791 - recall_8: 0.8620 - precision_8: 0.8927 - val_loss: 0.2859 - val_accuracy: 0.8930 - val_recall_8: 0.9053 - val_precision_8: 0.8829\n",
      "Epoch 135/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2906 - accuracy: 0.8816 - recall_8: 0.8651 - precision_8: 0.8949 - val_loss: 0.2849 - val_accuracy: 0.8931 - val_recall_8: 0.9058 - val_precision_8: 0.8826\n",
      "Epoch 136/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2894 - accuracy: 0.8807 - recall_8: 0.8644 - precision_8: 0.8937 - val_loss: 0.2827 - val_accuracy: 0.8941 - val_recall_8: 0.9010 - val_precision_8: 0.8881\n",
      "Epoch 137/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2898 - accuracy: 0.8805 - recall_8: 0.8644 - precision_8: 0.8934 - val_loss: 0.2817 - val_accuracy: 0.8941 - val_recall_8: 0.8991 - val_precision_8: 0.8895\n",
      "Epoch 138/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2891 - accuracy: 0.8825 - recall_8: 0.8660 - precision_8: 0.8957 - val_loss: 0.2822 - val_accuracy: 0.8953 - val_recall_8: 0.9003 - val_precision_8: 0.8907\n",
      "Epoch 139/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2885 - accuracy: 0.8822 - recall_8: 0.8655 - precision_8: 0.8957 - val_loss: 0.2791 - val_accuracy: 0.8936 - val_recall_8: 0.8934 - val_precision_8: 0.8930\n",
      "Epoch 140/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2875 - accuracy: 0.8833 - recall_8: 0.8668 - precision_8: 0.8967 - val_loss: 0.2798 - val_accuracy: 0.8948 - val_recall_8: 0.9066 - val_precision_8: 0.8850\n",
      "Epoch 141/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2881 - accuracy: 0.8829 - recall_8: 0.8685 - precision_8: 0.8944 - val_loss: 0.2805 - val_accuracy: 0.8954 - val_recall_8: 0.9078 - val_precision_8: 0.8851\n",
      "Epoch 142/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2873 - accuracy: 0.8829 - recall_8: 0.8669 - precision_8: 0.8957 - val_loss: 0.2810 - val_accuracy: 0.8943 - val_recall_8: 0.9059 - val_precision_8: 0.8846\n",
      "Epoch 143/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2876 - accuracy: 0.8833 - recall_8: 0.8685 - precision_8: 0.8953 - val_loss: 0.2763 - val_accuracy: 0.8976 - val_recall_8: 0.9001 - val_precision_8: 0.8949\n",
      "Epoch 144/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2864 - accuracy: 0.8828 - recall_8: 0.8678 - precision_8: 0.8949 - val_loss: 0.2789 - val_accuracy: 0.8968 - val_recall_8: 0.9116 - val_precision_8: 0.8847\n",
      "Epoch 145/500\n",
      "1451/1451 [==============================] - 4s 2ms/step - loss: 0.2848 - accuracy: 0.8852 - recall_8: 0.8703 - precision_8: 0.8973 - val_loss: 0.2769 - val_accuracy: 0.8974 - val_recall_8: 0.9077 - val_precision_8: 0.8886\n",
      "Epoch 146/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2849 - accuracy: 0.8850 - recall_8: 0.8701 - precision_8: 0.8970 - val_loss: 0.2781 - val_accuracy: 0.8970 - val_recall_8: 0.9140 - val_precision_8: 0.8832\n",
      "Epoch 147/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2836 - accuracy: 0.8850 - recall_8: 0.8709 - precision_8: 0.8964 - val_loss: 0.2772 - val_accuracy: 0.8977 - val_recall_8: 0.9147 - val_precision_8: 0.8838\n",
      "Epoch 148/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2817 - accuracy: 0.8860 - recall_8: 0.8717 - precision_8: 0.8976 - val_loss: 0.2746 - val_accuracy: 0.8995 - val_recall_8: 0.9083 - val_precision_8: 0.8918\n",
      "Epoch 149/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2837 - accuracy: 0.8860 - recall_8: 0.8726 - precision_8: 0.8969 - val_loss: 0.2756 - val_accuracy: 0.8995 - val_recall_8: 0.9175 - val_precision_8: 0.8850\n",
      "Epoch 150/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2809 - accuracy: 0.8861 - recall_8: 0.8722 - precision_8: 0.8973 - val_loss: 0.2728 - val_accuracy: 0.8998 - val_recall_8: 0.9102 - val_precision_8: 0.8909\n",
      "Epoch 151/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2798 - accuracy: 0.8879 - recall_8: 0.8746 - precision_8: 0.8986 - val_loss: 0.2730 - val_accuracy: 0.9006 - val_recall_8: 0.9170 - val_precision_8: 0.8872\n",
      "Epoch 152/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2817 - accuracy: 0.8867 - recall_8: 0.8731 - precision_8: 0.8977 - val_loss: 0.2721 - val_accuracy: 0.8998 - val_recall_8: 0.9158 - val_precision_8: 0.8868\n",
      "Epoch 153/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2808 - accuracy: 0.8871 - recall_8: 0.8737 - precision_8: 0.8979 - val_loss: 0.2741 - val_accuracy: 0.9002 - val_recall_8: 0.9207 - val_precision_8: 0.8838\n",
      "Epoch 154/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2790 - accuracy: 0.8880 - recall_8: 0.8751 - precision_8: 0.8985 - val_loss: 0.2712 - val_accuracy: 0.9012 - val_recall_8: 0.9145 - val_precision_8: 0.8901\n",
      "Epoch 155/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8885 - recall_8: 0.8770 - precision_8: 0.8978 - val_loss: 0.2706 - val_accuracy: 0.9006 - val_recall_8: 0.9154 - val_precision_8: 0.8884\n",
      "Epoch 156/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2776 - accuracy: 0.8893 - recall_8: 0.8768 - precision_8: 0.8995 - val_loss: 0.2706 - val_accuracy: 0.9002 - val_recall_8: 0.9164 - val_precision_8: 0.8869\n",
      "Epoch 157/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2778 - accuracy: 0.8892 - recall_8: 0.8776 - precision_8: 0.8986 - val_loss: 0.2693 - val_accuracy: 0.9026 - val_recall_8: 0.9175 - val_precision_8: 0.8903\n",
      "Epoch 158/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2764 - accuracy: 0.8899 - recall_8: 0.8785 - precision_8: 0.8993 - val_loss: 0.2685 - val_accuracy: 0.9034 - val_recall_8: 0.9174 - val_precision_8: 0.8918\n",
      "Epoch 159/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2775 - accuracy: 0.8891 - recall_8: 0.8779 - precision_8: 0.8983 - val_loss: 0.2679 - val_accuracy: 0.9035 - val_recall_8: 0.9162 - val_precision_8: 0.8928\n",
      "Epoch 160/500\n",
      "1451/1451 [==============================] - 3s 2ms/step - loss: 0.2758 - accuracy: 0.8891 - recall_8: 0.8763 - precision_8: 0.8996 - val_loss: 0.2670 - val_accuracy: 0.9039 - val_recall_8: 0.9192 - val_precision_8: 0.8912\n",
      "Epoch 161/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2759 - accuracy: 0.8891 - recall_8: 0.8778 - precision_8: 0.8984 - val_loss: 0.2665 - val_accuracy: 0.9039 - val_recall_8: 0.9190 - val_precision_8: 0.8915\n",
      "Epoch 162/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2755 - accuracy: 0.8904 - recall_8: 0.8789 - precision_8: 0.8997 - val_loss: 0.2660 - val_accuracy: 0.9045 - val_recall_8: 0.9193 - val_precision_8: 0.8921\n",
      "Epoch 163/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2730 - accuracy: 0.8918 - recall_8: 0.8799 - precision_8: 0.9016 - val_loss: 0.2651 - val_accuracy: 0.9058 - val_recall_8: 0.9211 - val_precision_8: 0.8930\n",
      "Epoch 164/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2730 - accuracy: 0.8908 - recall_8: 0.8798 - precision_8: 0.8998 - val_loss: 0.2640 - val_accuracy: 0.9055 - val_recall_8: 0.9199 - val_precision_8: 0.8935\n",
      "Epoch 165/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2737 - accuracy: 0.8914 - recall_8: 0.8812 - precision_8: 0.8997 - val_loss: 0.2643 - val_accuracy: 0.9054 - val_recall_8: 0.9199 - val_precision_8: 0.8933\n",
      "Epoch 166/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2742 - accuracy: 0.8908 - recall_8: 0.8793 - precision_8: 0.9002 - val_loss: 0.2632 - val_accuracy: 0.9050 - val_recall_8: 0.9175 - val_precision_8: 0.8945\n",
      "Epoch 167/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2734 - accuracy: 0.8916 - recall_8: 0.8812 - precision_8: 0.9001 - val_loss: 0.2624 - val_accuracy: 0.9058 - val_recall_8: 0.9183 - val_precision_8: 0.8952\n",
      "Epoch 168/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2723 - accuracy: 0.8917 - recall_8: 0.8807 - precision_8: 0.9007 - val_loss: 0.2635 - val_accuracy: 0.9061 - val_recall_8: 0.9243 - val_precision_8: 0.8912\n",
      "Epoch 169/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2704 - accuracy: 0.8929 - recall_8: 0.8814 - precision_8: 0.9024 - val_loss: 0.2617 - val_accuracy: 0.9057 - val_recall_8: 0.9202 - val_precision_8: 0.8936\n",
      "Epoch 170/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2700 - accuracy: 0.8935 - recall_8: 0.8841 - precision_8: 0.9011 - val_loss: 0.2620 - val_accuracy: 0.9073 - val_recall_8: 0.9205 - val_precision_8: 0.8962\n",
      "Epoch 171/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2706 - accuracy: 0.8929 - recall_8: 0.8826 - precision_8: 0.9014 - val_loss: 0.2625 - val_accuracy: 0.9055 - val_recall_8: 0.9245 - val_precision_8: 0.8900\n",
      "Epoch 172/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2701 - accuracy: 0.8928 - recall_8: 0.8826 - precision_8: 0.9011 - val_loss: 0.2619 - val_accuracy: 0.9080 - val_recall_8: 0.9258 - val_precision_8: 0.8933\n",
      "Epoch 173/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2688 - accuracy: 0.8933 - recall_8: 0.8837 - precision_8: 0.9012 - val_loss: 0.2629 - val_accuracy: 0.9058 - val_recall_8: 0.9318 - val_precision_8: 0.8851\n",
      "Epoch 174/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2672 - accuracy: 0.8949 - recall_8: 0.8860 - precision_8: 0.9021 - val_loss: 0.2600 - val_accuracy: 0.9076 - val_recall_8: 0.9196 - val_precision_8: 0.8974\n",
      "Epoch 175/500\n",
      "1451/1451 [==============================] - 6s 4ms/step - loss: 0.2694 - accuracy: 0.8940 - recall_8: 0.8845 - precision_8: 0.9018 - val_loss: 0.2609 - val_accuracy: 0.9086 - val_recall_8: 0.9270 - val_precision_8: 0.8934\n",
      "Epoch 176/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2683 - accuracy: 0.8939 - recall_8: 0.8837 - precision_8: 0.9023 - val_loss: 0.2589 - val_accuracy: 0.9092 - val_recall_8: 0.9266 - val_precision_8: 0.8948\n",
      "Epoch 177/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2655 - accuracy: 0.8957 - recall_8: 0.8872 - precision_8: 0.9028 - val_loss: 0.2580 - val_accuracy: 0.9095 - val_recall_8: 0.9260 - val_precision_8: 0.8959\n",
      "Epoch 178/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2665 - accuracy: 0.8949 - recall_8: 0.8859 - precision_8: 0.9024 - val_loss: 0.2579 - val_accuracy: 0.9099 - val_recall_8: 0.9296 - val_precision_8: 0.8938\n",
      "Epoch 179/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2655 - accuracy: 0.8950 - recall_8: 0.8860 - precision_8: 0.9024 - val_loss: 0.2591 - val_accuracy: 0.9086 - val_recall_8: 0.9316 - val_precision_8: 0.8901\n",
      "Epoch 180/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2651 - accuracy: 0.8954 - recall_8: 0.8869 - precision_8: 0.9023 - val_loss: 0.2577 - val_accuracy: 0.9116 - val_recall_8: 0.9313 - val_precision_8: 0.8954\n",
      "Epoch 181/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2652 - accuracy: 0.8970 - recall_8: 0.8887 - precision_8: 0.9039 - val_loss: 0.2561 - val_accuracy: 0.9113 - val_recall_8: 0.9281 - val_precision_8: 0.8972\n",
      "Epoch 182/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2651 - accuracy: 0.8955 - recall_8: 0.8871 - precision_8: 0.9024 - val_loss: 0.2544 - val_accuracy: 0.9117 - val_recall_8: 0.9273 - val_precision_8: 0.8986\n",
      "Epoch 183/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2609 - accuracy: 0.8985 - recall_8: 0.8902 - precision_8: 0.9054 - val_loss: 0.2540 - val_accuracy: 0.9119 - val_recall_8: 0.9270 - val_precision_8: 0.8992\n",
      "Epoch 184/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2624 - accuracy: 0.8971 - recall_8: 0.8890 - precision_8: 0.9039 - val_loss: 0.2548 - val_accuracy: 0.9132 - val_recall_8: 0.9323 - val_precision_8: 0.8973\n",
      "Epoch 185/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2637 - accuracy: 0.8970 - recall_8: 0.8888 - precision_8: 0.9038 - val_loss: 0.2539 - val_accuracy: 0.9116 - val_recall_8: 0.9349 - val_precision_8: 0.8927\n",
      "Epoch 186/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2622 - accuracy: 0.8982 - recall_8: 0.8899 - precision_8: 0.9050 - val_loss: 0.2539 - val_accuracy: 0.9129 - val_recall_8: 0.9339 - val_precision_8: 0.8957\n",
      "Epoch 187/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2615 - accuracy: 0.8976 - recall_8: 0.8889 - precision_8: 0.9048 - val_loss: 0.2524 - val_accuracy: 0.9122 - val_recall_8: 0.9286 - val_precision_8: 0.8986\n",
      "Epoch 188/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2617 - accuracy: 0.8985 - recall_8: 0.8899 - precision_8: 0.9056 - val_loss: 0.2537 - val_accuracy: 0.9126 - val_recall_8: 0.9336 - val_precision_8: 0.8953\n",
      "Epoch 189/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2612 - accuracy: 0.8980 - recall_8: 0.8902 - precision_8: 0.9045 - val_loss: 0.2543 - val_accuracy: 0.9115 - val_recall_8: 0.9323 - val_precision_8: 0.8945\n",
      "Epoch 190/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2586 - accuracy: 0.8996 - recall_8: 0.8925 - precision_8: 0.9056 - val_loss: 0.2506 - val_accuracy: 0.9128 - val_recall_8: 0.9218 - val_precision_8: 0.9048\n",
      "Epoch 191/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2602 - accuracy: 0.8992 - recall_8: 0.8909 - precision_8: 0.9062 - val_loss: 0.2515 - val_accuracy: 0.9130 - val_recall_8: 0.9352 - val_precision_8: 0.8949\n",
      "Epoch 192/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2614 - accuracy: 0.8975 - recall_8: 0.8910 - precision_8: 0.9029 - val_loss: 0.2490 - val_accuracy: 0.9150 - val_recall_8: 0.9292 - val_precision_8: 0.9029\n",
      "Epoch 193/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2600 - accuracy: 0.8993 - recall_8: 0.8915 - precision_8: 0.9057 - val_loss: 0.2514 - val_accuracy: 0.9141 - val_recall_8: 0.9365 - val_precision_8: 0.8957\n",
      "Epoch 194/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2588 - accuracy: 0.9000 - recall_8: 0.8937 - precision_8: 0.9052 - val_loss: 0.2480 - val_accuracy: 0.9141 - val_recall_8: 0.9281 - val_precision_8: 0.9022\n",
      "Epoch 195/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2594 - accuracy: 0.8985 - recall_8: 0.8922 - precision_8: 0.9038 - val_loss: 0.2501 - val_accuracy: 0.9145 - val_recall_8: 0.9318 - val_precision_8: 0.9001\n",
      "Epoch 196/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2587 - accuracy: 0.9003 - recall_8: 0.8939 - precision_8: 0.9056 - val_loss: 0.2469 - val_accuracy: 0.9149 - val_recall_8: 0.9269 - val_precision_8: 0.9045\n",
      "Epoch 197/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2583 - accuracy: 0.8998 - recall_8: 0.8928 - precision_8: 0.9056 - val_loss: 0.2476 - val_accuracy: 0.9140 - val_recall_8: 0.9357 - val_precision_8: 0.8962\n",
      "Epoch 198/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2586 - accuracy: 0.8995 - recall_8: 0.8922 - precision_8: 0.9057 - val_loss: 0.2484 - val_accuracy: 0.9145 - val_recall_8: 0.9331 - val_precision_8: 0.8989\n",
      "Epoch 199/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2563 - accuracy: 0.9014 - recall_8: 0.8951 - precision_8: 0.9067 - val_loss: 0.2486 - val_accuracy: 0.9143 - val_recall_8: 0.9345 - val_precision_8: 0.8976\n",
      "Epoch 200/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2559 - accuracy: 0.9017 - recall_8: 0.8949 - precision_8: 0.9073 - val_loss: 0.2475 - val_accuracy: 0.9143 - val_recall_8: 0.9338 - val_precision_8: 0.8982\n",
      "Epoch 201/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2551 - accuracy: 0.9013 - recall_8: 0.8941 - precision_8: 0.9074 - val_loss: 0.2473 - val_accuracy: 0.9156 - val_recall_8: 0.9343 - val_precision_8: 0.9000\n",
      "Epoch 202/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2574 - accuracy: 0.9010 - recall_8: 0.8945 - precision_8: 0.9066 - val_loss: 0.2457 - val_accuracy: 0.9157 - val_recall_8: 0.9332 - val_precision_8: 0.9010\n",
      "Epoch 203/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2554 - accuracy: 0.9014 - recall_8: 0.8953 - precision_8: 0.9065 - val_loss: 0.2454 - val_accuracy: 0.9165 - val_recall_8: 0.9305 - val_precision_8: 0.9046\n",
      "Epoch 204/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2535 - accuracy: 0.9022 - recall_8: 0.8948 - precision_8: 0.9085 - val_loss: 0.2472 - val_accuracy: 0.9163 - val_recall_8: 0.9393 - val_precision_8: 0.8974\n",
      "Epoch 205/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2572 - accuracy: 0.9005 - recall_8: 0.8945 - precision_8: 0.9056 - val_loss: 0.2443 - val_accuracy: 0.9164 - val_recall_8: 0.9315 - val_precision_8: 0.9037\n",
      "Epoch 206/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2558 - accuracy: 0.9002 - recall_8: 0.8941 - precision_8: 0.9054 - val_loss: 0.2453 - val_accuracy: 0.9159 - val_recall_8: 0.9341 - val_precision_8: 0.9007\n",
      "Epoch 207/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2539 - accuracy: 0.9026 - recall_8: 0.8972 - precision_8: 0.9071 - val_loss: 0.2433 - val_accuracy: 0.9186 - val_recall_8: 0.9332 - val_precision_8: 0.9061\n",
      "Epoch 208/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2550 - accuracy: 0.9015 - recall_8: 0.8957 - precision_8: 0.9064 - val_loss: 0.2444 - val_accuracy: 0.9175 - val_recall_8: 0.9370 - val_precision_8: 0.9012\n",
      "Epoch 209/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2536 - accuracy: 0.9031 - recall_8: 0.8969 - precision_8: 0.9083 - val_loss: 0.2429 - val_accuracy: 0.9188 - val_recall_8: 0.9363 - val_precision_8: 0.9040\n",
      "Epoch 210/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2539 - accuracy: 0.9028 - recall_8: 0.8966 - precision_8: 0.9080 - val_loss: 0.2457 - val_accuracy: 0.9173 - val_recall_8: 0.9407 - val_precision_8: 0.8980\n",
      "Epoch 211/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2522 - accuracy: 0.9040 - recall_8: 0.8985 - precision_8: 0.9086 - val_loss: 0.2444 - val_accuracy: 0.9176 - val_recall_8: 0.9385 - val_precision_8: 0.9003\n",
      "Epoch 212/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2519 - accuracy: 0.9035 - recall_8: 0.8977 - precision_8: 0.9084 - val_loss: 0.2462 - val_accuracy: 0.9154 - val_recall_8: 0.9424 - val_precision_8: 0.8935\n",
      "Epoch 213/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2527 - accuracy: 0.9035 - recall_8: 0.8979 - precision_8: 0.9083 - val_loss: 0.2430 - val_accuracy: 0.9188 - val_recall_8: 0.9364 - val_precision_8: 0.9041\n",
      "Epoch 214/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2528 - accuracy: 0.9040 - recall_8: 0.8985 - precision_8: 0.9086 - val_loss: 0.2428 - val_accuracy: 0.9166 - val_recall_8: 0.9328 - val_precision_8: 0.9029\n",
      "Epoch 215/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2518 - accuracy: 0.9032 - recall_8: 0.8975 - precision_8: 0.9080 - val_loss: 0.2411 - val_accuracy: 0.9181 - val_recall_8: 0.9332 - val_precision_8: 0.9053\n",
      "Epoch 216/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2513 - accuracy: 0.9036 - recall_8: 0.8975 - precision_8: 0.9088 - val_loss: 0.2417 - val_accuracy: 0.9182 - val_recall_8: 0.9383 - val_precision_8: 0.9014\n",
      "Epoch 217/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2514 - accuracy: 0.9035 - recall_8: 0.8975 - precision_8: 0.9085 - val_loss: 0.2444 - val_accuracy: 0.9179 - val_recall_8: 0.9427 - val_precision_8: 0.8975\n",
      "Epoch 218/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2514 - accuracy: 0.9044 - recall_8: 0.8983 - precision_8: 0.9095 - val_loss: 0.2401 - val_accuracy: 0.9182 - val_recall_8: 0.9318 - val_precision_8: 0.9067\n",
      "Epoch 219/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2504 - accuracy: 0.9045 - recall_8: 0.8990 - precision_8: 0.9092 - val_loss: 0.2445 - val_accuracy: 0.9172 - val_recall_8: 0.9442 - val_precision_8: 0.8952\n",
      "Epoch 220/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2495 - accuracy: 0.9064 - recall_8: 0.9010 - precision_8: 0.9109 - val_loss: 0.2396 - val_accuracy: 0.9197 - val_recall_8: 0.9388 - val_precision_8: 0.9036\n",
      "Epoch 221/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2486 - accuracy: 0.9050 - recall_8: 0.9010 - precision_8: 0.9085 - val_loss: 0.2406 - val_accuracy: 0.9190 - val_recall_8: 0.9402 - val_precision_8: 0.9014\n",
      "Epoch 222/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2481 - accuracy: 0.9056 - recall_8: 0.9005 - precision_8: 0.9099 - val_loss: 0.2386 - val_accuracy: 0.9185 - val_recall_8: 0.9393 - val_precision_8: 0.9012\n",
      "Epoch 223/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2479 - accuracy: 0.9058 - recall_8: 0.9005 - precision_8: 0.9103 - val_loss: 0.2402 - val_accuracy: 0.9187 - val_recall_8: 0.9388 - val_precision_8: 0.9019\n",
      "Epoch 224/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2482 - accuracy: 0.9057 - recall_8: 0.9009 - precision_8: 0.9099 - val_loss: 0.2424 - val_accuracy: 0.9183 - val_recall_8: 0.9459 - val_precision_8: 0.8959\n",
      "Epoch 225/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2469 - accuracy: 0.9054 - recall_8: 0.9010 - precision_8: 0.9090 - val_loss: 0.2415 - val_accuracy: 0.9188 - val_recall_8: 0.9427 - val_precision_8: 0.8992\n",
      "Epoch 226/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2467 - accuracy: 0.9063 - recall_8: 0.9018 - precision_8: 0.9100 - val_loss: 0.2376 - val_accuracy: 0.9188 - val_recall_8: 0.9373 - val_precision_8: 0.9034\n",
      "Epoch 227/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2477 - accuracy: 0.9064 - recall_8: 0.9011 - precision_8: 0.9109 - val_loss: 0.2423 - val_accuracy: 0.9172 - val_recall_8: 0.9459 - val_precision_8: 0.8940\n",
      "Epoch 228/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2460 - accuracy: 0.9062 - recall_8: 0.9012 - precision_8: 0.9104 - val_loss: 0.2381 - val_accuracy: 0.9204 - val_recall_8: 0.9414 - val_precision_8: 0.9029\n",
      "Epoch 229/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2454 - accuracy: 0.9074 - recall_8: 0.9033 - precision_8: 0.9108 - val_loss: 0.2380 - val_accuracy: 0.9198 - val_recall_8: 0.9446 - val_precision_8: 0.8993\n",
      "Epoch 230/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2466 - accuracy: 0.9069 - recall_8: 0.9029 - precision_8: 0.9104 - val_loss: 0.2376 - val_accuracy: 0.9213 - val_recall_8: 0.9434 - val_precision_8: 0.9030\n",
      "Epoch 231/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2474 - accuracy: 0.9066 - recall_8: 0.9023 - precision_8: 0.9103 - val_loss: 0.2357 - val_accuracy: 0.9207 - val_recall_8: 0.9390 - val_precision_8: 0.9052\n",
      "Epoch 232/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2463 - accuracy: 0.9078 - recall_8: 0.9027 - precision_8: 0.9122 - val_loss: 0.2357 - val_accuracy: 0.9216 - val_recall_8: 0.9390 - val_precision_8: 0.9069\n",
      "Epoch 233/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2452 - accuracy: 0.9071 - recall_8: 0.9022 - precision_8: 0.9113 - val_loss: 0.2393 - val_accuracy: 0.9192 - val_recall_8: 0.9446 - val_precision_8: 0.8983\n",
      "Epoch 234/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2444 - accuracy: 0.9081 - recall_8: 0.9035 - precision_8: 0.9121 - val_loss: 0.2371 - val_accuracy: 0.9216 - val_recall_8: 0.9455 - val_precision_8: 0.9017\n",
      "Epoch 235/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2437 - accuracy: 0.9076 - recall_8: 0.9032 - precision_8: 0.9115 - val_loss: 0.2356 - val_accuracy: 0.9204 - val_recall_8: 0.9441 - val_precision_8: 0.9009\n",
      "Epoch 236/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2457 - accuracy: 0.9073 - recall_8: 0.9029 - precision_8: 0.9110 - val_loss: 0.2359 - val_accuracy: 0.9214 - val_recall_8: 0.9436 - val_precision_8: 0.9030\n",
      "Epoch 237/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2434 - accuracy: 0.9082 - recall_8: 0.9040 - precision_8: 0.9119 - val_loss: 0.2355 - val_accuracy: 0.9213 - val_recall_8: 0.9416 - val_precision_8: 0.9043\n",
      "Epoch 238/500\n",
      "1451/1451 [==============================] - 5s 3ms/step - loss: 0.2458 - accuracy: 0.9069 - recall_8: 0.9015 - precision_8: 0.9115 - val_loss: 0.2372 - val_accuracy: 0.9204 - val_recall_8: 0.9460 - val_precision_8: 0.8994\n",
      "Epoch 239/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2453 - accuracy: 0.9076 - recall_8: 0.9031 - precision_8: 0.9115 - val_loss: 0.2354 - val_accuracy: 0.9220 - val_recall_8: 0.9420 - val_precision_8: 0.9052\n",
      "Epoch 240/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2431 - accuracy: 0.9080 - recall_8: 0.9040 - precision_8: 0.9114 - val_loss: 0.2349 - val_accuracy: 0.9223 - val_recall_8: 0.9426 - val_precision_8: 0.9054\n",
      "Epoch 241/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2437 - accuracy: 0.9077 - recall_8: 0.9026 - precision_8: 0.9120 - val_loss: 0.2370 - val_accuracy: 0.9220 - val_recall_8: 0.9445 - val_precision_8: 0.9034\n",
      "Epoch 242/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2441 - accuracy: 0.9081 - recall_8: 0.9038 - precision_8: 0.9117 - val_loss: 0.2343 - val_accuracy: 0.9225 - val_recall_8: 0.9402 - val_precision_8: 0.9075\n",
      "Epoch 243/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2420 - accuracy: 0.9083 - recall_8: 0.9035 - precision_8: 0.9125 - val_loss: 0.2370 - val_accuracy: 0.9213 - val_recall_8: 0.9482 - val_precision_8: 0.8993\n",
      "Epoch 244/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2421 - accuracy: 0.9095 - recall_8: 0.9048 - precision_8: 0.9136 - val_loss: 0.2364 - val_accuracy: 0.9220 - val_recall_8: 0.9464 - val_precision_8: 0.9019\n",
      "Epoch 245/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2435 - accuracy: 0.9083 - recall_8: 0.9032 - precision_8: 0.9126 - val_loss: 0.2345 - val_accuracy: 0.9211 - val_recall_8: 0.9465 - val_precision_8: 0.9002\n",
      "Epoch 246/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2401 - accuracy: 0.9100 - recall_8: 0.9063 - precision_8: 0.9132 - val_loss: 0.2301 - val_accuracy: 0.9244 - val_recall_8: 0.9400 - val_precision_8: 0.9110\n",
      "Epoch 247/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2413 - accuracy: 0.9096 - recall_8: 0.9062 - precision_8: 0.9126 - val_loss: 0.2337 - val_accuracy: 0.9220 - val_recall_8: 0.9462 - val_precision_8: 0.9020\n",
      "Epoch 248/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2427 - accuracy: 0.9085 - recall_8: 0.9048 - precision_8: 0.9117 - val_loss: 0.2328 - val_accuracy: 0.9231 - val_recall_8: 0.9444 - val_precision_8: 0.9052\n",
      "Epoch 249/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2396 - accuracy: 0.9099 - recall_8: 0.9062 - precision_8: 0.9132 - val_loss: 0.2316 - val_accuracy: 0.9240 - val_recall_8: 0.9433 - val_precision_8: 0.9076\n",
      "Epoch 250/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2403 - accuracy: 0.9095 - recall_8: 0.9061 - precision_8: 0.9124 - val_loss: 0.2346 - val_accuracy: 0.9207 - val_recall_8: 0.9463 - val_precision_8: 0.8997\n",
      "Epoch 251/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2414 - accuracy: 0.9098 - recall_8: 0.9058 - precision_8: 0.9133 - val_loss: 0.2356 - val_accuracy: 0.9232 - val_recall_8: 0.9497 - val_precision_8: 0.9014\n",
      "Epoch 252/500\n",
      "1451/1451 [==============================] - 6s 4ms/step - loss: 0.2388 - accuracy: 0.9115 - recall_8: 0.9085 - precision_8: 0.9141 - val_loss: 0.2319 - val_accuracy: 0.9241 - val_recall_8: 0.9478 - val_precision_8: 0.9043\n",
      "Epoch 253/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2398 - accuracy: 0.9103 - recall_8: 0.9066 - precision_8: 0.9135 - val_loss: 0.2302 - val_accuracy: 0.9241 - val_recall_8: 0.9425 - val_precision_8: 0.9085\n",
      "Epoch 254/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2398 - accuracy: 0.9104 - recall_8: 0.9063 - precision_8: 0.9140 - val_loss: 0.2336 - val_accuracy: 0.9207 - val_recall_8: 0.9482 - val_precision_8: 0.8982\n",
      "Epoch 255/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2401 - accuracy: 0.9097 - recall_8: 0.9067 - precision_8: 0.9123 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_recall_8: 0.9435 - val_precision_8: 0.9075\n",
      "Epoch 256/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2391 - accuracy: 0.9114 - recall_8: 0.9075 - precision_8: 0.9149 - val_loss: 0.2261 - val_accuracy: 0.9264 - val_recall_8: 0.9374 - val_precision_8: 0.9168\n",
      "Epoch 257/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.9112 - recall_8: 0.9074 - precision_8: 0.9145 - val_loss: 0.2314 - val_accuracy: 0.9229 - val_recall_8: 0.9471 - val_precision_8: 0.9029\n",
      "Epoch 258/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2390 - accuracy: 0.9102 - recall_8: 0.9062 - precision_8: 0.9136 - val_loss: 0.2298 - val_accuracy: 0.9243 - val_recall_8: 0.9454 - val_precision_8: 0.9066\n",
      "Epoch 259/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2390 - accuracy: 0.9111 - recall_8: 0.9069 - precision_8: 0.9148 - val_loss: 0.2307 - val_accuracy: 0.9247 - val_recall_8: 0.9471 - val_precision_8: 0.9060\n",
      "Epoch 260/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2381 - accuracy: 0.9105 - recall_8: 0.9065 - precision_8: 0.9139 - val_loss: 0.2312 - val_accuracy: 0.9233 - val_recall_8: 0.9444 - val_precision_8: 0.9057\n",
      "Epoch 261/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2380 - accuracy: 0.9109 - recall_8: 0.9071 - precision_8: 0.9142 - val_loss: 0.2299 - val_accuracy: 0.9247 - val_recall_8: 0.9484 - val_precision_8: 0.9049\n",
      "Epoch 262/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2375 - accuracy: 0.9116 - recall_8: 0.9087 - precision_8: 0.9141 - val_loss: 0.2300 - val_accuracy: 0.9236 - val_recall_8: 0.9497 - val_precision_8: 0.9021\n",
      "Epoch 263/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2384 - accuracy: 0.9121 - recall_8: 0.9096 - precision_8: 0.9144 - val_loss: 0.2290 - val_accuracy: 0.9243 - val_recall_8: 0.9452 - val_precision_8: 0.9067\n",
      "Epoch 264/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2358 - accuracy: 0.9127 - recall_8: 0.9093 - precision_8: 0.9156 - val_loss: 0.2305 - val_accuracy: 0.9227 - val_recall_8: 0.9465 - val_precision_8: 0.9030\n",
      "Epoch 265/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2371 - accuracy: 0.9111 - recall_8: 0.9085 - precision_8: 0.9134 - val_loss: 0.2310 - val_accuracy: 0.9239 - val_recall_8: 0.9497 - val_precision_8: 0.9027\n",
      "Epoch 266/500\n",
      "1451/1451 [==============================] - 4s 3ms/step - loss: 0.2362 - accuracy: 0.9126 - recall_8: 0.9096 - precision_8: 0.9153 - val_loss: 0.2330 - val_accuracy: 0.9228 - val_recall_8: 0.9529 - val_precision_8: 0.8982\n",
      "2902/2902 [==============================] - 3s 1ms/step\n",
      "726/726 [==============================] - 1s 1ms/step\n",
      "Acurácia no conjunto de treinamento: 0.9585285186767578\n",
      "Acurácia no conjunto de teste: 0.926426887512207\n",
      "AUC no conjunto de treinamento: 0.9888849835150342\n",
      "AUC no conjunto de teste: 0.9756561501317572\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.00005)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.00005)))\n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.00005)))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Mantendo a taxa de aprendizado e o tamanho do batch do último ajuste\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Aumentando a paciência no EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Paciência aumentada para permitir mais treinamento\n",
    "\n",
    "# Treinando o modelo com mais épocas\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64,  # Aumento do número de épocas\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 888us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.94      0.92      0.93     11654\n",
      "    Classe 1       0.92      0.94      0.93     11561\n",
      "\n",
      "    accuracy                           0.93     23215\n",
      "   macro avg       0.93      0.93      0.93     23215\n",
      "weighted avg       0.93      0.93      0.93     23215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 832us/step\n",
      "Threshold: 0.10, Precision: 0.723, Recall: 0.994, F1 Score: 0.837, Accuracy: 0.807\n",
      "Threshold: 0.11, Precision: 0.733, Recall: 0.993, F1 Score: 0.843, Accuracy: 0.816\n",
      "Threshold: 0.12, Precision: 0.742, Recall: 0.992, F1 Score: 0.849, Accuracy: 0.824\n",
      "Threshold: 0.13, Precision: 0.751, Recall: 0.991, F1 Score: 0.855, Accuracy: 0.832\n",
      "Threshold: 0.14, Precision: 0.759, Recall: 0.990, F1 Score: 0.859, Accuracy: 0.839\n",
      "Threshold: 0.15, Precision: 0.767, Recall: 0.988, F1 Score: 0.864, Accuracy: 0.845\n",
      "Threshold: 0.16, Precision: 0.774, Recall: 0.988, F1 Score: 0.868, Accuracy: 0.851\n",
      "Threshold: 0.17, Precision: 0.781, Recall: 0.987, F1 Score: 0.872, Accuracy: 0.856\n",
      "Threshold: 0.18, Precision: 0.787, Recall: 0.985, F1 Score: 0.875, Accuracy: 0.860\n",
      "Threshold: 0.19, Precision: 0.795, Recall: 0.984, F1 Score: 0.879, Accuracy: 0.866\n",
      "Threshold: 0.20, Precision: 0.802, Recall: 0.983, F1 Score: 0.883, Accuracy: 0.871\n",
      "Threshold: 0.21, Precision: 0.807, Recall: 0.982, F1 Score: 0.886, Accuracy: 0.875\n",
      "Threshold: 0.22, Precision: 0.813, Recall: 0.981, F1 Score: 0.889, Accuracy: 0.878\n",
      "Threshold: 0.23, Precision: 0.818, Recall: 0.980, F1 Score: 0.892, Accuracy: 0.881\n",
      "Threshold: 0.24, Precision: 0.824, Recall: 0.979, F1 Score: 0.894, Accuracy: 0.885\n",
      "Threshold: 0.25, Precision: 0.830, Recall: 0.978, F1 Score: 0.898, Accuracy: 0.889\n",
      "Threshold: 0.26, Precision: 0.835, Recall: 0.976, F1 Score: 0.900, Accuracy: 0.892\n",
      "Threshold: 0.27, Precision: 0.840, Recall: 0.976, F1 Score: 0.903, Accuracy: 0.895\n",
      "Threshold: 0.28, Precision: 0.845, Recall: 0.974, F1 Score: 0.905, Accuracy: 0.898\n",
      "Threshold: 0.29, Precision: 0.849, Recall: 0.972, F1 Score: 0.907, Accuracy: 0.900\n",
      "Threshold: 0.30, Precision: 0.854, Recall: 0.971, F1 Score: 0.908, Accuracy: 0.902\n",
      "Threshold: 0.31, Precision: 0.857, Recall: 0.970, F1 Score: 0.910, Accuracy: 0.904\n",
      "Threshold: 0.32, Precision: 0.860, Recall: 0.969, F1 Score: 0.911, Accuracy: 0.906\n",
      "Threshold: 0.33, Precision: 0.864, Recall: 0.967, F1 Score: 0.912, Accuracy: 0.907\n",
      "Threshold: 0.34, Precision: 0.868, Recall: 0.966, F1 Score: 0.914, Accuracy: 0.910\n",
      "Threshold: 0.35, Precision: 0.872, Recall: 0.964, F1 Score: 0.915, Accuracy: 0.911\n",
      "Threshold: 0.36, Precision: 0.875, Recall: 0.962, F1 Score: 0.917, Accuracy: 0.913\n",
      "Threshold: 0.37, Precision: 0.879, Recall: 0.960, F1 Score: 0.918, Accuracy: 0.914\n",
      "Threshold: 0.38, Precision: 0.883, Recall: 0.960, F1 Score: 0.920, Accuracy: 0.916\n",
      "Threshold: 0.39, Precision: 0.886, Recall: 0.958, F1 Score: 0.921, Accuracy: 0.918\n",
      "Threshold: 0.40, Precision: 0.890, Recall: 0.957, F1 Score: 0.922, Accuracy: 0.919\n",
      "Threshold: 0.41, Precision: 0.893, Recall: 0.955, F1 Score: 0.923, Accuracy: 0.921\n",
      "Threshold: 0.42, Precision: 0.896, Recall: 0.954, F1 Score: 0.924, Accuracy: 0.922\n",
      "Threshold: 0.43, Precision: 0.900, Recall: 0.952, F1 Score: 0.925, Accuracy: 0.923\n",
      "Threshold: 0.44, Precision: 0.902, Recall: 0.950, F1 Score: 0.926, Accuracy: 0.924\n",
      "Threshold: 0.45, Precision: 0.905, Recall: 0.949, F1 Score: 0.926, Accuracy: 0.925\n",
      "Threshold: 0.46, Precision: 0.908, Recall: 0.946, F1 Score: 0.927, Accuracy: 0.925\n",
      "Threshold: 0.47, Precision: 0.911, Recall: 0.944, F1 Score: 0.927, Accuracy: 0.926\n",
      "Threshold: 0.48, Precision: 0.912, Recall: 0.942, F1 Score: 0.927, Accuracy: 0.926\n",
      "Threshold: 0.49, Precision: 0.914, Recall: 0.939, F1 Score: 0.927, Accuracy: 0.926\n",
      "Threshold: 0.50, Precision: 0.917, Recall: 0.937, F1 Score: 0.927, Accuracy: 0.926\n",
      "Threshold: 0.51, Precision: 0.919, Recall: 0.935, F1 Score: 0.927, Accuracy: 0.926\n",
      "Threshold: 0.52, Precision: 0.920, Recall: 0.932, F1 Score: 0.926, Accuracy: 0.926\n",
      "Threshold: 0.53, Precision: 0.922, Recall: 0.929, F1 Score: 0.925, Accuracy: 0.925\n",
      "Threshold: 0.54, Precision: 0.924, Recall: 0.926, F1 Score: 0.925, Accuracy: 0.925\n",
      "Threshold: 0.55, Precision: 0.926, Recall: 0.923, F1 Score: 0.924, Accuracy: 0.925\n",
      "Threshold: 0.56, Precision: 0.927, Recall: 0.919, F1 Score: 0.923, Accuracy: 0.924\n",
      "Threshold: 0.57, Precision: 0.930, Recall: 0.916, F1 Score: 0.923, Accuracy: 0.924\n",
      "Threshold: 0.58, Precision: 0.932, Recall: 0.913, F1 Score: 0.922, Accuracy: 0.923\n",
      "Threshold: 0.59, Precision: 0.934, Recall: 0.910, F1 Score: 0.922, Accuracy: 0.923\n",
      "Threshold: 0.60, Precision: 0.936, Recall: 0.906, F1 Score: 0.921, Accuracy: 0.922\n",
      "Threshold: 0.61, Precision: 0.938, Recall: 0.902, F1 Score: 0.920, Accuracy: 0.922\n",
      "Threshold: 0.62, Precision: 0.941, Recall: 0.897, F1 Score: 0.919, Accuracy: 0.921\n",
      "Threshold: 0.63, Precision: 0.942, Recall: 0.892, F1 Score: 0.916, Accuracy: 0.919\n",
      "Threshold: 0.64, Precision: 0.944, Recall: 0.887, F1 Score: 0.915, Accuracy: 0.918\n",
      "Threshold: 0.65, Precision: 0.945, Recall: 0.882, F1 Score: 0.913, Accuracy: 0.916\n",
      "Threshold: 0.66, Precision: 0.948, Recall: 0.879, F1 Score: 0.912, Accuracy: 0.916\n",
      "Threshold: 0.67, Precision: 0.950, Recall: 0.873, F1 Score: 0.910, Accuracy: 0.914\n",
      "Threshold: 0.68, Precision: 0.952, Recall: 0.868, F1 Score: 0.908, Accuracy: 0.913\n",
      "Threshold: 0.69, Precision: 0.954, Recall: 0.863, F1 Score: 0.906, Accuracy: 0.911\n",
      "Threshold: 0.70, Precision: 0.955, Recall: 0.856, F1 Score: 0.903, Accuracy: 0.908\n",
      "Threshold: 0.71, Precision: 0.957, Recall: 0.852, F1 Score: 0.901, Accuracy: 0.907\n",
      "Threshold: 0.72, Precision: 0.959, Recall: 0.845, F1 Score: 0.898, Accuracy: 0.905\n",
      "Threshold: 0.73, Precision: 0.959, Recall: 0.839, F1 Score: 0.895, Accuracy: 0.902\n",
      "Threshold: 0.74, Precision: 0.960, Recall: 0.833, F1 Score: 0.892, Accuracy: 0.899\n",
      "Threshold: 0.75, Precision: 0.961, Recall: 0.826, F1 Score: 0.889, Accuracy: 0.897\n",
      "Threshold: 0.76, Precision: 0.963, Recall: 0.819, F1 Score: 0.885, Accuracy: 0.894\n",
      "Threshold: 0.77, Precision: 0.964, Recall: 0.811, F1 Score: 0.881, Accuracy: 0.891\n",
      "Threshold: 0.78, Precision: 0.965, Recall: 0.805, F1 Score: 0.878, Accuracy: 0.888\n",
      "Threshold: 0.79, Precision: 0.967, Recall: 0.797, F1 Score: 0.874, Accuracy: 0.885\n",
      "Threshold: 0.80, Precision: 0.968, Recall: 0.788, F1 Score: 0.869, Accuracy: 0.882\n",
      "Threshold: 0.81, Precision: 0.969, Recall: 0.780, F1 Score: 0.864, Accuracy: 0.878\n",
      "Threshold: 0.82, Precision: 0.970, Recall: 0.771, F1 Score: 0.859, Accuracy: 0.874\n",
      "Threshold: 0.83, Precision: 0.971, Recall: 0.760, F1 Score: 0.853, Accuracy: 0.870\n",
      "Threshold: 0.84, Precision: 0.972, Recall: 0.750, F1 Score: 0.847, Accuracy: 0.865\n",
      "Threshold: 0.85, Precision: 0.974, Recall: 0.737, F1 Score: 0.839, Accuracy: 0.860\n",
      "Threshold: 0.86, Precision: 0.976, Recall: 0.724, F1 Score: 0.831, Accuracy: 0.854\n",
      "Threshold: 0.87, Precision: 0.976, Recall: 0.710, F1 Score: 0.822, Accuracy: 0.847\n",
      "Threshold: 0.88, Precision: 0.978, Recall: 0.699, F1 Score: 0.815, Accuracy: 0.842\n",
      "Threshold: 0.89, Precision: 0.978, Recall: 0.685, F1 Score: 0.806, Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
