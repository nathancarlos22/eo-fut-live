{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'blockedShotsHome',\n",
       "       'blockedShotsAway', 'league', 'corners_home', 'corners_away',\n",
       "       'shotsOffgoal_home', 'shotsOffgoal_away', 'shotsOngoal_home',\n",
       "       'shotsOngoal_away', 'yellowcards_home', 'yellowcards_away',\n",
       "       'fouls_home', 'fouls_away', 'offsides_home', 'offsides_away',\n",
       "       'tackles_home', 'tackles_away', 'result', 'match_id',\n",
       "       'possessiontime_away', 'possessiontime_home', 'shotsOnGoalEfficiency',\n",
       "       'attackPressure', 'shotAccuracy_home', 'shotAccuracy_away',\n",
       "       'possessionControl', 'passRisk', 'defensiveDiscipline',\n",
       "       'defensiveEfficacy', 'defensiveAggression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "965/965 [==============================] - 4s 3ms/step - loss: 0.6900 - accuracy: 0.5326 - recall: 0.5255 - precision: 0.5333 - auc: 0.5468 - val_loss: 0.6861 - val_accuracy: 0.5473 - val_recall: 0.5082 - val_precision: 0.5505 - val_auc: 0.5682\n",
      "Epoch 2/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6840 - accuracy: 0.5493 - recall: 0.5732 - precision: 0.5472 - auc: 0.5727 - val_loss: 0.6798 - val_accuracy: 0.5558 - val_recall: 0.5662 - val_precision: 0.5539 - val_auc: 0.5856\n",
      "Epoch 3/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.5640 - recall: 0.6078 - precision: 0.5590 - auc: 0.5961 - val_loss: 0.6706 - val_accuracy: 0.5788 - val_recall: 0.5927 - val_precision: 0.5760 - val_auc: 0.6148\n",
      "Epoch 4/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6679 - accuracy: 0.5786 - recall: 0.6063 - precision: 0.5746 - auc: 0.6180 - val_loss: 0.6592 - val_accuracy: 0.5929 - val_recall: 0.5873 - val_precision: 0.5932 - val_auc: 0.6379\n",
      "Epoch 5/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6575 - accuracy: 0.5935 - recall: 0.6286 - precision: 0.5875 - auc: 0.6404 - val_loss: 0.6464 - val_accuracy: 0.6117 - val_recall: 0.5388 - val_precision: 0.6299 - val_auc: 0.6688\n",
      "Epoch 6/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6472 - accuracy: 0.6066 - recall: 0.6247 - precision: 0.6030 - auc: 0.6586 - val_loss: 0.6331 - val_accuracy: 0.6221 - val_recall: 0.6741 - val_precision: 0.6100 - val_auc: 0.6858\n",
      "Epoch 7/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6367 - accuracy: 0.6185 - recall: 0.6399 - precision: 0.6138 - auc: 0.6765 - val_loss: 0.6283 - val_accuracy: 0.6383 - val_recall: 0.6943 - val_precision: 0.6238 - val_auc: 0.7041\n",
      "Epoch 8/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6286 - accuracy: 0.6295 - recall: 0.6502 - precision: 0.6245 - auc: 0.6898 - val_loss: 0.6184 - val_accuracy: 0.6434 - val_recall: 0.6648 - val_precision: 0.6369 - val_auc: 0.7133\n",
      "Epoch 9/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6198 - accuracy: 0.6355 - recall: 0.6520 - precision: 0.6314 - auc: 0.7015 - val_loss: 0.6055 - val_accuracy: 0.6593 - val_recall: 0.6287 - val_precision: 0.6689 - val_auc: 0.7335\n",
      "Epoch 10/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6122 - accuracy: 0.6450 - recall: 0.6623 - precision: 0.6403 - auc: 0.7124 - val_loss: 0.5934 - val_accuracy: 0.6657 - val_recall: 0.7096 - val_precision: 0.6517 - val_auc: 0.7441\n",
      "Epoch 11/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.6038 - accuracy: 0.6535 - recall: 0.6714 - precision: 0.6484 - auc: 0.7238 - val_loss: 0.5901 - val_accuracy: 0.6706 - val_recall: 0.6841 - val_precision: 0.6655 - val_auc: 0.7500\n",
      "Epoch 12/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5990 - accuracy: 0.6565 - recall: 0.6736 - precision: 0.6514 - auc: 0.7289 - val_loss: 0.5778 - val_accuracy: 0.6817 - val_recall: 0.6289 - val_precision: 0.7023 - val_auc: 0.7669\n",
      "Epoch 13/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.5924 - accuracy: 0.6649 - recall: 0.6794 - precision: 0.6605 - auc: 0.7383 - val_loss: 0.5719 - val_accuracy: 0.6873 - val_recall: 0.6519 - val_precision: 0.7008 - val_auc: 0.7733\n",
      "Epoch 14/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5870 - accuracy: 0.6670 - recall: 0.6871 - precision: 0.6607 - auc: 0.7436 - val_loss: 0.5666 - val_accuracy: 0.6896 - val_recall: 0.7836 - val_precision: 0.6591 - val_auc: 0.7764\n",
      "Epoch 15/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.6713 - recall: 0.6928 - precision: 0.6644 - auc: 0.7492 - val_loss: 0.5607 - val_accuracy: 0.6960 - val_recall: 0.7000 - val_precision: 0.6938 - val_auc: 0.7835\n",
      "Epoch 16/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.6755 - recall: 0.6967 - precision: 0.6685 - auc: 0.7548 - val_loss: 0.5551 - val_accuracy: 0.7026 - val_recall: 0.7624 - val_precision: 0.6804 - val_auc: 0.7905\n",
      "Epoch 17/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5742 - accuracy: 0.6782 - recall: 0.7035 - precision: 0.6698 - auc: 0.7581 - val_loss: 0.5457 - val_accuracy: 0.7094 - val_recall: 0.7285 - val_precision: 0.7011 - val_auc: 0.7979\n",
      "Epoch 18/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5690 - accuracy: 0.6827 - recall: 0.7008 - precision: 0.6765 - auc: 0.7642 - val_loss: 0.5465 - val_accuracy: 0.7126 - val_recall: 0.7394 - val_precision: 0.7012 - val_auc: 0.7998\n",
      "Epoch 19/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5674 - accuracy: 0.6861 - recall: 0.7048 - precision: 0.6795 - auc: 0.7665 - val_loss: 0.5427 - val_accuracy: 0.7147 - val_recall: 0.7618 - val_precision: 0.6957 - val_auc: 0.8036\n",
      "Epoch 20/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5618 - accuracy: 0.6910 - recall: 0.7077 - precision: 0.6850 - auc: 0.7723 - val_loss: 0.5362 - val_accuracy: 0.7178 - val_recall: 0.6959 - val_precision: 0.7271 - val_auc: 0.8077\n",
      "Epoch 21/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5600 - accuracy: 0.6920 - recall: 0.7085 - precision: 0.6860 - auc: 0.7742 - val_loss: 0.5331 - val_accuracy: 0.7218 - val_recall: 0.7858 - val_precision: 0.6961 - val_auc: 0.8125\n",
      "Epoch 22/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5573 - accuracy: 0.6935 - recall: 0.7119 - precision: 0.6867 - auc: 0.7766 - val_loss: 0.5328 - val_accuracy: 0.7245 - val_recall: 0.7295 - val_precision: 0.7217 - val_auc: 0.8147\n",
      "Epoch 23/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5552 - accuracy: 0.6945 - recall: 0.7116 - precision: 0.6882 - auc: 0.7788 - val_loss: 0.5260 - val_accuracy: 0.7284 - val_recall: 0.7651 - val_precision: 0.7122 - val_auc: 0.8187\n",
      "Epoch 24/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5517 - accuracy: 0.6975 - recall: 0.7164 - precision: 0.6905 - auc: 0.7828 - val_loss: 0.5282 - val_accuracy: 0.7258 - val_recall: 0.7488 - val_precision: 0.7153 - val_auc: 0.8168\n",
      "Epoch 25/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.6982 - recall: 0.7126 - precision: 0.6928 - auc: 0.7828 - val_loss: 0.5247 - val_accuracy: 0.7283 - val_recall: 0.7548 - val_precision: 0.7163 - val_auc: 0.8198\n",
      "Epoch 26/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7046 - recall: 0.7199 - precision: 0.6987 - auc: 0.7895 - val_loss: 0.5195 - val_accuracy: 0.7330 - val_recall: 0.7626 - val_precision: 0.7194 - val_auc: 0.8246\n",
      "Epoch 27/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7036 - recall: 0.7167 - precision: 0.6985 - auc: 0.7895 - val_loss: 0.5180 - val_accuracy: 0.7312 - val_recall: 0.7441 - val_precision: 0.7247 - val_auc: 0.8238\n",
      "Epoch 28/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7073 - recall: 0.7253 - precision: 0.7003 - auc: 0.7936 - val_loss: 0.5126 - val_accuracy: 0.7365 - val_recall: 0.7753 - val_precision: 0.7189 - val_auc: 0.8301\n",
      "Epoch 29/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7091 - recall: 0.7250 - precision: 0.7028 - auc: 0.7947 - val_loss: 0.5092 - val_accuracy: 0.7400 - val_recall: 0.7952 - val_precision: 0.7156 - val_auc: 0.8327\n",
      "Epoch 30/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7077 - recall: 0.7281 - precision: 0.6996 - auc: 0.7944 - val_loss: 0.5082 - val_accuracy: 0.7428 - val_recall: 0.7480 - val_precision: 0.7397 - val_auc: 0.8346\n",
      "Epoch 31/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7108 - recall: 0.7308 - precision: 0.7028 - auc: 0.7976 - val_loss: 0.5070 - val_accuracy: 0.7439 - val_recall: 0.8008 - val_precision: 0.7184 - val_auc: 0.8345\n",
      "Epoch 32/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7098 - recall: 0.7301 - precision: 0.7017 - auc: 0.7964 - val_loss: 0.5044 - val_accuracy: 0.7456 - val_recall: 0.7688 - val_precision: 0.7342 - val_auc: 0.8373\n",
      "Epoch 33/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.5328 - accuracy: 0.7137 - recall: 0.7332 - precision: 0.7058 - auc: 0.8004 - val_loss: 0.5030 - val_accuracy: 0.7454 - val_recall: 0.7470 - val_precision: 0.7441 - val_auc: 0.8390\n",
      "Epoch 34/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.5322 - accuracy: 0.7130 - recall: 0.7313 - precision: 0.7057 - auc: 0.8010 - val_loss: 0.5004 - val_accuracy: 0.7451 - val_recall: 0.7781 - val_precision: 0.7293 - val_auc: 0.8385\n",
      "Epoch 35/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.5287 - accuracy: 0.7169 - recall: 0.7325 - precision: 0.7105 - auc: 0.8047 - val_loss: 0.4948 - val_accuracy: 0.7506 - val_recall: 0.8177 - val_precision: 0.7204 - val_auc: 0.8435\n",
      "Epoch 36/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.7163 - recall: 0.7263 - precision: 0.7122 - auc: 0.8043 - val_loss: 0.4964 - val_accuracy: 0.7487 - val_recall: 0.7696 - val_precision: 0.7382 - val_auc: 0.8428\n",
      "Epoch 37/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5259 - accuracy: 0.7193 - recall: 0.7346 - precision: 0.7130 - auc: 0.8068 - val_loss: 0.4952 - val_accuracy: 0.7517 - val_recall: 0.7906 - val_precision: 0.7330 - val_auc: 0.8443\n",
      "Epoch 38/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5250 - accuracy: 0.7183 - recall: 0.7347 - precision: 0.7115 - auc: 0.8072 - val_loss: 0.4933 - val_accuracy: 0.7537 - val_recall: 0.7740 - val_precision: 0.7433 - val_auc: 0.8468\n",
      "Epoch 39/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5245 - accuracy: 0.7206 - recall: 0.7363 - precision: 0.7140 - auc: 0.8086 - val_loss: 0.4920 - val_accuracy: 0.7520 - val_recall: 0.7576 - val_precision: 0.7486 - val_auc: 0.8474\n",
      "Epoch 40/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5217 - accuracy: 0.7199 - recall: 0.7367 - precision: 0.7129 - auc: 0.8102 - val_loss: 0.4885 - val_accuracy: 0.7529 - val_recall: 0.8120 - val_precision: 0.7257 - val_auc: 0.8486\n",
      "Epoch 41/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5197 - accuracy: 0.7242 - recall: 0.7413 - precision: 0.7169 - auc: 0.8128 - val_loss: 0.4899 - val_accuracy: 0.7544 - val_recall: 0.7982 - val_precision: 0.7334 - val_auc: 0.8478\n",
      "Epoch 42/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5188 - accuracy: 0.7238 - recall: 0.7433 - precision: 0.7156 - auc: 0.8134 - val_loss: 0.4886 - val_accuracy: 0.7564 - val_recall: 0.7854 - val_precision: 0.7418 - val_auc: 0.8498\n",
      "Epoch 43/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5186 - accuracy: 0.7231 - recall: 0.7405 - precision: 0.7157 - auc: 0.8131 - val_loss: 0.4891 - val_accuracy: 0.7553 - val_recall: 0.8252 - val_precision: 0.7236 - val_auc: 0.8496\n",
      "Epoch 44/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5188 - accuracy: 0.7240 - recall: 0.7387 - precision: 0.7178 - auc: 0.8138 - val_loss: 0.4838 - val_accuracy: 0.7591 - val_recall: 0.7567 - val_precision: 0.7597 - val_auc: 0.8526\n",
      "Epoch 45/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5142 - accuracy: 0.7280 - recall: 0.7428 - precision: 0.7216 - auc: 0.8176 - val_loss: 0.4848 - val_accuracy: 0.7588 - val_recall: 0.8182 - val_precision: 0.7309 - val_auc: 0.8519\n",
      "Epoch 46/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5140 - accuracy: 0.7275 - recall: 0.7420 - precision: 0.7212 - auc: 0.8172 - val_loss: 0.4822 - val_accuracy: 0.7639 - val_recall: 0.7746 - val_precision: 0.7578 - val_auc: 0.8550\n",
      "Epoch 47/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5133 - accuracy: 0.7283 - recall: 0.7473 - precision: 0.7201 - auc: 0.8181 - val_loss: 0.4812 - val_accuracy: 0.7606 - val_recall: 0.8185 - val_precision: 0.7331 - val_auc: 0.8550\n",
      "Epoch 48/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5110 - accuracy: 0.7286 - recall: 0.7453 - precision: 0.7213 - auc: 0.8200 - val_loss: 0.4823 - val_accuracy: 0.7585 - val_recall: 0.8080 - val_precision: 0.7348 - val_auc: 0.8539\n",
      "Epoch 49/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5118 - accuracy: 0.7300 - recall: 0.7495 - precision: 0.7215 - auc: 0.8200 - val_loss: 0.4789 - val_accuracy: 0.7630 - val_recall: 0.7887 - val_precision: 0.7497 - val_auc: 0.8567\n",
      "Epoch 50/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5110 - accuracy: 0.7307 - recall: 0.7498 - precision: 0.7223 - auc: 0.8201 - val_loss: 0.4765 - val_accuracy: 0.7649 - val_recall: 0.7764 - val_precision: 0.7585 - val_auc: 0.8581\n",
      "Epoch 51/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5092 - accuracy: 0.7311 - recall: 0.7508 - precision: 0.7225 - auc: 0.8213 - val_loss: 0.4785 - val_accuracy: 0.7625 - val_recall: 0.8116 - val_precision: 0.7386 - val_auc: 0.8577\n",
      "Epoch 52/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5091 - accuracy: 0.7315 - recall: 0.7496 - precision: 0.7236 - auc: 0.8219 - val_loss: 0.4723 - val_accuracy: 0.7646 - val_recall: 0.7945 - val_precision: 0.7491 - val_auc: 0.8598\n",
      "Epoch 53/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5070 - accuracy: 0.7337 - recall: 0.7495 - precision: 0.7266 - auc: 0.8237 - val_loss: 0.4750 - val_accuracy: 0.7646 - val_recall: 0.7789 - val_precision: 0.7567 - val_auc: 0.8593\n",
      "Epoch 54/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.7315 - recall: 0.7447 - precision: 0.7257 - auc: 0.8222 - val_loss: 0.4774 - val_accuracy: 0.7648 - val_recall: 0.7996 - val_precision: 0.7470 - val_auc: 0.8590\n",
      "Epoch 55/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5062 - accuracy: 0.7334 - recall: 0.7465 - precision: 0.7276 - auc: 0.8239 - val_loss: 0.4723 - val_accuracy: 0.7673 - val_recall: 0.7758 - val_precision: 0.7623 - val_auc: 0.8613\n",
      "Epoch 56/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5050 - accuracy: 0.7351 - recall: 0.7519 - precision: 0.7276 - auc: 0.8254 - val_loss: 0.4703 - val_accuracy: 0.7695 - val_recall: 0.8273 - val_precision: 0.7412 - val_auc: 0.8641\n",
      "Epoch 57/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5026 - accuracy: 0.7363 - recall: 0.7541 - precision: 0.7282 - auc: 0.8270 - val_loss: 0.4700 - val_accuracy: 0.7676 - val_recall: 0.7642 - val_precision: 0.7689 - val_auc: 0.8631\n",
      "Epoch 58/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5029 - accuracy: 0.7367 - recall: 0.7526 - precision: 0.7295 - auc: 0.8270 - val_loss: 0.4749 - val_accuracy: 0.7648 - val_recall: 0.8420 - val_precision: 0.7289 - val_auc: 0.8618\n",
      "Epoch 59/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5010 - accuracy: 0.7369 - recall: 0.7561 - precision: 0.7283 - auc: 0.8284 - val_loss: 0.4696 - val_accuracy: 0.7687 - val_recall: 0.7850 - val_precision: 0.7596 - val_auc: 0.8647\n",
      "Epoch 60/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5016 - accuracy: 0.7371 - recall: 0.7558 - precision: 0.7286 - auc: 0.8281 - val_loss: 0.4697 - val_accuracy: 0.7695 - val_recall: 0.8121 - val_precision: 0.7479 - val_auc: 0.8633\n",
      "Epoch 61/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.7361 - recall: 0.7558 - precision: 0.7272 - auc: 0.8275 - val_loss: 0.4684 - val_accuracy: 0.7690 - val_recall: 0.8229 - val_precision: 0.7423 - val_auc: 0.8638\n",
      "Epoch 62/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4999 - accuracy: 0.7376 - recall: 0.7574 - precision: 0.7286 - auc: 0.8293 - val_loss: 0.4669 - val_accuracy: 0.7690 - val_recall: 0.7698 - val_precision: 0.7680 - val_auc: 0.8632\n",
      "Epoch 63/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.5005 - accuracy: 0.7378 - recall: 0.7519 - precision: 0.7314 - auc: 0.8290 - val_loss: 0.4684 - val_accuracy: 0.7708 - val_recall: 0.8168 - val_precision: 0.7476 - val_auc: 0.8648\n",
      "Epoch 64/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.7400 - recall: 0.7534 - precision: 0.7338 - auc: 0.8315 - val_loss: 0.4643 - val_accuracy: 0.7717 - val_recall: 0.7737 - val_precision: 0.7701 - val_auc: 0.8659\n",
      "Epoch 65/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4981 - accuracy: 0.7391 - recall: 0.7576 - precision: 0.7307 - auc: 0.8307 - val_loss: 0.4682 - val_accuracy: 0.7674 - val_recall: 0.8371 - val_precision: 0.7343 - val_auc: 0.8645\n",
      "Epoch 66/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4989 - accuracy: 0.7386 - recall: 0.7520 - precision: 0.7325 - auc: 0.8301 - val_loss: 0.4612 - val_accuracy: 0.7739 - val_recall: 0.8304 - val_precision: 0.7457 - val_auc: 0.8689\n",
      "Epoch 67/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7407 - recall: 0.7596 - precision: 0.7320 - auc: 0.8324 - val_loss: 0.4664 - val_accuracy: 0.7699 - val_recall: 0.8459 - val_precision: 0.7339 - val_auc: 0.8660\n",
      "Epoch 68/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7399 - recall: 0.7560 - precision: 0.7325 - auc: 0.8322 - val_loss: 0.4632 - val_accuracy: 0.7728 - val_recall: 0.8142 - val_precision: 0.7515 - val_auc: 0.8672\n",
      "Epoch 69/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.7405 - recall: 0.7541 - precision: 0.7342 - auc: 0.8322 - val_loss: 0.4620 - val_accuracy: 0.7748 - val_recall: 0.7846 - val_precision: 0.7691 - val_auc: 0.8691\n",
      "Epoch 70/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4932 - accuracy: 0.7443 - recall: 0.7615 - precision: 0.7363 - auc: 0.8347 - val_loss: 0.4591 - val_accuracy: 0.7716 - val_recall: 0.8408 - val_precision: 0.7381 - val_auc: 0.8689\n",
      "Epoch 71/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4938 - accuracy: 0.7406 - recall: 0.7579 - precision: 0.7328 - auc: 0.8336 - val_loss: 0.4621 - val_accuracy: 0.7743 - val_recall: 0.8493 - val_precision: 0.7381 - val_auc: 0.8705\n",
      "Epoch 72/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7422 - recall: 0.7596 - precision: 0.7342 - auc: 0.8337 - val_loss: 0.4589 - val_accuracy: 0.7742 - val_recall: 0.8092 - val_precision: 0.7558 - val_auc: 0.8696\n",
      "Epoch 73/500\n",
      "965/965 [==============================] - 4s 4ms/step - loss: 0.4915 - accuracy: 0.7431 - recall: 0.7620 - precision: 0.7345 - auc: 0.8360 - val_loss: 0.4609 - val_accuracy: 0.7734 - val_recall: 0.8357 - val_precision: 0.7426 - val_auc: 0.8698\n",
      "Epoch 74/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4927 - accuracy: 0.7442 - recall: 0.7624 - precision: 0.7358 - auc: 0.8352 - val_loss: 0.4588 - val_accuracy: 0.7739 - val_recall: 0.8455 - val_precision: 0.7391 - val_auc: 0.8718\n",
      "Epoch 75/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4922 - accuracy: 0.7440 - recall: 0.7573 - precision: 0.7378 - auc: 0.8358 - val_loss: 0.4575 - val_accuracy: 0.7759 - val_recall: 0.8115 - val_precision: 0.7571 - val_auc: 0.8719\n",
      "Epoch 76/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4934 - accuracy: 0.7422 - recall: 0.7568 - precision: 0.7355 - auc: 0.8346 - val_loss: 0.4591 - val_accuracy: 0.7794 - val_recall: 0.8046 - val_precision: 0.7655 - val_auc: 0.8733\n",
      "Epoch 77/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.7444 - recall: 0.7641 - precision: 0.7353 - auc: 0.8370 - val_loss: 0.4545 - val_accuracy: 0.7773 - val_recall: 0.8139 - val_precision: 0.7579 - val_auc: 0.8727\n",
      "Epoch 78/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4907 - accuracy: 0.7450 - recall: 0.7592 - precision: 0.7384 - auc: 0.8367 - val_loss: 0.4601 - val_accuracy: 0.7769 - val_recall: 0.8105 - val_precision: 0.7589 - val_auc: 0.8713\n",
      "Epoch 79/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4895 - accuracy: 0.7449 - recall: 0.7629 - precision: 0.7365 - auc: 0.8376 - val_loss: 0.4577 - val_accuracy: 0.7767 - val_recall: 0.7965 - val_precision: 0.7656 - val_auc: 0.8706\n",
      "Epoch 80/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4889 - accuracy: 0.7450 - recall: 0.7555 - precision: 0.7400 - auc: 0.8379 - val_loss: 0.4534 - val_accuracy: 0.7787 - val_recall: 0.8196 - val_precision: 0.7572 - val_auc: 0.8736\n",
      "Epoch 81/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4878 - accuracy: 0.7468 - recall: 0.7587 - precision: 0.7413 - auc: 0.8390 - val_loss: 0.4573 - val_accuracy: 0.7769 - val_recall: 0.8359 - val_precision: 0.7472 - val_auc: 0.8731\n",
      "Epoch 82/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4876 - accuracy: 0.7478 - recall: 0.7630 - precision: 0.7407 - auc: 0.8395 - val_loss: 0.4561 - val_accuracy: 0.7782 - val_recall: 0.8321 - val_precision: 0.7507 - val_auc: 0.8738\n",
      "Epoch 83/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.7463 - recall: 0.7588 - precision: 0.7405 - auc: 0.8387 - val_loss: 0.4532 - val_accuracy: 0.7800 - val_recall: 0.7987 - val_precision: 0.7695 - val_auc: 0.8751\n",
      "Epoch 84/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4883 - accuracy: 0.7470 - recall: 0.7630 - precision: 0.7395 - auc: 0.8388 - val_loss: 0.4527 - val_accuracy: 0.7792 - val_recall: 0.8634 - val_precision: 0.7385 - val_auc: 0.8748\n",
      "Epoch 85/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4845 - accuracy: 0.7461 - recall: 0.7656 - precision: 0.7370 - auc: 0.8407 - val_loss: 0.4538 - val_accuracy: 0.7775 - val_recall: 0.8270 - val_precision: 0.7521 - val_auc: 0.8740\n",
      "Epoch 86/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4862 - accuracy: 0.7476 - recall: 0.7606 - precision: 0.7415 - auc: 0.8401 - val_loss: 0.4511 - val_accuracy: 0.7807 - val_recall: 0.8149 - val_precision: 0.7623 - val_auc: 0.8750\n",
      "Epoch 87/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4834 - accuracy: 0.7489 - recall: 0.7629 - precision: 0.7422 - auc: 0.8420 - val_loss: 0.4494 - val_accuracy: 0.7798 - val_recall: 0.7675 - val_precision: 0.7864 - val_auc: 0.8747\n",
      "Epoch 88/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.7492 - recall: 0.7619 - precision: 0.7432 - auc: 0.8414 - val_loss: 0.4514 - val_accuracy: 0.7804 - val_recall: 0.7793 - val_precision: 0.7805 - val_auc: 0.8755\n",
      "Epoch 89/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4832 - accuracy: 0.7505 - recall: 0.7598 - precision: 0.7461 - auc: 0.8427 - val_loss: 0.4517 - val_accuracy: 0.7813 - val_recall: 0.8370 - val_precision: 0.7527 - val_auc: 0.8758\n",
      "Epoch 90/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.7513 - recall: 0.7646 - precision: 0.7450 - auc: 0.8439 - val_loss: 0.4504 - val_accuracy: 0.7793 - val_recall: 0.8638 - val_precision: 0.7384 - val_auc: 0.8768\n",
      "Epoch 91/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4835 - accuracy: 0.7492 - recall: 0.7646 - precision: 0.7419 - auc: 0.8423 - val_loss: 0.4496 - val_accuracy: 0.7826 - val_recall: 0.8094 - val_precision: 0.7677 - val_auc: 0.8769\n",
      "Epoch 92/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4825 - accuracy: 0.7517 - recall: 0.7643 - precision: 0.7456 - auc: 0.8433 - val_loss: 0.4515 - val_accuracy: 0.7798 - val_recall: 0.8290 - val_precision: 0.7542 - val_auc: 0.8761\n",
      "Epoch 93/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.7508 - recall: 0.7638 - precision: 0.7445 - auc: 0.8437 - val_loss: 0.4480 - val_accuracy: 0.7843 - val_recall: 0.8035 - val_precision: 0.7733 - val_auc: 0.8777\n",
      "Epoch 94/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4822 - accuracy: 0.7498 - recall: 0.7642 - precision: 0.7430 - auc: 0.8433 - val_loss: 0.4526 - val_accuracy: 0.7806 - val_recall: 0.8493 - val_precision: 0.7462 - val_auc: 0.8764\n",
      "Epoch 95/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4834 - accuracy: 0.7505 - recall: 0.7691 - precision: 0.7416 - auc: 0.8427 - val_loss: 0.4485 - val_accuracy: 0.7815 - val_recall: 0.8355 - val_precision: 0.7536 - val_auc: 0.8773\n",
      "Epoch 96/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4800 - accuracy: 0.7525 - recall: 0.7706 - precision: 0.7438 - auc: 0.8451 - val_loss: 0.4480 - val_accuracy: 0.7821 - val_recall: 0.8326 - val_precision: 0.7557 - val_auc: 0.8773\n",
      "Epoch 97/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4798 - accuracy: 0.7518 - recall: 0.7677 - precision: 0.7441 - auc: 0.8449 - val_loss: 0.4472 - val_accuracy: 0.7871 - val_recall: 0.7870 - val_precision: 0.7866 - val_auc: 0.8794\n",
      "Epoch 98/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4790 - accuracy: 0.7542 - recall: 0.7707 - precision: 0.7462 - auc: 0.8458 - val_loss: 0.4453 - val_accuracy: 0.7828 - val_recall: 0.8481 - val_precision: 0.7497 - val_auc: 0.8802\n",
      "Epoch 99/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4783 - accuracy: 0.7538 - recall: 0.7731 - precision: 0.7445 - auc: 0.8464 - val_loss: 0.4445 - val_accuracy: 0.7821 - val_recall: 0.8624 - val_precision: 0.7427 - val_auc: 0.8796\n",
      "Epoch 100/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4793 - accuracy: 0.7525 - recall: 0.7653 - precision: 0.7463 - auc: 0.8454 - val_loss: 0.4468 - val_accuracy: 0.7852 - val_recall: 0.8496 - val_precision: 0.7522 - val_auc: 0.8800\n",
      "Epoch 101/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4794 - accuracy: 0.7520 - recall: 0.7682 - precision: 0.7443 - auc: 0.8454 - val_loss: 0.4458 - val_accuracy: 0.7864 - val_recall: 0.8288 - val_precision: 0.7636 - val_auc: 0.8799\n",
      "Epoch 102/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4798 - accuracy: 0.7527 - recall: 0.7646 - precision: 0.7469 - auc: 0.8451 - val_loss: 0.4459 - val_accuracy: 0.7860 - val_recall: 0.8488 - val_precision: 0.7536 - val_auc: 0.8806\n",
      "Epoch 103/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4773 - accuracy: 0.7545 - recall: 0.7696 - precision: 0.7471 - auc: 0.8471 - val_loss: 0.4433 - val_accuracy: 0.7849 - val_recall: 0.8429 - val_precision: 0.7548 - val_auc: 0.8805\n",
      "Epoch 104/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4769 - accuracy: 0.7554 - recall: 0.7732 - precision: 0.7467 - auc: 0.8475 - val_loss: 0.4436 - val_accuracy: 0.7875 - val_recall: 0.8039 - val_precision: 0.7778 - val_auc: 0.8807\n",
      "Epoch 105/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4773 - accuracy: 0.7543 - recall: 0.7686 - precision: 0.7474 - auc: 0.8470 - val_loss: 0.4431 - val_accuracy: 0.7872 - val_recall: 0.8134 - val_precision: 0.7724 - val_auc: 0.8814\n",
      "Epoch 106/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4769 - accuracy: 0.7565 - recall: 0.7657 - precision: 0.7520 - auc: 0.8477 - val_loss: 0.4470 - val_accuracy: 0.7843 - val_recall: 0.8103 - val_precision: 0.7698 - val_auc: 0.8793\n",
      "Epoch 107/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4774 - accuracy: 0.7560 - recall: 0.7682 - precision: 0.7500 - auc: 0.8478 - val_loss: 0.4406 - val_accuracy: 0.7852 - val_recall: 0.8179 - val_precision: 0.7671 - val_auc: 0.8812\n",
      "Epoch 108/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4769 - accuracy: 0.7560 - recall: 0.7712 - precision: 0.7486 - auc: 0.8476 - val_loss: 0.4435 - val_accuracy: 0.7869 - val_recall: 0.8279 - val_precision: 0.7648 - val_auc: 0.8810\n",
      "Epoch 109/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4753 - accuracy: 0.7559 - recall: 0.7712 - precision: 0.7484 - auc: 0.8485 - val_loss: 0.4459 - val_accuracy: 0.7852 - val_recall: 0.8628 - val_precision: 0.7464 - val_auc: 0.8812\n",
      "Epoch 110/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4747 - accuracy: 0.7559 - recall: 0.7690 - precision: 0.7495 - auc: 0.8490 - val_loss: 0.4426 - val_accuracy: 0.7875 - val_recall: 0.8399 - val_precision: 0.7597 - val_auc: 0.8825\n",
      "Epoch 111/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4762 - accuracy: 0.7559 - recall: 0.7704 - precision: 0.7489 - auc: 0.8483 - val_loss: 0.4403 - val_accuracy: 0.7891 - val_recall: 0.8359 - val_precision: 0.7639 - val_auc: 0.8834\n",
      "Epoch 112/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4761 - accuracy: 0.7567 - recall: 0.7681 - precision: 0.7511 - auc: 0.8484 - val_loss: 0.4432 - val_accuracy: 0.7852 - val_recall: 0.8527 - val_precision: 0.7508 - val_auc: 0.8819\n",
      "Epoch 113/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4755 - accuracy: 0.7545 - recall: 0.7701 - precision: 0.7470 - auc: 0.8483 - val_loss: 0.4443 - val_accuracy: 0.7855 - val_recall: 0.8494 - val_precision: 0.7528 - val_auc: 0.8817\n",
      "Epoch 114/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4750 - accuracy: 0.7564 - recall: 0.7730 - precision: 0.7483 - auc: 0.8491 - val_loss: 0.4407 - val_accuracy: 0.7888 - val_recall: 0.8280 - val_precision: 0.7673 - val_auc: 0.8829\n",
      "Epoch 115/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4740 - accuracy: 0.7565 - recall: 0.7668 - precision: 0.7514 - auc: 0.8497 - val_loss: 0.4384 - val_accuracy: 0.7863 - val_recall: 0.8587 - val_precision: 0.7496 - val_auc: 0.8837\n",
      "Epoch 116/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4730 - accuracy: 0.7581 - recall: 0.7732 - precision: 0.7506 - auc: 0.8503 - val_loss: 0.4380 - val_accuracy: 0.7883 - val_recall: 0.7905 - val_precision: 0.7865 - val_auc: 0.8817\n",
      "Epoch 117/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4734 - accuracy: 0.7566 - recall: 0.7702 - precision: 0.7499 - auc: 0.8499 - val_loss: 0.4386 - val_accuracy: 0.7890 - val_recall: 0.8050 - val_precision: 0.7796 - val_auc: 0.8834\n",
      "Epoch 118/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4734 - accuracy: 0.7579 - recall: 0.7689 - precision: 0.7525 - auc: 0.8505 - val_loss: 0.4375 - val_accuracy: 0.7876 - val_recall: 0.8350 - val_precision: 0.7623 - val_auc: 0.8829\n",
      "Epoch 119/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4725 - accuracy: 0.7591 - recall: 0.7711 - precision: 0.7531 - auc: 0.8511 - val_loss: 0.4360 - val_accuracy: 0.7903 - val_recall: 0.8127 - val_precision: 0.7774 - val_auc: 0.8847\n",
      "Epoch 120/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.7614 - recall: 0.7761 - precision: 0.7541 - auc: 0.8541 - val_loss: 0.4385 - val_accuracy: 0.7877 - val_recall: 0.8125 - val_precision: 0.7737 - val_auc: 0.8825\n",
      "Epoch 121/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4716 - accuracy: 0.7594 - recall: 0.7735 - precision: 0.7525 - auc: 0.8516 - val_loss: 0.4404 - val_accuracy: 0.7859 - val_recall: 0.8352 - val_precision: 0.7599 - val_auc: 0.8829\n",
      "Epoch 122/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4710 - accuracy: 0.7572 - recall: 0.7712 - precision: 0.7504 - auc: 0.8513 - val_loss: 0.4371 - val_accuracy: 0.7906 - val_recall: 0.8052 - val_precision: 0.7819 - val_auc: 0.8844\n",
      "Epoch 123/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4718 - accuracy: 0.7581 - recall: 0.7749 - precision: 0.7499 - auc: 0.8509 - val_loss: 0.4391 - val_accuracy: 0.7886 - val_recall: 0.8050 - val_precision: 0.7790 - val_auc: 0.8837\n",
      "Epoch 124/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4682 - accuracy: 0.7600 - recall: 0.7747 - precision: 0.7527 - auc: 0.8536 - val_loss: 0.4373 - val_accuracy: 0.7881 - val_recall: 0.8322 - val_precision: 0.7643 - val_auc: 0.8838\n",
      "Epoch 125/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.7581 - recall: 0.7712 - precision: 0.7517 - auc: 0.8513 - val_loss: 0.4403 - val_accuracy: 0.7896 - val_recall: 0.8326 - val_precision: 0.7663 - val_auc: 0.8850\n",
      "Epoch 126/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4723 - accuracy: 0.7579 - recall: 0.7694 - precision: 0.7523 - auc: 0.8506 - val_loss: 0.4353 - val_accuracy: 0.7917 - val_recall: 0.8263 - val_precision: 0.7724 - val_auc: 0.8845\n",
      "Epoch 127/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.7588 - recall: 0.7689 - precision: 0.7538 - auc: 0.8515 - val_loss: 0.4372 - val_accuracy: 0.7932 - val_recall: 0.8070 - val_precision: 0.7849 - val_auc: 0.8851\n",
      "Epoch 128/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4717 - accuracy: 0.7582 - recall: 0.7723 - precision: 0.7512 - auc: 0.8516 - val_loss: 0.4385 - val_accuracy: 0.7896 - val_recall: 0.8234 - val_precision: 0.7708 - val_auc: 0.8839\n",
      "Epoch 129/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4691 - accuracy: 0.7600 - recall: 0.7721 - precision: 0.7540 - auc: 0.8534 - val_loss: 0.4356 - val_accuracy: 0.7895 - val_recall: 0.8213 - val_precision: 0.7717 - val_auc: 0.8847\n",
      "Epoch 130/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4691 - accuracy: 0.7611 - recall: 0.7808 - precision: 0.7513 - auc: 0.8534 - val_loss: 0.4376 - val_accuracy: 0.7915 - val_recall: 0.8190 - val_precision: 0.7758 - val_auc: 0.8840\n",
      "Epoch 131/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4707 - accuracy: 0.7609 - recall: 0.7733 - precision: 0.7547 - auc: 0.8525 - val_loss: 0.4418 - val_accuracy: 0.7867 - val_recall: 0.8695 - val_precision: 0.7456 - val_auc: 0.8838\n",
      "Epoch 132/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.7601 - recall: 0.7776 - precision: 0.7514 - auc: 0.8527 - val_loss: 0.4350 - val_accuracy: 0.7913 - val_recall: 0.8120 - val_precision: 0.7792 - val_auc: 0.8854\n",
      "Epoch 133/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4686 - accuracy: 0.7603 - recall: 0.7762 - precision: 0.7523 - auc: 0.8536 - val_loss: 0.4350 - val_accuracy: 0.7909 - val_recall: 0.8208 - val_precision: 0.7740 - val_auc: 0.8851\n",
      "Epoch 134/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4685 - accuracy: 0.7600 - recall: 0.7748 - precision: 0.7526 - auc: 0.8535 - val_loss: 0.4338 - val_accuracy: 0.7944 - val_recall: 0.8228 - val_precision: 0.7781 - val_auc: 0.8856\n",
      "Epoch 135/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4685 - accuracy: 0.7600 - recall: 0.7748 - precision: 0.7527 - auc: 0.8534 - val_loss: 0.4391 - val_accuracy: 0.7896 - val_recall: 0.8655 - val_precision: 0.7510 - val_auc: 0.8852\n",
      "Epoch 136/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4683 - accuracy: 0.7607 - recall: 0.7775 - precision: 0.7524 - auc: 0.8541 - val_loss: 0.4347 - val_accuracy: 0.7900 - val_recall: 0.8519 - val_precision: 0.7577 - val_auc: 0.8861\n",
      "Epoch 137/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4673 - accuracy: 0.7610 - recall: 0.7816 - precision: 0.7508 - auc: 0.8543 - val_loss: 0.4372 - val_accuracy: 0.7908 - val_recall: 0.8389 - val_precision: 0.7649 - val_auc: 0.8857\n",
      "Epoch 138/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.7632 - recall: 0.7765 - precision: 0.7565 - auc: 0.8558 - val_loss: 0.4380 - val_accuracy: 0.7887 - val_recall: 0.8375 - val_precision: 0.7626 - val_auc: 0.8843\n",
      "Epoch 139/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.7602 - recall: 0.7692 - precision: 0.7558 - auc: 0.8540 - val_loss: 0.4350 - val_accuracy: 0.7894 - val_recall: 0.8234 - val_precision: 0.7705 - val_auc: 0.8854\n",
      "Epoch 140/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4658 - accuracy: 0.7606 - recall: 0.7721 - precision: 0.7549 - auc: 0.8556 - val_loss: 0.4339 - val_accuracy: 0.7917 - val_recall: 0.8091 - val_precision: 0.7815 - val_auc: 0.8858\n",
      "Epoch 141/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4645 - accuracy: 0.7622 - recall: 0.7775 - precision: 0.7546 - auc: 0.8562 - val_loss: 0.4362 - val_accuracy: 0.7887 - val_recall: 0.8326 - val_precision: 0.7649 - val_auc: 0.8845\n",
      "Epoch 142/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4646 - accuracy: 0.7637 - recall: 0.7756 - precision: 0.7577 - auc: 0.8565 - val_loss: 0.4336 - val_accuracy: 0.7928 - val_recall: 0.8467 - val_precision: 0.7638 - val_auc: 0.8869\n",
      "Epoch 143/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4654 - accuracy: 0.7630 - recall: 0.7776 - precision: 0.7557 - auc: 0.8559 - val_loss: 0.4342 - val_accuracy: 0.7919 - val_recall: 0.7979 - val_precision: 0.7879 - val_auc: 0.8863\n",
      "Epoch 144/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4652 - accuracy: 0.7622 - recall: 0.7714 - precision: 0.7576 - auc: 0.8556 - val_loss: 0.4329 - val_accuracy: 0.7930 - val_recall: 0.8451 - val_precision: 0.7649 - val_auc: 0.8874\n",
      "Epoch 145/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4636 - accuracy: 0.7644 - recall: 0.7769 - precision: 0.7581 - auc: 0.8573 - val_loss: 0.4318 - val_accuracy: 0.7927 - val_recall: 0.8306 - val_precision: 0.7716 - val_auc: 0.8868\n",
      "Epoch 146/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4616 - accuracy: 0.7649 - recall: 0.7766 - precision: 0.7589 - auc: 0.8584 - val_loss: 0.4311 - val_accuracy: 0.7940 - val_recall: 0.8309 - val_precision: 0.7733 - val_auc: 0.8875\n",
      "Epoch 147/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.7629 - recall: 0.7730 - precision: 0.7578 - auc: 0.8552 - val_loss: 0.4335 - val_accuracy: 0.7913 - val_recall: 0.8479 - val_precision: 0.7613 - val_auc: 0.8866\n",
      "Epoch 148/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4638 - accuracy: 0.7628 - recall: 0.7776 - precision: 0.7554 - auc: 0.8567 - val_loss: 0.4303 - val_accuracy: 0.7931 - val_recall: 0.8254 - val_precision: 0.7749 - val_auc: 0.8875\n",
      "Epoch 149/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4643 - accuracy: 0.7629 - recall: 0.7729 - precision: 0.7578 - auc: 0.8565 - val_loss: 0.4320 - val_accuracy: 0.7920 - val_recall: 0.8694 - val_precision: 0.7524 - val_auc: 0.8874\n",
      "Epoch 150/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.7625 - recall: 0.7771 - precision: 0.7552 - auc: 0.8558 - val_loss: 0.4294 - val_accuracy: 0.7952 - val_recall: 0.8653 - val_precision: 0.7585 - val_auc: 0.8890\n",
      "Epoch 151/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4611 - accuracy: 0.7654 - recall: 0.7779 - precision: 0.7591 - auc: 0.8589 - val_loss: 0.4306 - val_accuracy: 0.7932 - val_recall: 0.7987 - val_precision: 0.7896 - val_auc: 0.8873\n",
      "Epoch 152/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4649 - accuracy: 0.7627 - recall: 0.7764 - precision: 0.7558 - auc: 0.8561 - val_loss: 0.4315 - val_accuracy: 0.7937 - val_recall: 0.7973 - val_precision: 0.7911 - val_auc: 0.8871\n",
      "Epoch 153/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4636 - accuracy: 0.7624 - recall: 0.7740 - precision: 0.7566 - auc: 0.8567 - val_loss: 0.4281 - val_accuracy: 0.7947 - val_recall: 0.8239 - val_precision: 0.7779 - val_auc: 0.8889\n",
      "Epoch 154/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4632 - accuracy: 0.7639 - recall: 0.7748 - precision: 0.7584 - auc: 0.8575 - val_loss: 0.4290 - val_accuracy: 0.7954 - val_recall: 0.8399 - val_precision: 0.7708 - val_auc: 0.8885\n",
      "Epoch 155/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4635 - accuracy: 0.7641 - recall: 0.7754 - precision: 0.7584 - auc: 0.8571 - val_loss: 0.4289 - val_accuracy: 0.7935 - val_recall: 0.8379 - val_precision: 0.7691 - val_auc: 0.8886\n",
      "Epoch 156/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.7639 - recall: 0.7732 - precision: 0.7591 - auc: 0.8577 - val_loss: 0.4303 - val_accuracy: 0.7927 - val_recall: 0.8546 - val_precision: 0.7600 - val_auc: 0.8881\n",
      "Epoch 157/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4643 - accuracy: 0.7638 - recall: 0.7792 - precision: 0.7561 - auc: 0.8570 - val_loss: 0.4320 - val_accuracy: 0.7936 - val_recall: 0.8440 - val_precision: 0.7663 - val_auc: 0.8888\n",
      "Epoch 158/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4630 - accuracy: 0.7639 - recall: 0.7784 - precision: 0.7565 - auc: 0.8573 - val_loss: 0.4292 - val_accuracy: 0.7936 - val_recall: 0.8132 - val_precision: 0.7820 - val_auc: 0.8893\n",
      "Epoch 159/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4629 - accuracy: 0.7638 - recall: 0.7728 - precision: 0.7592 - auc: 0.8575 - val_loss: 0.4288 - val_accuracy: 0.7960 - val_recall: 0.8067 - val_precision: 0.7894 - val_auc: 0.8888\n",
      "Epoch 160/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4652 - accuracy: 0.7628 - recall: 0.7732 - precision: 0.7576 - auc: 0.8560 - val_loss: 0.4307 - val_accuracy: 0.7940 - val_recall: 0.8538 - val_precision: 0.7621 - val_auc: 0.8894\n",
      "Epoch 161/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.7655 - recall: 0.7777 - precision: 0.7593 - auc: 0.8592 - val_loss: 0.4294 - val_accuracy: 0.7943 - val_recall: 0.8655 - val_precision: 0.7572 - val_auc: 0.8896\n",
      "Epoch 162/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4615 - accuracy: 0.7666 - recall: 0.7814 - precision: 0.7591 - auc: 0.8590 - val_loss: 0.4281 - val_accuracy: 0.7970 - val_recall: 0.8490 - val_precision: 0.7686 - val_auc: 0.8905\n",
      "Epoch 163/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4627 - accuracy: 0.7649 - recall: 0.7785 - precision: 0.7581 - auc: 0.8579 - val_loss: 0.4299 - val_accuracy: 0.7973 - val_recall: 0.8340 - val_precision: 0.7765 - val_auc: 0.8889\n",
      "Epoch 164/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.7657 - recall: 0.7762 - precision: 0.7604 - auc: 0.8589 - val_loss: 0.4255 - val_accuracy: 0.7969 - val_recall: 0.8216 - val_precision: 0.7825 - val_auc: 0.8903\n",
      "Epoch 165/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4622 - accuracy: 0.7652 - recall: 0.7764 - precision: 0.7595 - auc: 0.8584 - val_loss: 0.4297 - val_accuracy: 0.7942 - val_recall: 0.8414 - val_precision: 0.7684 - val_auc: 0.8892\n",
      "Epoch 166/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4592 - accuracy: 0.7663 - recall: 0.7786 - precision: 0.7600 - auc: 0.8600 - val_loss: 0.4285 - val_accuracy: 0.7954 - val_recall: 0.8540 - val_precision: 0.7639 - val_auc: 0.8893\n",
      "Epoch 167/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4620 - accuracy: 0.7640 - recall: 0.7788 - precision: 0.7566 - auc: 0.8580 - val_loss: 0.4270 - val_accuracy: 0.7958 - val_recall: 0.8348 - val_precision: 0.7740 - val_auc: 0.8898\n",
      "Epoch 168/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4591 - accuracy: 0.7674 - recall: 0.7805 - precision: 0.7607 - auc: 0.8605 - val_loss: 0.4245 - val_accuracy: 0.7960 - val_recall: 0.8455 - val_precision: 0.7689 - val_auc: 0.8899\n",
      "Epoch 169/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4597 - accuracy: 0.7659 - recall: 0.7776 - precision: 0.7600 - auc: 0.8595 - val_loss: 0.4280 - val_accuracy: 0.7981 - val_recall: 0.8087 - val_precision: 0.7914 - val_auc: 0.8903\n",
      "Epoch 170/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4590 - accuracy: 0.7680 - recall: 0.7797 - precision: 0.7620 - auc: 0.8607 - val_loss: 0.4322 - val_accuracy: 0.7948 - val_recall: 0.8327 - val_precision: 0.7735 - val_auc: 0.8884\n",
      "Epoch 171/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4599 - accuracy: 0.7656 - recall: 0.7814 - precision: 0.7576 - auc: 0.8597 - val_loss: 0.4313 - val_accuracy: 0.7955 - val_recall: 0.8604 - val_precision: 0.7612 - val_auc: 0.8897\n",
      "Epoch 172/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4596 - accuracy: 0.7664 - recall: 0.7802 - precision: 0.7593 - auc: 0.8601 - val_loss: 0.4266 - val_accuracy: 0.7987 - val_recall: 0.8325 - val_precision: 0.7794 - val_auc: 0.8919\n",
      "Epoch 173/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4594 - accuracy: 0.7668 - recall: 0.7811 - precision: 0.7595 - auc: 0.8601 - val_loss: 0.4234 - val_accuracy: 0.7981 - val_recall: 0.8192 - val_precision: 0.7856 - val_auc: 0.8911\n",
      "Epoch 174/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4594 - accuracy: 0.7659 - recall: 0.7811 - precision: 0.7581 - auc: 0.8600 - val_loss: 0.4292 - val_accuracy: 0.7946 - val_recall: 0.8115 - val_precision: 0.7846 - val_auc: 0.8886\n",
      "Epoch 175/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4592 - accuracy: 0.7672 - recall: 0.7821 - precision: 0.7597 - auc: 0.8605 - val_loss: 0.4281 - val_accuracy: 0.7959 - val_recall: 0.8470 - val_precision: 0.7680 - val_auc: 0.8909\n",
      "Epoch 176/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4593 - accuracy: 0.7651 - recall: 0.7742 - precision: 0.7604 - auc: 0.8597 - val_loss: 0.4262 - val_accuracy: 0.7973 - val_recall: 0.8529 - val_precision: 0.7671 - val_auc: 0.8918\n",
      "Epoch 177/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4598 - accuracy: 0.7666 - recall: 0.7729 - precision: 0.7635 - auc: 0.8600 - val_loss: 0.4262 - val_accuracy: 0.7975 - val_recall: 0.8529 - val_precision: 0.7673 - val_auc: 0.8915\n",
      "Epoch 178/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4598 - accuracy: 0.7668 - recall: 0.7770 - precision: 0.7616 - auc: 0.8602 - val_loss: 0.4266 - val_accuracy: 0.7961 - val_recall: 0.8577 - val_precision: 0.7633 - val_auc: 0.8915\n",
      "Epoch 179/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4569 - accuracy: 0.7684 - recall: 0.7827 - precision: 0.7611 - auc: 0.8620 - val_loss: 0.4248 - val_accuracy: 0.7980 - val_recall: 0.8387 - val_precision: 0.7751 - val_auc: 0.8913\n",
      "Epoch 180/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4566 - accuracy: 0.7683 - recall: 0.7819 - precision: 0.7613 - auc: 0.8618 - val_loss: 0.4255 - val_accuracy: 0.7988 - val_recall: 0.8561 - val_precision: 0.7677 - val_auc: 0.8918\n",
      "Epoch 181/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4599 - accuracy: 0.7661 - recall: 0.7762 - precision: 0.7610 - auc: 0.8597 - val_loss: 0.4229 - val_accuracy: 0.8002 - val_recall: 0.8197 - val_precision: 0.7885 - val_auc: 0.8921\n",
      "Epoch 182/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4600 - accuracy: 0.7654 - recall: 0.7747 - precision: 0.7607 - auc: 0.8595 - val_loss: 0.4245 - val_accuracy: 0.7986 - val_recall: 0.8130 - val_precision: 0.7898 - val_auc: 0.8917\n",
      "Epoch 183/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4576 - accuracy: 0.7683 - recall: 0.7763 - precision: 0.7642 - auc: 0.8613 - val_loss: 0.4222 - val_accuracy: 0.7977 - val_recall: 0.7999 - val_precision: 0.7960 - val_auc: 0.8923\n",
      "Epoch 184/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4560 - accuracy: 0.7683 - recall: 0.7783 - precision: 0.7632 - auc: 0.8622 - val_loss: 0.4246 - val_accuracy: 0.7971 - val_recall: 0.8237 - val_precision: 0.7817 - val_auc: 0.8918\n",
      "Epoch 185/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4577 - accuracy: 0.7688 - recall: 0.7772 - precision: 0.7645 - auc: 0.8615 - val_loss: 0.4235 - val_accuracy: 0.7985 - val_recall: 0.8187 - val_precision: 0.7864 - val_auc: 0.8915\n",
      "Epoch 186/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4580 - accuracy: 0.7667 - recall: 0.7795 - precision: 0.7601 - auc: 0.8607 - val_loss: 0.4255 - val_accuracy: 0.7967 - val_recall: 0.8607 - val_precision: 0.7626 - val_auc: 0.8918\n",
      "Epoch 187/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4551 - accuracy: 0.7692 - recall: 0.7793 - precision: 0.7640 - auc: 0.8629 - val_loss: 0.4235 - val_accuracy: 0.7977 - val_recall: 0.8585 - val_precision: 0.7650 - val_auc: 0.8918\n",
      "Epoch 188/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4548 - accuracy: 0.7701 - recall: 0.7854 - precision: 0.7622 - auc: 0.8636 - val_loss: 0.4272 - val_accuracy: 0.7988 - val_recall: 0.8204 - val_precision: 0.7860 - val_auc: 0.8913\n",
      "Epoch 189/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4566 - accuracy: 0.7669 - recall: 0.7815 - precision: 0.7594 - auc: 0.8619 - val_loss: 0.4273 - val_accuracy: 0.7960 - val_recall: 0.8626 - val_precision: 0.7608 - val_auc: 0.8910\n",
      "Epoch 190/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4575 - accuracy: 0.7670 - recall: 0.7774 - precision: 0.7617 - auc: 0.8612 - val_loss: 0.4231 - val_accuracy: 0.7996 - val_recall: 0.8320 - val_precision: 0.7810 - val_auc: 0.8932\n",
      "Epoch 191/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.7693 - recall: 0.7782 - precision: 0.7647 - auc: 0.8631 - val_loss: 0.4201 - val_accuracy: 0.8003 - val_recall: 0.8192 - val_precision: 0.7888 - val_auc: 0.8932\n",
      "Epoch 192/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4564 - accuracy: 0.7684 - recall: 0.7774 - precision: 0.7637 - auc: 0.8621 - val_loss: 0.4261 - val_accuracy: 0.7983 - val_recall: 0.8413 - val_precision: 0.7743 - val_auc: 0.8928\n",
      "Epoch 193/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4555 - accuracy: 0.7694 - recall: 0.7790 - precision: 0.7644 - auc: 0.8628 - val_loss: 0.4229 - val_accuracy: 0.7991 - val_recall: 0.8674 - val_precision: 0.7628 - val_auc: 0.8936\n",
      "Epoch 194/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.7689 - recall: 0.7788 - precision: 0.7638 - auc: 0.8634 - val_loss: 0.4203 - val_accuracy: 0.7994 - val_recall: 0.8555 - val_precision: 0.7688 - val_auc: 0.8937\n",
      "Epoch 195/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.7678 - recall: 0.7829 - precision: 0.7600 - auc: 0.8614 - val_loss: 0.4219 - val_accuracy: 0.7996 - val_recall: 0.8340 - val_precision: 0.7799 - val_auc: 0.8931\n",
      "Epoch 196/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7707 - recall: 0.7820 - precision: 0.7648 - auc: 0.8644 - val_loss: 0.4213 - val_accuracy: 0.7986 - val_recall: 0.8476 - val_precision: 0.7716 - val_auc: 0.8927\n",
      "Epoch 197/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7699 - recall: 0.7816 - precision: 0.7639 - auc: 0.8639 - val_loss: 0.4212 - val_accuracy: 0.7989 - val_recall: 0.8426 - val_precision: 0.7744 - val_auc: 0.8932\n",
      "Epoch 198/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7716 - recall: 0.7898 - precision: 0.7622 - auc: 0.8649 - val_loss: 0.4192 - val_accuracy: 0.7994 - val_recall: 0.8529 - val_precision: 0.7701 - val_auc: 0.8937\n",
      "Epoch 199/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7706 - recall: 0.7820 - precision: 0.7646 - auc: 0.8644 - val_loss: 0.4179 - val_accuracy: 0.8014 - val_recall: 0.8207 - val_precision: 0.7897 - val_auc: 0.8943\n",
      "Epoch 200/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7695 - recall: 0.7800 - precision: 0.7640 - auc: 0.8638 - val_loss: 0.4190 - val_accuracy: 0.8018 - val_recall: 0.8219 - val_precision: 0.7896 - val_auc: 0.8943\n",
      "Epoch 201/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7709 - recall: 0.7835 - precision: 0.7644 - auc: 0.8641 - val_loss: 0.4202 - val_accuracy: 0.8022 - val_recall: 0.7944 - val_precision: 0.8065 - val_auc: 0.8937\n",
      "Epoch 202/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7722 - recall: 0.7817 - precision: 0.7673 - auc: 0.8647 - val_loss: 0.4204 - val_accuracy: 0.8004 - val_recall: 0.8509 - val_precision: 0.7724 - val_auc: 0.8936\n",
      "Epoch 203/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4557 - accuracy: 0.7688 - recall: 0.7762 - precision: 0.7650 - auc: 0.8627 - val_loss: 0.4182 - val_accuracy: 0.8007 - val_recall: 0.8420 - val_precision: 0.7774 - val_auc: 0.8944\n",
      "Epoch 204/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.7703 - recall: 0.7830 - precision: 0.7638 - auc: 0.8642 - val_loss: 0.4217 - val_accuracy: 0.7983 - val_recall: 0.7976 - val_precision: 0.7982 - val_auc: 0.8924\n",
      "Epoch 205/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4547 - accuracy: 0.7698 - recall: 0.7800 - precision: 0.7646 - auc: 0.8635 - val_loss: 0.4204 - val_accuracy: 0.8020 - val_recall: 0.8103 - val_precision: 0.7965 - val_auc: 0.8947\n",
      "Epoch 206/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7701 - recall: 0.7794 - precision: 0.7653 - auc: 0.8638 - val_loss: 0.4194 - val_accuracy: 0.8027 - val_recall: 0.8270 - val_precision: 0.7881 - val_auc: 0.8948\n",
      "Epoch 207/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4546 - accuracy: 0.7703 - recall: 0.7802 - precision: 0.7652 - auc: 0.8638 - val_loss: 0.4177 - val_accuracy: 0.8013 - val_recall: 0.8341 - val_precision: 0.7824 - val_auc: 0.8946\n",
      "Epoch 208/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.7704 - recall: 0.7789 - precision: 0.7660 - auc: 0.8639 - val_loss: 0.4228 - val_accuracy: 0.7982 - val_recall: 0.8651 - val_precision: 0.7626 - val_auc: 0.8937\n",
      "Epoch 209/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.7699 - recall: 0.7791 - precision: 0.7651 - auc: 0.8643 - val_loss: 0.4240 - val_accuracy: 0.7997 - val_recall: 0.8791 - val_precision: 0.7582 - val_auc: 0.8945\n",
      "Epoch 210/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4535 - accuracy: 0.7696 - recall: 0.7821 - precision: 0.7632 - auc: 0.8639 - val_loss: 0.4210 - val_accuracy: 0.8009 - val_recall: 0.8103 - val_precision: 0.7949 - val_auc: 0.8941\n",
      "Epoch 211/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.7705 - recall: 0.7780 - precision: 0.7666 - auc: 0.8637 - val_loss: 0.4291 - val_accuracy: 0.7955 - val_recall: 0.8531 - val_precision: 0.7646 - val_auc: 0.8918\n",
      "Epoch 212/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7716 - recall: 0.7777 - precision: 0.7684 - auc: 0.8647 - val_loss: 0.4253 - val_accuracy: 0.7968 - val_recall: 0.8681 - val_precision: 0.7593 - val_auc: 0.8926\n",
      "Epoch 213/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7708 - recall: 0.7764 - precision: 0.7678 - auc: 0.8646 - val_loss: 0.4205 - val_accuracy: 0.8017 - val_recall: 0.8453 - val_precision: 0.7771 - val_auc: 0.8953\n",
      "Epoch 214/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.7699 - recall: 0.7804 - precision: 0.7645 - auc: 0.8638 - val_loss: 0.4207 - val_accuracy: 0.8003 - val_recall: 0.8678 - val_precision: 0.7642 - val_auc: 0.8950\n",
      "Epoch 215/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7725 - recall: 0.7845 - precision: 0.7662 - auc: 0.8651 - val_loss: 0.4203 - val_accuracy: 0.8008 - val_recall: 0.8588 - val_precision: 0.7691 - val_auc: 0.8950\n",
      "Epoch 216/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.7711 - recall: 0.7797 - precision: 0.7666 - auc: 0.8649 - val_loss: 0.4222 - val_accuracy: 0.8013 - val_recall: 0.8338 - val_precision: 0.7824 - val_auc: 0.8941\n",
      "Epoch 217/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.7723 - recall: 0.7839 - precision: 0.7663 - auc: 0.8653 - val_loss: 0.4200 - val_accuracy: 0.8005 - val_recall: 0.8654 - val_precision: 0.7656 - val_auc: 0.8949\n",
      "Epoch 218/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4534 - accuracy: 0.7704 - recall: 0.7795 - precision: 0.7657 - auc: 0.8640 - val_loss: 0.4232 - val_accuracy: 0.8006 - val_recall: 0.8696 - val_precision: 0.7637 - val_auc: 0.8947\n",
      "Epoch 219/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4542 - accuracy: 0.7703 - recall: 0.7787 - precision: 0.7660 - auc: 0.8637 - val_loss: 0.4170 - val_accuracy: 0.8015 - val_recall: 0.8452 - val_precision: 0.7768 - val_auc: 0.8957\n",
      "Epoch 220/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7718 - recall: 0.7871 - precision: 0.7638 - auc: 0.8655 - val_loss: 0.4222 - val_accuracy: 0.8013 - val_recall: 0.8453 - val_precision: 0.7765 - val_auc: 0.8945\n",
      "Epoch 221/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7727 - recall: 0.7871 - precision: 0.7651 - auc: 0.8659 - val_loss: 0.4204 - val_accuracy: 0.7999 - val_recall: 0.8498 - val_precision: 0.7722 - val_auc: 0.8940\n",
      "Epoch 222/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.7722 - recall: 0.7847 - precision: 0.7657 - auc: 0.8647 - val_loss: 0.4216 - val_accuracy: 0.7991 - val_recall: 0.8017 - val_precision: 0.7971 - val_auc: 0.8930\n",
      "Epoch 223/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7707 - recall: 0.7817 - precision: 0.7650 - auc: 0.8648 - val_loss: 0.4209 - val_accuracy: 0.8011 - val_recall: 0.8542 - val_precision: 0.7718 - val_auc: 0.8946\n",
      "Epoch 224/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7729 - recall: 0.7829 - precision: 0.7676 - auc: 0.8662 - val_loss: 0.4193 - val_accuracy: 0.8010 - val_recall: 0.8706 - val_precision: 0.7639 - val_auc: 0.8946\n",
      "Epoch 225/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4515 - accuracy: 0.7721 - recall: 0.7797 - precision: 0.7682 - auc: 0.8655 - val_loss: 0.4195 - val_accuracy: 0.8028 - val_recall: 0.8292 - val_precision: 0.7872 - val_auc: 0.8953\n",
      "Epoch 226/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.7728 - recall: 0.7813 - precision: 0.7684 - auc: 0.8671 - val_loss: 0.4199 - val_accuracy: 0.8047 - val_recall: 0.8483 - val_precision: 0.7799 - val_auc: 0.8950\n",
      "Epoch 227/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4510 - accuracy: 0.7705 - recall: 0.7798 - precision: 0.7657 - auc: 0.8656 - val_loss: 0.4199 - val_accuracy: 0.8012 - val_recall: 0.8329 - val_precision: 0.7828 - val_auc: 0.8943\n",
      "Epoch 228/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.7730 - recall: 0.7826 - precision: 0.7681 - auc: 0.8669 - val_loss: 0.4203 - val_accuracy: 0.8013 - val_recall: 0.8467 - val_precision: 0.7757 - val_auc: 0.8946\n",
      "Epoch 229/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7724 - recall: 0.7852 - precision: 0.7658 - auc: 0.8666 - val_loss: 0.4193 - val_accuracy: 0.8006 - val_recall: 0.8426 - val_precision: 0.7768 - val_auc: 0.8947\n",
      "Epoch 230/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4493 - accuracy: 0.7728 - recall: 0.7809 - precision: 0.7686 - auc: 0.8668 - val_loss: 0.4249 - val_accuracy: 0.7990 - val_recall: 0.8516 - val_precision: 0.7702 - val_auc: 0.8929\n",
      "Epoch 231/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.7719 - recall: 0.7788 - precision: 0.7683 - auc: 0.8656 - val_loss: 0.4209 - val_accuracy: 0.8010 - val_recall: 0.8703 - val_precision: 0.7640 - val_auc: 0.8946\n",
      "Epoch 232/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4513 - accuracy: 0.7723 - recall: 0.7850 - precision: 0.7657 - auc: 0.8658 - val_loss: 0.4209 - val_accuracy: 0.8011 - val_recall: 0.8364 - val_precision: 0.7809 - val_auc: 0.8935\n",
      "Epoch 233/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4523 - accuracy: 0.7714 - recall: 0.7800 - precision: 0.7670 - auc: 0.8652 - val_loss: 0.4208 - val_accuracy: 0.8017 - val_recall: 0.8531 - val_precision: 0.7731 - val_auc: 0.8949\n",
      "Epoch 234/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4494 - accuracy: 0.7735 - recall: 0.7805 - precision: 0.7699 - auc: 0.8670 - val_loss: 0.4160 - val_accuracy: 0.8032 - val_recall: 0.8324 - val_precision: 0.7861 - val_auc: 0.8962\n",
      "Epoch 235/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4505 - accuracy: 0.7719 - recall: 0.7827 - precision: 0.7663 - auc: 0.8660 - val_loss: 0.4172 - val_accuracy: 0.8029 - val_recall: 0.8273 - val_precision: 0.7884 - val_auc: 0.8947\n",
      "Epoch 236/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4512 - accuracy: 0.7702 - recall: 0.7731 - precision: 0.7688 - auc: 0.8654 - val_loss: 0.4156 - val_accuracy: 0.8038 - val_recall: 0.8215 - val_precision: 0.7929 - val_auc: 0.8956\n",
      "Epoch 237/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4523 - accuracy: 0.7713 - recall: 0.7787 - precision: 0.7675 - auc: 0.8651 - val_loss: 0.4164 - val_accuracy: 0.8036 - val_recall: 0.8394 - val_precision: 0.7829 - val_auc: 0.8956\n",
      "Epoch 238/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.7718 - recall: 0.7811 - precision: 0.7669 - auc: 0.8651 - val_loss: 0.4163 - val_accuracy: 0.8027 - val_recall: 0.8358 - val_precision: 0.7834 - val_auc: 0.8952\n",
      "Epoch 239/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4486 - accuracy: 0.7738 - recall: 0.7804 - precision: 0.7704 - auc: 0.8675 - val_loss: 0.4172 - val_accuracy: 0.8030 - val_recall: 0.8617 - val_precision: 0.7708 - val_auc: 0.8958\n",
      "Epoch 240/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4504 - accuracy: 0.7733 - recall: 0.7843 - precision: 0.7675 - auc: 0.8663 - val_loss: 0.4148 - val_accuracy: 0.8029 - val_recall: 0.8450 - val_precision: 0.7790 - val_auc: 0.8962\n",
      "Epoch 241/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.7719 - recall: 0.7831 - precision: 0.7660 - auc: 0.8665 - val_loss: 0.4165 - val_accuracy: 0.8038 - val_recall: 0.8328 - val_precision: 0.7867 - val_auc: 0.8960\n",
      "Epoch 242/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4492 - accuracy: 0.7733 - recall: 0.7834 - precision: 0.7680 - auc: 0.8671 - val_loss: 0.4172 - val_accuracy: 0.8016 - val_recall: 0.8433 - val_precision: 0.7779 - val_auc: 0.8951\n",
      "Epoch 243/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4492 - accuracy: 0.7739 - recall: 0.7849 - precision: 0.7681 - auc: 0.8673 - val_loss: 0.4152 - val_accuracy: 0.8017 - val_recall: 0.8133 - val_precision: 0.7943 - val_auc: 0.8953\n",
      "Epoch 244/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4492 - accuracy: 0.7742 - recall: 0.7827 - precision: 0.7697 - auc: 0.8674 - val_loss: 0.4166 - val_accuracy: 0.8015 - val_recall: 0.8431 - val_precision: 0.7779 - val_auc: 0.8953\n",
      "Epoch 245/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4499 - accuracy: 0.7737 - recall: 0.7840 - precision: 0.7684 - auc: 0.8668 - val_loss: 0.4156 - val_accuracy: 0.8013 - val_recall: 0.8053 - val_precision: 0.7984 - val_auc: 0.8953\n",
      "Epoch 246/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4500 - accuracy: 0.7726 - recall: 0.7808 - precision: 0.7683 - auc: 0.8665 - val_loss: 0.4181 - val_accuracy: 0.8010 - val_recall: 0.8654 - val_precision: 0.7663 - val_auc: 0.8947\n",
      "Epoch 247/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4485 - accuracy: 0.7740 - recall: 0.7855 - precision: 0.7679 - auc: 0.8674 - val_loss: 0.4211 - val_accuracy: 0.7990 - val_recall: 0.8580 - val_precision: 0.7671 - val_auc: 0.8954\n",
      "Epoch 248/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4484 - accuracy: 0.7743 - recall: 0.7834 - precision: 0.7696 - auc: 0.8677 - val_loss: 0.4194 - val_accuracy: 0.8007 - val_recall: 0.8637 - val_precision: 0.7667 - val_auc: 0.8957\n",
      "Epoch 249/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.7749 - recall: 0.7869 - precision: 0.7686 - auc: 0.8680 - val_loss: 0.4165 - val_accuracy: 0.8019 - val_recall: 0.8803 - val_precision: 0.7605 - val_auc: 0.8966\n",
      "Epoch 250/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4489 - accuracy: 0.7723 - recall: 0.7852 - precision: 0.7656 - auc: 0.8668 - val_loss: 0.4182 - val_accuracy: 0.7989 - val_recall: 0.8822 - val_precision: 0.7558 - val_auc: 0.8959\n",
      "Epoch 251/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4481 - accuracy: 0.7739 - recall: 0.7908 - precision: 0.7650 - auc: 0.8676 - val_loss: 0.4186 - val_accuracy: 0.8010 - val_recall: 0.8544 - val_precision: 0.7716 - val_auc: 0.8953\n",
      "Epoch 252/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4482 - accuracy: 0.7745 - recall: 0.7861 - precision: 0.7684 - auc: 0.8677 - val_loss: 0.4171 - val_accuracy: 0.8038 - val_recall: 0.8451 - val_precision: 0.7802 - val_auc: 0.8967\n",
      "Epoch 253/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4488 - accuracy: 0.7742 - recall: 0.7865 - precision: 0.7677 - auc: 0.8674 - val_loss: 0.4136 - val_accuracy: 0.8022 - val_recall: 0.8608 - val_precision: 0.7701 - val_auc: 0.8973\n",
      "Epoch 254/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4473 - accuracy: 0.7747 - recall: 0.7830 - precision: 0.7703 - auc: 0.8685 - val_loss: 0.4156 - val_accuracy: 0.8034 - val_recall: 0.8507 - val_precision: 0.7767 - val_auc: 0.8974\n",
      "Epoch 255/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4470 - accuracy: 0.7748 - recall: 0.7886 - precision: 0.7676 - auc: 0.8686 - val_loss: 0.4144 - val_accuracy: 0.8042 - val_recall: 0.8170 - val_precision: 0.7961 - val_auc: 0.8969\n",
      "Epoch 256/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4493 - accuracy: 0.7732 - recall: 0.7830 - precision: 0.7680 - auc: 0.8668 - val_loss: 0.4182 - val_accuracy: 0.8021 - val_recall: 0.8383 - val_precision: 0.7813 - val_auc: 0.8954\n",
      "Epoch 257/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4475 - accuracy: 0.7745 - recall: 0.7858 - precision: 0.7685 - auc: 0.8681 - val_loss: 0.4115 - val_accuracy: 0.8057 - val_recall: 0.8223 - val_precision: 0.7955 - val_auc: 0.8977\n",
      "Epoch 258/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4468 - accuracy: 0.7750 - recall: 0.7854 - precision: 0.7695 - auc: 0.8688 - val_loss: 0.4155 - val_accuracy: 0.8051 - val_recall: 0.8153 - val_precision: 0.7984 - val_auc: 0.8964\n",
      "Epoch 259/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4476 - accuracy: 0.7748 - recall: 0.7881 - precision: 0.7678 - auc: 0.8685 - val_loss: 0.4173 - val_accuracy: 0.8024 - val_recall: 0.8818 - val_precision: 0.7605 - val_auc: 0.8970\n",
      "Epoch 260/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4469 - accuracy: 0.7736 - recall: 0.7835 - precision: 0.7685 - auc: 0.8685 - val_loss: 0.4166 - val_accuracy: 0.8033 - val_recall: 0.8442 - val_precision: 0.7799 - val_auc: 0.8969\n",
      "Epoch 261/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4473 - accuracy: 0.7751 - recall: 0.7843 - precision: 0.7703 - auc: 0.8684 - val_loss: 0.4135 - val_accuracy: 0.8047 - val_recall: 0.8300 - val_precision: 0.7897 - val_auc: 0.8969\n",
      "Epoch 262/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4460 - accuracy: 0.7775 - recall: 0.7867 - precision: 0.7727 - auc: 0.8697 - val_loss: 0.4145 - val_accuracy: 0.8022 - val_recall: 0.8353 - val_precision: 0.7830 - val_auc: 0.8972\n",
      "Epoch 263/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4497 - accuracy: 0.7737 - recall: 0.7796 - precision: 0.7706 - auc: 0.8672 - val_loss: 0.4153 - val_accuracy: 0.8022 - val_recall: 0.8496 - val_precision: 0.7757 - val_auc: 0.8966\n",
      "Epoch 264/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4462 - accuracy: 0.7757 - recall: 0.7828 - precision: 0.7719 - auc: 0.8694 - val_loss: 0.4160 - val_accuracy: 0.8018 - val_recall: 0.8483 - val_precision: 0.7757 - val_auc: 0.8967\n",
      "Epoch 265/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4475 - accuracy: 0.7727 - recall: 0.7837 - precision: 0.7670 - auc: 0.8679 - val_loss: 0.4141 - val_accuracy: 0.8024 - val_recall: 0.8417 - val_precision: 0.7800 - val_auc: 0.8975\n",
      "Epoch 266/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4487 - accuracy: 0.7750 - recall: 0.7849 - precision: 0.7698 - auc: 0.8679 - val_loss: 0.4145 - val_accuracy: 0.8036 - val_recall: 0.8494 - val_precision: 0.7777 - val_auc: 0.8972\n",
      "Epoch 267/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4473 - accuracy: 0.7750 - recall: 0.7863 - precision: 0.7690 - auc: 0.8684 - val_loss: 0.4141 - val_accuracy: 0.8066 - val_recall: 0.8496 - val_precision: 0.7819 - val_auc: 0.8985\n",
      "Epoch 268/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.7759 - recall: 0.7843 - precision: 0.7715 - auc: 0.8695 - val_loss: 0.4126 - val_accuracy: 0.8047 - val_recall: 0.8359 - val_precision: 0.7864 - val_auc: 0.8981\n",
      "Epoch 269/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4462 - accuracy: 0.7759 - recall: 0.7845 - precision: 0.7714 - auc: 0.8696 - val_loss: 0.4121 - val_accuracy: 0.8058 - val_recall: 0.8470 - val_precision: 0.7821 - val_auc: 0.8991\n",
      "Epoch 270/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.7750 - recall: 0.7902 - precision: 0.7671 - auc: 0.8680 - val_loss: 0.4160 - val_accuracy: 0.8050 - val_recall: 0.8309 - val_precision: 0.7895 - val_auc: 0.8977\n",
      "Epoch 271/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.7761 - recall: 0.7837 - precision: 0.7720 - auc: 0.8688 - val_loss: 0.4139 - val_accuracy: 0.8025 - val_recall: 0.8630 - val_precision: 0.7694 - val_auc: 0.8974\n",
      "Epoch 272/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4452 - accuracy: 0.7741 - recall: 0.7833 - precision: 0.7693 - auc: 0.8696 - val_loss: 0.4109 - val_accuracy: 0.8047 - val_recall: 0.8694 - val_precision: 0.7694 - val_auc: 0.8987\n",
      "Epoch 273/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4450 - accuracy: 0.7769 - recall: 0.7880 - precision: 0.7710 - auc: 0.8698 - val_loss: 0.4156 - val_accuracy: 0.8015 - val_recall: 0.8355 - val_precision: 0.7819 - val_auc: 0.8971\n",
      "Epoch 274/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4446 - accuracy: 0.7765 - recall: 0.7816 - precision: 0.7739 - auc: 0.8702 - val_loss: 0.4137 - val_accuracy: 0.8036 - val_recall: 0.8620 - val_precision: 0.7715 - val_auc: 0.8984\n",
      "Epoch 275/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4444 - accuracy: 0.7760 - recall: 0.7862 - precision: 0.7707 - auc: 0.8703 - val_loss: 0.4096 - val_accuracy: 0.8052 - val_recall: 0.8250 - val_precision: 0.7932 - val_auc: 0.8987\n",
      "Epoch 276/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4459 - accuracy: 0.7747 - recall: 0.7875 - precision: 0.7680 - auc: 0.8691 - val_loss: 0.4106 - val_accuracy: 0.8031 - val_recall: 0.8277 - val_precision: 0.7884 - val_auc: 0.8980\n",
      "Epoch 277/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4428 - accuracy: 0.7775 - recall: 0.7876 - precision: 0.7721 - auc: 0.8712 - val_loss: 0.4113 - val_accuracy: 0.8042 - val_recall: 0.8370 - val_precision: 0.7851 - val_auc: 0.8986\n",
      "Epoch 278/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.7758 - recall: 0.7862 - precision: 0.7704 - auc: 0.8694 - val_loss: 0.4148 - val_accuracy: 0.8034 - val_recall: 0.8704 - val_precision: 0.7672 - val_auc: 0.8979\n",
      "Epoch 279/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4458 - accuracy: 0.7758 - recall: 0.7879 - precision: 0.7694 - auc: 0.8695 - val_loss: 0.4171 - val_accuracy: 0.8035 - val_recall: 0.8623 - val_precision: 0.7712 - val_auc: 0.8981\n",
      "Epoch 280/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4430 - accuracy: 0.7784 - recall: 0.7925 - precision: 0.7709 - auc: 0.8716 - val_loss: 0.4134 - val_accuracy: 0.8026 - val_recall: 0.8463 - val_precision: 0.7778 - val_auc: 0.8977\n",
      "Epoch 281/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4440 - accuracy: 0.7782 - recall: 0.7862 - precision: 0.7740 - auc: 0.8708 - val_loss: 0.4158 - val_accuracy: 0.8035 - val_recall: 0.8498 - val_precision: 0.7774 - val_auc: 0.8976\n",
      "Epoch 282/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4449 - accuracy: 0.7754 - recall: 0.7833 - precision: 0.7713 - auc: 0.8698 - val_loss: 0.4126 - val_accuracy: 0.8031 - val_recall: 0.8416 - val_precision: 0.7810 - val_auc: 0.8982\n",
      "Epoch 283/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4434 - accuracy: 0.7767 - recall: 0.7858 - precision: 0.7719 - auc: 0.8709 - val_loss: 0.4170 - val_accuracy: 0.8023 - val_recall: 0.8576 - val_precision: 0.7717 - val_auc: 0.8972\n",
      "Epoch 284/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.7768 - recall: 0.7841 - precision: 0.7729 - auc: 0.8706 - val_loss: 0.4106 - val_accuracy: 0.8041 - val_recall: 0.8325 - val_precision: 0.7874 - val_auc: 0.8980\n",
      "Epoch 285/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4445 - accuracy: 0.7760 - recall: 0.7843 - precision: 0.7717 - auc: 0.8701 - val_loss: 0.4095 - val_accuracy: 0.8042 - val_recall: 0.8279 - val_precision: 0.7900 - val_auc: 0.8987\n",
      "Epoch 286/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4426 - accuracy: 0.7775 - recall: 0.7823 - precision: 0.7750 - auc: 0.8714 - val_loss: 0.4112 - val_accuracy: 0.8025 - val_recall: 0.8641 - val_precision: 0.7689 - val_auc: 0.8983\n",
      "Epoch 287/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.7759 - recall: 0.7890 - precision: 0.7689 - auc: 0.8701 - val_loss: 0.4113 - val_accuracy: 0.8060 - val_recall: 0.8283 - val_precision: 0.7925 - val_auc: 0.8992\n",
      "Epoch 288/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4439 - accuracy: 0.7774 - recall: 0.7924 - precision: 0.7693 - auc: 0.8710 - val_loss: 0.4110 - val_accuracy: 0.8049 - val_recall: 0.8248 - val_precision: 0.7927 - val_auc: 0.8985\n",
      "Epoch 289/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4431 - accuracy: 0.7783 - recall: 0.7883 - precision: 0.7729 - auc: 0.8715 - val_loss: 0.4131 - val_accuracy: 0.8032 - val_recall: 0.8545 - val_precision: 0.7746 - val_auc: 0.8976\n",
      "Epoch 290/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4462 - accuracy: 0.7756 - recall: 0.7826 - precision: 0.7718 - auc: 0.8693 - val_loss: 0.4110 - val_accuracy: 0.8036 - val_recall: 0.8638 - val_precision: 0.7706 - val_auc: 0.8992\n",
      "Epoch 291/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.7774 - recall: 0.7853 - precision: 0.7731 - auc: 0.8709 - val_loss: 0.4131 - val_accuracy: 0.8055 - val_recall: 0.8334 - val_precision: 0.7889 - val_auc: 0.8994\n",
      "Epoch 292/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4442 - accuracy: 0.7777 - recall: 0.7867 - precision: 0.7729 - auc: 0.8706 - val_loss: 0.4092 - val_accuracy: 0.8065 - val_recall: 0.8660 - val_precision: 0.7735 - val_auc: 0.8999\n",
      "Epoch 293/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4433 - accuracy: 0.7769 - recall: 0.7897 - precision: 0.7701 - auc: 0.8711 - val_loss: 0.4123 - val_accuracy: 0.8053 - val_recall: 0.8377 - val_precision: 0.7864 - val_auc: 0.8988\n",
      "Epoch 294/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4434 - accuracy: 0.7781 - recall: 0.7861 - precision: 0.7738 - auc: 0.8711 - val_loss: 0.4112 - val_accuracy: 0.8043 - val_recall: 0.8640 - val_precision: 0.7715 - val_auc: 0.8985\n",
      "Epoch 295/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4441 - accuracy: 0.7769 - recall: 0.7849 - precision: 0.7727 - auc: 0.8706 - val_loss: 0.4135 - val_accuracy: 0.8037 - val_recall: 0.8662 - val_precision: 0.7696 - val_auc: 0.8981\n",
      "Epoch 296/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4416 - accuracy: 0.7774 - recall: 0.7908 - precision: 0.7703 - auc: 0.8719 - val_loss: 0.4132 - val_accuracy: 0.8041 - val_recall: 0.8634 - val_precision: 0.7714 - val_auc: 0.8977\n",
      "Epoch 297/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4438 - accuracy: 0.7766 - recall: 0.7837 - precision: 0.7728 - auc: 0.8705 - val_loss: 0.4092 - val_accuracy: 0.8067 - val_recall: 0.8603 - val_precision: 0.7765 - val_auc: 0.9002\n",
      "Epoch 298/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.7752 - recall: 0.7890 - precision: 0.7679 - auc: 0.8692 - val_loss: 0.4118 - val_accuracy: 0.8066 - val_recall: 0.8125 - val_precision: 0.8026 - val_auc: 0.8995\n",
      "Epoch 299/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4439 - accuracy: 0.7783 - recall: 0.7876 - precision: 0.7734 - auc: 0.8708 - val_loss: 0.4142 - val_accuracy: 0.8027 - val_recall: 0.8474 - val_precision: 0.7775 - val_auc: 0.8980\n",
      "Epoch 300/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4426 - accuracy: 0.7786 - recall: 0.7876 - precision: 0.7738 - auc: 0.8718 - val_loss: 0.4132 - val_accuracy: 0.8058 - val_recall: 0.8361 - val_precision: 0.7878 - val_auc: 0.8990\n",
      "Epoch 301/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.7780 - recall: 0.7872 - precision: 0.7731 - auc: 0.8713 - val_loss: 0.4123 - val_accuracy: 0.8041 - val_recall: 0.8596 - val_precision: 0.7733 - val_auc: 0.8981\n",
      "Epoch 302/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4428 - accuracy: 0.7774 - recall: 0.7902 - precision: 0.7706 - auc: 0.8714 - val_loss: 0.4178 - val_accuracy: 0.8028 - val_recall: 0.8514 - val_precision: 0.7755 - val_auc: 0.8973\n",
      "Epoch 303/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.7762 - recall: 0.7872 - precision: 0.7704 - auc: 0.8701 - val_loss: 0.4147 - val_accuracy: 0.8050 - val_recall: 0.8259 - val_precision: 0.7923 - val_auc: 0.8986\n",
      "Epoch 304/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4413 - accuracy: 0.7785 - recall: 0.7859 - precision: 0.7746 - auc: 0.8721 - val_loss: 0.4110 - val_accuracy: 0.8055 - val_recall: 0.8315 - val_precision: 0.7900 - val_auc: 0.8981\n",
      "Epoch 305/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4417 - accuracy: 0.7782 - recall: 0.7877 - precision: 0.7732 - auc: 0.8719 - val_loss: 0.4095 - val_accuracy: 0.8055 - val_recall: 0.8539 - val_precision: 0.7781 - val_auc: 0.8991\n",
      "Epoch 306/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4434 - accuracy: 0.7768 - recall: 0.7879 - precision: 0.7709 - auc: 0.8710 - val_loss: 0.4083 - val_accuracy: 0.8055 - val_recall: 0.8228 - val_precision: 0.7948 - val_auc: 0.8988\n",
      "Epoch 307/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4430 - accuracy: 0.7777 - recall: 0.7848 - precision: 0.7739 - auc: 0.8713 - val_loss: 0.4109 - val_accuracy: 0.8044 - val_recall: 0.8439 - val_precision: 0.7816 - val_auc: 0.8990\n",
      "Epoch 308/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4440 - accuracy: 0.7770 - recall: 0.7855 - precision: 0.7725 - auc: 0.8705 - val_loss: 0.4124 - val_accuracy: 0.8066 - val_recall: 0.8312 - val_precision: 0.7918 - val_auc: 0.8985\n",
      "Epoch 309/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4417 - accuracy: 0.7791 - recall: 0.7884 - precision: 0.7742 - auc: 0.8723 - val_loss: 0.4108 - val_accuracy: 0.8034 - val_recall: 0.8472 - val_precision: 0.7786 - val_auc: 0.8984\n",
      "Epoch 310/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4414 - accuracy: 0.7779 - recall: 0.7888 - precision: 0.7721 - auc: 0.8719 - val_loss: 0.4111 - val_accuracy: 0.8053 - val_recall: 0.8114 - val_precision: 0.8011 - val_auc: 0.8978\n",
      "Epoch 311/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4406 - accuracy: 0.7793 - recall: 0.7871 - precision: 0.7751 - auc: 0.8729 - val_loss: 0.4097 - val_accuracy: 0.8060 - val_recall: 0.8465 - val_precision: 0.7827 - val_auc: 0.8992\n",
      "Epoch 312/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4418 - accuracy: 0.7783 - recall: 0.7900 - precision: 0.7721 - auc: 0.8723 - val_loss: 0.4117 - val_accuracy: 0.8062 - val_recall: 0.8576 - val_precision: 0.7772 - val_auc: 0.8995\n",
      "Epoch 313/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4420 - accuracy: 0.7789 - recall: 0.7879 - precision: 0.7740 - auc: 0.8720 - val_loss: 0.4110 - val_accuracy: 0.8057 - val_recall: 0.8311 - val_precision: 0.7905 - val_auc: 0.8984\n",
      "Epoch 314/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4409 - accuracy: 0.7782 - recall: 0.7865 - precision: 0.7738 - auc: 0.8724 - val_loss: 0.4100 - val_accuracy: 0.8052 - val_recall: 0.8585 - val_precision: 0.7754 - val_auc: 0.8999\n",
      "Epoch 315/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4410 - accuracy: 0.7786 - recall: 0.7894 - precision: 0.7728 - auc: 0.8721 - val_loss: 0.4082 - val_accuracy: 0.8060 - val_recall: 0.8115 - val_precision: 0.8021 - val_auc: 0.8990\n",
      "Epoch 316/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4431 - accuracy: 0.7775 - recall: 0.7856 - precision: 0.7732 - auc: 0.8713 - val_loss: 0.4159 - val_accuracy: 0.8043 - val_recall: 0.8459 - val_precision: 0.7805 - val_auc: 0.8984\n",
      "Epoch 317/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4436 - accuracy: 0.7783 - recall: 0.7904 - precision: 0.7718 - auc: 0.8713 - val_loss: 0.4125 - val_accuracy: 0.8039 - val_recall: 0.8457 - val_precision: 0.7800 - val_auc: 0.8985\n",
      "Epoch 318/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4406 - accuracy: 0.7791 - recall: 0.7870 - precision: 0.7748 - auc: 0.8730 - val_loss: 0.4166 - val_accuracy: 0.8031 - val_recall: 0.8668 - val_precision: 0.7685 - val_auc: 0.8967\n",
      "Epoch 319/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4438 - accuracy: 0.7773 - recall: 0.7858 - precision: 0.7729 - auc: 0.8709 - val_loss: 0.4121 - val_accuracy: 0.8084 - val_recall: 0.8656 - val_precision: 0.7763 - val_auc: 0.8997\n",
      "Epoch 320/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.7796 - recall: 0.7866 - precision: 0.7758 - auc: 0.8719 - val_loss: 0.4100 - val_accuracy: 0.8053 - val_recall: 0.8637 - val_precision: 0.7731 - val_auc: 0.9003\n",
      "Epoch 321/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4398 - accuracy: 0.7782 - recall: 0.7855 - precision: 0.7744 - auc: 0.8730 - val_loss: 0.4119 - val_accuracy: 0.8046 - val_recall: 0.8730 - val_precision: 0.7675 - val_auc: 0.9001\n",
      "Epoch 322/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4404 - accuracy: 0.7799 - recall: 0.7910 - precision: 0.7740 - auc: 0.8729 - val_loss: 0.4079 - val_accuracy: 0.8076 - val_recall: 0.8525 - val_precision: 0.7819 - val_auc: 0.9011\n",
      "Epoch 323/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4424 - accuracy: 0.7774 - recall: 0.7868 - precision: 0.7724 - auc: 0.8716 - val_loss: 0.4117 - val_accuracy: 0.8059 - val_recall: 0.8429 - val_precision: 0.7844 - val_auc: 0.8991\n",
      "Epoch 324/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4404 - accuracy: 0.7788 - recall: 0.7874 - precision: 0.7742 - auc: 0.8730 - val_loss: 0.4073 - val_accuracy: 0.8084 - val_recall: 0.8246 - val_precision: 0.7983 - val_auc: 0.9008\n",
      "Epoch 325/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4414 - accuracy: 0.7791 - recall: 0.7884 - precision: 0.7742 - auc: 0.8724 - val_loss: 0.4084 - val_accuracy: 0.8067 - val_recall: 0.8476 - val_precision: 0.7830 - val_auc: 0.8998\n",
      "Epoch 326/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4405 - accuracy: 0.7802 - recall: 0.7884 - precision: 0.7758 - auc: 0.8733 - val_loss: 0.4107 - val_accuracy: 0.8057 - val_recall: 0.8698 - val_precision: 0.7706 - val_auc: 0.9003\n",
      "Epoch 327/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4410 - accuracy: 0.7797 - recall: 0.7886 - precision: 0.7750 - auc: 0.8730 - val_loss: 0.4110 - val_accuracy: 0.8064 - val_recall: 0.8531 - val_precision: 0.7798 - val_auc: 0.8999\n",
      "Epoch 328/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4404 - accuracy: 0.7780 - recall: 0.7858 - precision: 0.7739 - auc: 0.8727 - val_loss: 0.4068 - val_accuracy: 0.8067 - val_recall: 0.8309 - val_precision: 0.7921 - val_auc: 0.9006\n",
      "Epoch 329/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4389 - accuracy: 0.7805 - recall: 0.7946 - precision: 0.7729 - auc: 0.8739 - val_loss: 0.4109 - val_accuracy: 0.8063 - val_recall: 0.8733 - val_precision: 0.7697 - val_auc: 0.9000\n",
      "Epoch 330/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.7786 - recall: 0.7899 - precision: 0.7727 - auc: 0.8721 - val_loss: 0.4084 - val_accuracy: 0.8082 - val_recall: 0.8284 - val_precision: 0.7958 - val_auc: 0.9000\n",
      "Epoch 331/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4415 - accuracy: 0.7799 - recall: 0.7909 - precision: 0.7740 - auc: 0.8725 - val_loss: 0.4101 - val_accuracy: 0.8054 - val_recall: 0.8468 - val_precision: 0.7817 - val_auc: 0.8993\n",
      "Epoch 332/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.7783 - recall: 0.7882 - precision: 0.7730 - auc: 0.8719 - val_loss: 0.4091 - val_accuracy: 0.8076 - val_recall: 0.8403 - val_precision: 0.7882 - val_auc: 0.8997\n",
      "Epoch 333/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4393 - accuracy: 0.7805 - recall: 0.7879 - precision: 0.7766 - auc: 0.8740 - val_loss: 0.4096 - val_accuracy: 0.8052 - val_recall: 0.8520 - val_precision: 0.7786 - val_auc: 0.8996\n",
      "Epoch 334/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4414 - accuracy: 0.7788 - recall: 0.7888 - precision: 0.7734 - auc: 0.8724 - val_loss: 0.4098 - val_accuracy: 0.8070 - val_recall: 0.8616 - val_precision: 0.7763 - val_auc: 0.9010\n",
      "Epoch 335/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.7793 - recall: 0.7908 - precision: 0.7731 - auc: 0.8730 - val_loss: 0.4095 - val_accuracy: 0.8083 - val_recall: 0.8608 - val_precision: 0.7786 - val_auc: 0.9017\n",
      "Epoch 336/500\n",
      "965/965 [==============================] - 3s 3ms/step - loss: 0.4395 - accuracy: 0.7789 - recall: 0.7893 - precision: 0.7733 - auc: 0.8736 - val_loss: 0.4089 - val_accuracy: 0.8072 - val_recall: 0.8583 - val_precision: 0.7783 - val_auc: 0.9003\n",
      "Epoch 337/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4402 - accuracy: 0.7794 - recall: 0.7885 - precision: 0.7746 - auc: 0.8732 - val_loss: 0.4099 - val_accuracy: 0.8060 - val_recall: 0.8600 - val_precision: 0.7757 - val_auc: 0.9011\n",
      "Epoch 338/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4389 - accuracy: 0.7801 - recall: 0.7926 - precision: 0.7734 - auc: 0.8736 - val_loss: 0.4088 - val_accuracy: 0.8055 - val_recall: 0.8352 - val_precision: 0.7879 - val_auc: 0.8999\n",
      "Epoch 339/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4394 - accuracy: 0.7799 - recall: 0.7869 - precision: 0.7761 - auc: 0.8737 - val_loss: 0.4108 - val_accuracy: 0.8049 - val_recall: 0.8649 - val_precision: 0.7719 - val_auc: 0.9005\n",
      "Epoch 340/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4369 - accuracy: 0.7806 - recall: 0.7913 - precision: 0.7749 - auc: 0.8750 - val_loss: 0.4101 - val_accuracy: 0.8052 - val_recall: 0.8712 - val_precision: 0.7692 - val_auc: 0.9018\n",
      "Epoch 341/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4399 - accuracy: 0.7789 - recall: 0.7855 - precision: 0.7754 - auc: 0.8730 - val_loss: 0.4101 - val_accuracy: 0.8037 - val_recall: 0.8814 - val_precision: 0.7625 - val_auc: 0.9013\n",
      "Epoch 342/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4388 - accuracy: 0.7801 - recall: 0.7879 - precision: 0.7759 - auc: 0.8738 - val_loss: 0.4080 - val_accuracy: 0.8051 - val_recall: 0.8683 - val_precision: 0.7705 - val_auc: 0.9006\n",
      "Epoch 343/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4401 - accuracy: 0.7776 - recall: 0.7878 - precision: 0.7721 - auc: 0.8728 - val_loss: 0.4067 - val_accuracy: 0.8061 - val_recall: 0.8316 - val_precision: 0.7908 - val_auc: 0.9005\n",
      "Epoch 344/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4402 - accuracy: 0.7803 - recall: 0.7885 - precision: 0.7760 - auc: 0.8733 - val_loss: 0.4086 - val_accuracy: 0.8069 - val_recall: 0.8326 - val_precision: 0.7914 - val_auc: 0.9004\n",
      "Epoch 345/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4368 - accuracy: 0.7819 - recall: 0.7903 - precision: 0.7774 - auc: 0.8755 - val_loss: 0.4051 - val_accuracy: 0.8073 - val_recall: 0.8168 - val_precision: 0.8011 - val_auc: 0.9009\n",
      "Epoch 346/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4397 - accuracy: 0.7792 - recall: 0.7866 - precision: 0.7752 - auc: 0.8732 - val_loss: 0.4080 - val_accuracy: 0.8066 - val_recall: 0.8536 - val_precision: 0.7798 - val_auc: 0.9013\n",
      "Epoch 347/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4394 - accuracy: 0.7802 - recall: 0.7907 - precision: 0.7745 - auc: 0.8736 - val_loss: 0.4096 - val_accuracy: 0.8063 - val_recall: 0.8670 - val_precision: 0.7727 - val_auc: 0.9011\n",
      "Epoch 348/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4413 - accuracy: 0.7785 - recall: 0.7859 - precision: 0.7745 - auc: 0.8725 - val_loss: 0.4086 - val_accuracy: 0.8056 - val_recall: 0.8281 - val_precision: 0.7920 - val_auc: 0.9000\n",
      "Epoch 349/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4397 - accuracy: 0.7794 - recall: 0.7877 - precision: 0.7750 - auc: 0.8734 - val_loss: 0.4046 - val_accuracy: 0.8092 - val_recall: 0.8442 - val_precision: 0.7885 - val_auc: 0.9021\n",
      "Epoch 350/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4412 - accuracy: 0.7787 - recall: 0.7886 - precision: 0.7734 - auc: 0.8728 - val_loss: 0.4062 - val_accuracy: 0.8084 - val_recall: 0.8512 - val_precision: 0.7836 - val_auc: 0.9009\n",
      "Epoch 351/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4369 - accuracy: 0.7812 - recall: 0.7911 - precision: 0.7758 - auc: 0.8752 - val_loss: 0.4036 - val_accuracy: 0.8100 - val_recall: 0.8042 - val_precision: 0.8132 - val_auc: 0.9011\n",
      "Epoch 352/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4407 - accuracy: 0.7798 - recall: 0.7854 - precision: 0.7769 - auc: 0.8730 - val_loss: 0.4065 - val_accuracy: 0.8095 - val_recall: 0.8544 - val_precision: 0.7835 - val_auc: 0.9017\n",
      "Epoch 353/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4378 - accuracy: 0.7806 - recall: 0.7960 - precision: 0.7723 - auc: 0.8746 - val_loss: 0.4082 - val_accuracy: 0.8069 - val_recall: 0.8465 - val_precision: 0.7840 - val_auc: 0.9012\n",
      "Epoch 354/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4384 - accuracy: 0.7814 - recall: 0.7887 - precision: 0.7775 - auc: 0.8747 - val_loss: 0.4079 - val_accuracy: 0.8068 - val_recall: 0.8300 - val_precision: 0.7927 - val_auc: 0.9000\n",
      "Epoch 355/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4404 - accuracy: 0.7783 - recall: 0.7860 - precision: 0.7742 - auc: 0.8725 - val_loss: 0.4118 - val_accuracy: 0.8048 - val_recall: 0.8801 - val_precision: 0.7645 - val_auc: 0.9010\n",
      "Epoch 356/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4362 - accuracy: 0.7824 - recall: 0.7957 - precision: 0.7752 - auc: 0.8756 - val_loss: 0.4080 - val_accuracy: 0.8066 - val_recall: 0.8731 - val_precision: 0.7703 - val_auc: 0.9016\n",
      "Epoch 357/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4398 - accuracy: 0.7797 - recall: 0.7897 - precision: 0.7743 - auc: 0.8731 - val_loss: 0.4059 - val_accuracy: 0.8071 - val_recall: 0.8439 - val_precision: 0.7856 - val_auc: 0.9014\n",
      "Epoch 358/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.7814 - recall: 0.7939 - precision: 0.7746 - auc: 0.8741 - val_loss: 0.4088 - val_accuracy: 0.8065 - val_recall: 0.8612 - val_precision: 0.7759 - val_auc: 0.9013\n",
      "Epoch 359/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4418 - accuracy: 0.7786 - recall: 0.7886 - precision: 0.7733 - auc: 0.8722 - val_loss: 0.4069 - val_accuracy: 0.8093 - val_recall: 0.8350 - val_precision: 0.7938 - val_auc: 0.9021\n",
      "Epoch 360/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4397 - accuracy: 0.7808 - recall: 0.7864 - precision: 0.7778 - auc: 0.8740 - val_loss: 0.4077 - val_accuracy: 0.8066 - val_recall: 0.8268 - val_precision: 0.7942 - val_auc: 0.9008\n",
      "Epoch 361/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4383 - accuracy: 0.7805 - recall: 0.7905 - precision: 0.7751 - auc: 0.8743 - val_loss: 0.4112 - val_accuracy: 0.8093 - val_recall: 0.8463 - val_precision: 0.7875 - val_auc: 0.9015\n",
      "Epoch 362/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4385 - accuracy: 0.7810 - recall: 0.7911 - precision: 0.7755 - auc: 0.8743 - val_loss: 0.4056 - val_accuracy: 0.8077 - val_recall: 0.8377 - val_precision: 0.7899 - val_auc: 0.9015\n",
      "Epoch 363/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4387 - accuracy: 0.7815 - recall: 0.7938 - precision: 0.7748 - auc: 0.8741 - val_loss: 0.4054 - val_accuracy: 0.8075 - val_recall: 0.8542 - val_precision: 0.7808 - val_auc: 0.9019\n",
      "Epoch 364/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4382 - accuracy: 0.7815 - recall: 0.7924 - precision: 0.7757 - auc: 0.8746 - val_loss: 0.4066 - val_accuracy: 0.8069 - val_recall: 0.8642 - val_precision: 0.7749 - val_auc: 0.9009\n",
      "Epoch 365/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4382 - accuracy: 0.7806 - recall: 0.7886 - precision: 0.7764 - auc: 0.8744 - val_loss: 0.4037 - val_accuracy: 0.8097 - val_recall: 0.8406 - val_precision: 0.7913 - val_auc: 0.9020\n",
      "Epoch 366/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4390 - accuracy: 0.7804 - recall: 0.7889 - precision: 0.7758 - auc: 0.8737 - val_loss: 0.4106 - val_accuracy: 0.8042 - val_recall: 0.8751 - val_precision: 0.7660 - val_auc: 0.9001\n",
      "Epoch 367/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4381 - accuracy: 0.7802 - recall: 0.7938 - precision: 0.7730 - auc: 0.8745 - val_loss: 0.4060 - val_accuracy: 0.8087 - val_recall: 0.8571 - val_precision: 0.7811 - val_auc: 0.9026\n",
      "Epoch 368/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4400 - accuracy: 0.7795 - recall: 0.7879 - precision: 0.7750 - auc: 0.8735 - val_loss: 0.4100 - val_accuracy: 0.8085 - val_recall: 0.8453 - val_precision: 0.7869 - val_auc: 0.9007\n",
      "Epoch 369/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4388 - accuracy: 0.7803 - recall: 0.7897 - precision: 0.7753 - auc: 0.8740 - val_loss: 0.4066 - val_accuracy: 0.8086 - val_recall: 0.8505 - val_precision: 0.7843 - val_auc: 0.9016\n",
      "Epoch 370/500\n",
      "965/965 [==============================] - 2s 2ms/step - loss: 0.4369 - accuracy: 0.7809 - recall: 0.7909 - precision: 0.7756 - auc: 0.8749 - val_loss: 0.4057 - val_accuracy: 0.8090 - val_recall: 0.8524 - val_precision: 0.7839 - val_auc: 0.9022\n",
      "Epoch 371/500\n",
      "965/965 [==============================] - 2s 3ms/step - loss: 0.4371 - accuracy: 0.7808 - recall: 0.7895 - precision: 0.7762 - auc: 0.8749 - val_loss: 0.4082 - val_accuracy: 0.8076 - val_recall: 0.8607 - val_precision: 0.7777 - val_auc: 0.9019\n",
      "3857/3857 [==============================] - 3s 759us/step\n",
      "965/965 [==============================] - 1s 858us/step\n",
      "Acurácia no conjunto de treinamento: 0.8749027848243713\n",
      "Acurácia no conjunto de teste: 0.8099837899208069\n",
      "AUC no conjunto de treinamento: 0.9584240410167665\n",
      "AUC no conjunto de teste: 0.9010743727014678\n",
      "965/965 [==============================] - 1s 788us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.81      0.82      0.81     15448\n",
      "    Classe 1       0.81      0.80      0.81     15402\n",
      "\n",
      "    accuracy                           0.81     30850\n",
      "   macro avg       0.81      0.81      0.81     30850\n",
      "weighted avg       0.81      0.81      0.81     30850\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2, l1_l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "# classes = np.unique(y_train)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "# class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Criação do modelo com possivelmente mais capacidade\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))  # Aumento na capacidade da primeira camada\n",
    "model.add(Dropout(0.3))  # Diminuição do dropout\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Diminuição do dropout\n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Otimizador com escalonamento de taxa de aprendizado\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', tf.metrics.Recall(), tf.metrics.Precision(), tf.metrics.AUC()])\n",
    "\n",
    "# Ajuste no callback de EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=128,  # Experimentar com um batch size diferente\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    # class_weight=class_weights,\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva de Aprendizado: A curva de aprendizado mostra que a acurácia de validação e treinamento estão se aproximando uma da outra conforme o número de épocas aumenta, o que é um bom sinal de que o modelo não está sofrendo de overfitting significativo.\n",
    "\n",
    "Acurácia e AUC: A acurácia e a Área Sob a Curva ROC (AUC) no conjunto de teste são bastante altas, o que sugere que o modelo tem um bom desempenho geral.\n",
    "\n",
    "Recall e Precision: Os valores de recall e precisão são bastante equilibrados para as previsões no conjunto de validação, indicando que o modelo tem um desempenho bom e equilibrado em relação a ambas as classes.\n",
    "\n",
    "Relatório de Classificação: O relatório de classificação mostra resultados quase simétricos para as classes 0 e 1, com uma precisão, recall e pontuação F1 bastante semelhantes para ambas, o que sugere que o modelo está tratando ambas as classes de forma equitativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965/965 [==============================] - 1s 728us/step\n",
      "Threshold: 0.10, Precision: 0.587, Recall: 0.998, F1 Score: 0.739, Accuracy: 0.648\n",
      "Threshold: 0.11, Precision: 0.593, Recall: 0.997, F1 Score: 0.744, Accuracy: 0.657\n",
      "Threshold: 0.12, Precision: 0.599, Recall: 0.996, F1 Score: 0.748, Accuracy: 0.665\n",
      "Threshold: 0.13, Precision: 0.605, Recall: 0.996, F1 Score: 0.753, Accuracy: 0.674\n",
      "Threshold: 0.14, Precision: 0.611, Recall: 0.995, F1 Score: 0.757, Accuracy: 0.681\n",
      "Threshold: 0.15, Precision: 0.616, Recall: 0.995, F1 Score: 0.761, Accuracy: 0.688\n",
      "Threshold: 0.16, Precision: 0.621, Recall: 0.994, F1 Score: 0.764, Accuracy: 0.694\n",
      "Threshold: 0.17, Precision: 0.627, Recall: 0.993, F1 Score: 0.768, Accuracy: 0.701\n",
      "Threshold: 0.18, Precision: 0.632, Recall: 0.992, F1 Score: 0.772, Accuracy: 0.708\n",
      "Threshold: 0.19, Precision: 0.637, Recall: 0.990, F1 Score: 0.775, Accuracy: 0.713\n",
      "Threshold: 0.20, Precision: 0.641, Recall: 0.989, F1 Score: 0.778, Accuracy: 0.718\n",
      "Threshold: 0.21, Precision: 0.646, Recall: 0.987, F1 Score: 0.781, Accuracy: 0.724\n",
      "Threshold: 0.22, Precision: 0.651, Recall: 0.986, F1 Score: 0.784, Accuracy: 0.729\n",
      "Threshold: 0.23, Precision: 0.655, Recall: 0.984, F1 Score: 0.787, Accuracy: 0.733\n",
      "Threshold: 0.24, Precision: 0.659, Recall: 0.983, F1 Score: 0.789, Accuracy: 0.738\n",
      "Threshold: 0.25, Precision: 0.664, Recall: 0.982, F1 Score: 0.792, Accuracy: 0.743\n",
      "Threshold: 0.26, Precision: 0.668, Recall: 0.980, F1 Score: 0.795, Accuracy: 0.747\n",
      "Threshold: 0.27, Precision: 0.672, Recall: 0.977, F1 Score: 0.796, Accuracy: 0.750\n",
      "Threshold: 0.28, Precision: 0.676, Recall: 0.975, F1 Score: 0.798, Accuracy: 0.754\n",
      "Threshold: 0.29, Precision: 0.681, Recall: 0.973, F1 Score: 0.801, Accuracy: 0.759\n",
      "Threshold: 0.30, Precision: 0.685, Recall: 0.971, F1 Score: 0.803, Accuracy: 0.763\n",
      "Threshold: 0.31, Precision: 0.689, Recall: 0.969, F1 Score: 0.805, Accuracy: 0.766\n",
      "Threshold: 0.32, Precision: 0.693, Recall: 0.966, F1 Score: 0.807, Accuracy: 0.770\n",
      "Threshold: 0.33, Precision: 0.698, Recall: 0.962, F1 Score: 0.809, Accuracy: 0.773\n",
      "Threshold: 0.34, Precision: 0.701, Recall: 0.959, F1 Score: 0.810, Accuracy: 0.776\n",
      "Threshold: 0.35, Precision: 0.706, Recall: 0.955, F1 Score: 0.812, Accuracy: 0.779\n",
      "Threshold: 0.36, Precision: 0.710, Recall: 0.951, F1 Score: 0.813, Accuracy: 0.781\n",
      "Threshold: 0.37, Precision: 0.714, Recall: 0.947, F1 Score: 0.814, Accuracy: 0.784\n",
      "Threshold: 0.38, Precision: 0.719, Recall: 0.942, F1 Score: 0.816, Accuracy: 0.787\n",
      "Threshold: 0.39, Precision: 0.724, Recall: 0.937, F1 Score: 0.817, Accuracy: 0.790\n",
      "Threshold: 0.40, Precision: 0.730, Recall: 0.931, F1 Score: 0.818, Accuracy: 0.793\n",
      "Threshold: 0.41, Precision: 0.735, Recall: 0.924, F1 Score: 0.819, Accuracy: 0.796\n",
      "Threshold: 0.42, Precision: 0.741, Recall: 0.917, F1 Score: 0.819, Accuracy: 0.798\n",
      "Threshold: 0.43, Precision: 0.747, Recall: 0.908, F1 Score: 0.819, Accuracy: 0.800\n",
      "Threshold: 0.44, Precision: 0.752, Recall: 0.897, F1 Score: 0.819, Accuracy: 0.801\n",
      "Threshold: 0.45, Precision: 0.760, Recall: 0.883, F1 Score: 0.817, Accuracy: 0.803\n",
      "Threshold: 0.46, Precision: 0.770, Recall: 0.867, F1 Score: 0.816, Accuracy: 0.805\n",
      "Threshold: 0.47, Precision: 0.781, Recall: 0.851, F1 Score: 0.814, Accuracy: 0.806\n",
      "Threshold: 0.48, Precision: 0.793, Recall: 0.834, F1 Score: 0.813, Accuracy: 0.808\n",
      "Threshold: 0.49, Precision: 0.803, Recall: 0.818, F1 Score: 0.810, Accuracy: 0.809\n",
      "Threshold: 0.50, Precision: 0.813, Recall: 0.804, F1 Score: 0.809, Accuracy: 0.810\n",
      "Threshold: 0.51, Precision: 0.822, Recall: 0.793, F1 Score: 0.807, Accuracy: 0.811\n",
      "Threshold: 0.52, Precision: 0.829, Recall: 0.783, F1 Score: 0.805, Accuracy: 0.811\n",
      "Threshold: 0.53, Precision: 0.835, Recall: 0.773, F1 Score: 0.803, Accuracy: 0.810\n",
      "Threshold: 0.54, Precision: 0.840, Recall: 0.761, F1 Score: 0.799, Accuracy: 0.808\n",
      "Threshold: 0.55, Precision: 0.845, Recall: 0.752, F1 Score: 0.796, Accuracy: 0.807\n",
      "Threshold: 0.56, Precision: 0.850, Recall: 0.743, F1 Score: 0.793, Accuracy: 0.806\n",
      "Threshold: 0.57, Precision: 0.854, Recall: 0.735, F1 Score: 0.790, Accuracy: 0.805\n",
      "Threshold: 0.58, Precision: 0.858, Recall: 0.725, F1 Score: 0.786, Accuracy: 0.803\n",
      "Threshold: 0.59, Precision: 0.863, Recall: 0.716, F1 Score: 0.783, Accuracy: 0.801\n",
      "Threshold: 0.60, Precision: 0.868, Recall: 0.706, F1 Score: 0.778, Accuracy: 0.799\n",
      "Threshold: 0.61, Precision: 0.872, Recall: 0.696, F1 Score: 0.774, Accuracy: 0.797\n",
      "Threshold: 0.62, Precision: 0.876, Recall: 0.686, F1 Score: 0.770, Accuracy: 0.795\n",
      "Threshold: 0.63, Precision: 0.881, Recall: 0.678, F1 Score: 0.766, Accuracy: 0.793\n",
      "Threshold: 0.64, Precision: 0.884, Recall: 0.668, F1 Score: 0.761, Accuracy: 0.791\n",
      "Threshold: 0.65, Precision: 0.888, Recall: 0.658, F1 Score: 0.756, Accuracy: 0.788\n",
      "Threshold: 0.66, Precision: 0.892, Recall: 0.646, F1 Score: 0.750, Accuracy: 0.784\n",
      "Threshold: 0.67, Precision: 0.896, Recall: 0.637, F1 Score: 0.745, Accuracy: 0.782\n",
      "Threshold: 0.68, Precision: 0.899, Recall: 0.627, F1 Score: 0.739, Accuracy: 0.779\n",
      "Threshold: 0.69, Precision: 0.902, Recall: 0.617, F1 Score: 0.733, Accuracy: 0.775\n",
      "Threshold: 0.70, Precision: 0.903, Recall: 0.606, F1 Score: 0.725, Accuracy: 0.771\n",
      "Threshold: 0.71, Precision: 0.907, Recall: 0.596, F1 Score: 0.719, Accuracy: 0.768\n",
      "Threshold: 0.72, Precision: 0.910, Recall: 0.584, F1 Score: 0.712, Accuracy: 0.764\n",
      "Threshold: 0.73, Precision: 0.913, Recall: 0.570, F1 Score: 0.702, Accuracy: 0.758\n",
      "Threshold: 0.74, Precision: 0.915, Recall: 0.558, F1 Score: 0.694, Accuracy: 0.754\n",
      "Threshold: 0.75, Precision: 0.917, Recall: 0.547, F1 Score: 0.686, Accuracy: 0.749\n",
      "Threshold: 0.76, Precision: 0.921, Recall: 0.534, F1 Score: 0.676, Accuracy: 0.744\n",
      "Threshold: 0.77, Precision: 0.924, Recall: 0.519, F1 Score: 0.664, Accuracy: 0.738\n",
      "Threshold: 0.78, Precision: 0.927, Recall: 0.506, F1 Score: 0.654, Accuracy: 0.733\n",
      "Threshold: 0.79, Precision: 0.930, Recall: 0.491, F1 Score: 0.642, Accuracy: 0.727\n",
      "Threshold: 0.80, Precision: 0.934, Recall: 0.475, F1 Score: 0.630, Accuracy: 0.721\n",
      "Threshold: 0.81, Precision: 0.936, Recall: 0.459, F1 Score: 0.616, Accuracy: 0.714\n",
      "Threshold: 0.82, Precision: 0.938, Recall: 0.443, F1 Score: 0.602, Accuracy: 0.707\n",
      "Threshold: 0.83, Precision: 0.940, Recall: 0.426, F1 Score: 0.587, Accuracy: 0.700\n",
      "Threshold: 0.84, Precision: 0.943, Recall: 0.408, F1 Score: 0.570, Accuracy: 0.692\n",
      "Threshold: 0.85, Precision: 0.944, Recall: 0.389, F1 Score: 0.551, Accuracy: 0.684\n",
      "Threshold: 0.86, Precision: 0.947, Recall: 0.370, F1 Score: 0.532, Accuracy: 0.675\n",
      "Threshold: 0.87, Precision: 0.948, Recall: 0.349, F1 Score: 0.511, Accuracy: 0.666\n",
      "Threshold: 0.88, Precision: 0.948, Recall: 0.327, F1 Score: 0.486, Accuracy: 0.655\n",
      "Threshold: 0.89, Precision: 0.948, Recall: 0.302, F1 Score: 0.458, Accuracy: 0.643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
