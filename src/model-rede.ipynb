{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'blockedShotsHome',\n",
       "       'blockedShotsAway', 'league', 'corners_home', 'corners_away',\n",
       "       'shotsOffgoal_home', 'shotsOffgoal_away', 'shotsOngoal_home',\n",
       "       'shotsOngoal_away', 'yellowcards_home', 'yellowcards_away',\n",
       "       'fouls_home', 'fouls_away', 'offsides_home', 'offsides_away',\n",
       "       'tackles_home', 'tackles_away', 'result', 'match_id',\n",
       "       'possessiontime_away', 'possessiontime_home', 'shotsOnGoalEfficiency',\n",
       "       'attackPressure', 'shotAccuracy_home', 'shotAccuracy_away',\n",
       "       'possessionControl', 'passRisk', 'defensiveDiscipline',\n",
       "       'defensiveEfficacy', 'defensiveAggression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "483/483 [==============================] - 3s 3ms/step - loss: 0.6891 - accuracy: 0.5340 - recall_1: 0.5368 - precision_1: 0.5340 - auc_1: 0.5499 - val_loss: 0.6848 - val_accuracy: 0.5454 - val_recall_1: 0.4893 - val_precision_1: 0.5503 - val_auc_1: 0.5670\n",
      "Epoch 2/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.6817 - accuracy: 0.5569 - recall_1: 0.5791 - precision_1: 0.5547 - auc_1: 0.5820 - val_loss: 0.6782 - val_accuracy: 0.5652 - val_recall_1: 0.4545 - val_precision_1: 0.5828 - val_auc_1: 0.5983\n",
      "Epoch 3/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.6741 - accuracy: 0.5707 - recall_1: 0.5932 - precision_1: 0.5678 - auc_1: 0.6042 - val_loss: 0.6695 - val_accuracy: 0.5789 - val_recall_1: 0.4990 - val_precision_1: 0.5930 - val_auc_1: 0.6195\n",
      "Epoch 4/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.6638 - accuracy: 0.5885 - recall_1: 0.6044 - precision_1: 0.5860 - auc_1: 0.6303 - val_loss: 0.6587 - val_accuracy: 0.5959 - val_recall_1: 0.5538 - val_precision_1: 0.6040 - val_auc_1: 0.6425\n",
      "Epoch 5/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.6530 - accuracy: 0.6032 - recall_1: 0.6159 - precision_1: 0.6009 - auc_1: 0.6513 - val_loss: 0.6440 - val_accuracy: 0.6155 - val_recall_1: 0.6347 - val_precision_1: 0.6106 - val_auc_1: 0.6723\n",
      "Epoch 6/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.6415 - accuracy: 0.6188 - recall_1: 0.6372 - precision_1: 0.6148 - auc_1: 0.6726 - val_loss: 0.6331 - val_accuracy: 0.6350 - val_recall_1: 0.6512 - val_precision_1: 0.6301 - val_auc_1: 0.6956\n",
      "Epoch 7/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6311 - recall_1: 0.6389 - precision_1: 0.6292 - auc_1: 0.6907 - val_loss: 0.6168 - val_accuracy: 0.6472 - val_recall_1: 0.6143 - val_precision_1: 0.6569 - val_auc_1: 0.7147\n",
      "Epoch 8/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.6199 - accuracy: 0.6425 - recall_1: 0.6534 - precision_1: 0.6396 - auc_1: 0.7059 - val_loss: 0.6031 - val_accuracy: 0.6631 - val_recall_1: 0.6704 - val_precision_1: 0.6601 - val_auc_1: 0.7343\n",
      "Epoch 9/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.6092 - accuracy: 0.6514 - recall_1: 0.6612 - precision_1: 0.6487 - auc_1: 0.7191 - val_loss: 0.5945 - val_accuracy: 0.6714 - val_recall_1: 0.6693 - val_precision_1: 0.6715 - val_auc_1: 0.7450\n",
      "Epoch 10/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5988 - accuracy: 0.6620 - recall_1: 0.6749 - precision_1: 0.6581 - auc_1: 0.7324 - val_loss: 0.5827 - val_accuracy: 0.6809 - val_recall_1: 0.6723 - val_precision_1: 0.6834 - val_auc_1: 0.7581\n",
      "Epoch 11/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6694 - recall_1: 0.6786 - precision_1: 0.6665 - auc_1: 0.7434 - val_loss: 0.5766 - val_accuracy: 0.6900 - val_recall_1: 0.7831 - val_precision_1: 0.6596 - val_auc_1: 0.7706\n",
      "Epoch 12/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5840 - accuracy: 0.6755 - recall_1: 0.6876 - precision_1: 0.6715 - auc_1: 0.7505 - val_loss: 0.5639 - val_accuracy: 0.6972 - val_recall_1: 0.6667 - val_precision_1: 0.7094 - val_auc_1: 0.7800\n",
      "Epoch 13/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.5742 - accuracy: 0.6826 - recall_1: 0.6951 - precision_1: 0.6782 - auc_1: 0.7605 - val_loss: 0.5574 - val_accuracy: 0.7021 - val_recall_1: 0.7476 - val_precision_1: 0.6847 - val_auc_1: 0.7853\n",
      "Epoch 14/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.6870 - recall_1: 0.7054 - precision_1: 0.6806 - auc_1: 0.7657 - val_loss: 0.5496 - val_accuracy: 0.7070 - val_recall_1: 0.7061 - val_precision_1: 0.7067 - val_auc_1: 0.7927\n",
      "Epoch 15/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.6929 - recall_1: 0.7079 - precision_1: 0.6875 - auc_1: 0.7732 - val_loss: 0.5442 - val_accuracy: 0.7091 - val_recall_1: 0.7019 - val_precision_1: 0.7115 - val_auc_1: 0.7960\n",
      "Epoch 16/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5577 - accuracy: 0.6962 - recall_1: 0.7124 - precision_1: 0.6902 - auc_1: 0.7781 - val_loss: 0.5406 - val_accuracy: 0.7174 - val_recall_1: 0.7803 - val_precision_1: 0.6926 - val_auc_1: 0.8035\n",
      "Epoch 17/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5532 - accuracy: 0.7006 - recall_1: 0.7175 - precision_1: 0.6942 - auc_1: 0.7829 - val_loss: 0.5314 - val_accuracy: 0.7219 - val_recall_1: 0.7176 - val_precision_1: 0.7233 - val_auc_1: 0.8110\n",
      "Epoch 18/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5475 - accuracy: 0.7058 - recall_1: 0.7235 - precision_1: 0.6990 - auc_1: 0.7885 - val_loss: 0.5258 - val_accuracy: 0.7273 - val_recall_1: 0.6959 - val_precision_1: 0.7418 - val_auc_1: 0.8168\n",
      "Epoch 19/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5429 - accuracy: 0.7067 - recall_1: 0.7179 - precision_1: 0.7023 - auc_1: 0.7924 - val_loss: 0.5244 - val_accuracy: 0.7307 - val_recall_1: 0.7761 - val_precision_1: 0.7110 - val_auc_1: 0.8198\n",
      "Epoch 20/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5415 - accuracy: 0.7095 - recall_1: 0.7271 - precision_1: 0.7025 - auc_1: 0.7937 - val_loss: 0.5205 - val_accuracy: 0.7335 - val_recall_1: 0.7573 - val_precision_1: 0.7224 - val_auc_1: 0.8225\n",
      "Epoch 21/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5376 - accuracy: 0.7127 - recall_1: 0.7281 - precision_1: 0.7064 - auc_1: 0.7978 - val_loss: 0.5153 - val_accuracy: 0.7362 - val_recall_1: 0.7517 - val_precision_1: 0.7285 - val_auc_1: 0.8255\n",
      "Epoch 22/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.5322 - accuracy: 0.7163 - recall_1: 0.7313 - precision_1: 0.7102 - auc_1: 0.8023 - val_loss: 0.5092 - val_accuracy: 0.7389 - val_recall_1: 0.7763 - val_precision_1: 0.7218 - val_auc_1: 0.8305\n",
      "Epoch 23/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7160 - recall_1: 0.7340 - precision_1: 0.7086 - auc_1: 0.8036 - val_loss: 0.5063 - val_accuracy: 0.7438 - val_recall_1: 0.7733 - val_precision_1: 0.7296 - val_auc_1: 0.8337\n",
      "Epoch 24/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.5260 - accuracy: 0.7211 - recall_1: 0.7376 - precision_1: 0.7141 - auc_1: 0.8081 - val_loss: 0.5017 - val_accuracy: 0.7454 - val_recall_1: 0.7456 - val_precision_1: 0.7448 - val_auc_1: 0.8366\n",
      "Epoch 25/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.7246 - recall_1: 0.7416 - precision_1: 0.7174 - auc_1: 0.8111 - val_loss: 0.4984 - val_accuracy: 0.7473 - val_recall_1: 0.7205 - val_precision_1: 0.7607 - val_auc_1: 0.8389\n",
      "Epoch 26/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.7251 - recall_1: 0.7375 - precision_1: 0.7197 - auc_1: 0.8127 - val_loss: 0.4974 - val_accuracy: 0.7500 - val_recall_1: 0.8057 - val_precision_1: 0.7244 - val_auc_1: 0.8410\n",
      "Epoch 27/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.5195 - accuracy: 0.7241 - recall_1: 0.7400 - precision_1: 0.7173 - auc_1: 0.8136 - val_loss: 0.4958 - val_accuracy: 0.7501 - val_recall_1: 0.7370 - val_precision_1: 0.7563 - val_auc_1: 0.8420\n",
      "Epoch 28/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7279 - recall_1: 0.7412 - precision_1: 0.7221 - auc_1: 0.8153 - val_loss: 0.4935 - val_accuracy: 0.7494 - val_recall_1: 0.7243 - val_precision_1: 0.7621 - val_auc_1: 0.8412\n",
      "Epoch 29/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7304 - recall_1: 0.7408 - precision_1: 0.7259 - auc_1: 0.8193 - val_loss: 0.4870 - val_accuracy: 0.7565 - val_recall_1: 0.7508 - val_precision_1: 0.7589 - val_auc_1: 0.8470\n",
      "Epoch 30/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5095 - accuracy: 0.7335 - recall_1: 0.7457 - precision_1: 0.7281 - auc_1: 0.8224 - val_loss: 0.4905 - val_accuracy: 0.7553 - val_recall_1: 0.7715 - val_precision_1: 0.7467 - val_auc_1: 0.8448\n",
      "Epoch 31/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.7342 - recall_1: 0.7448 - precision_1: 0.7294 - auc_1: 0.8245 - val_loss: 0.4852 - val_accuracy: 0.7581 - val_recall_1: 0.7853 - val_precision_1: 0.7443 - val_auc_1: 0.8489\n",
      "Epoch 32/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.7346 - recall_1: 0.7511 - precision_1: 0.7273 - auc_1: 0.8235 - val_loss: 0.4834 - val_accuracy: 0.7576 - val_recall_1: 0.7220 - val_precision_1: 0.7768 - val_auc_1: 0.8508\n",
      "Epoch 33/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.7376 - recall_1: 0.7477 - precision_1: 0.7330 - auc_1: 0.8270 - val_loss: 0.4801 - val_accuracy: 0.7622 - val_recall_1: 0.7342 - val_precision_1: 0.7772 - val_auc_1: 0.8535\n",
      "Epoch 34/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.7385 - recall_1: 0.7482 - precision_1: 0.7340 - auc_1: 0.8287 - val_loss: 0.4753 - val_accuracy: 0.7639 - val_recall_1: 0.7888 - val_precision_1: 0.7509 - val_auc_1: 0.8566\n",
      "Epoch 35/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7399 - recall_1: 0.7556 - precision_1: 0.7327 - auc_1: 0.8303 - val_loss: 0.4751 - val_accuracy: 0.7624 - val_recall_1: 0.7335 - val_precision_1: 0.7779 - val_auc_1: 0.8564\n",
      "Epoch 36/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.7386 - recall_1: 0.7477 - precision_1: 0.7345 - auc_1: 0.8305 - val_loss: 0.4726 - val_accuracy: 0.7664 - val_recall_1: 0.8044 - val_precision_1: 0.7471 - val_auc_1: 0.8584\n",
      "Epoch 37/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7422 - recall_1: 0.7561 - precision_1: 0.7358 - auc_1: 0.8328 - val_loss: 0.4694 - val_accuracy: 0.7681 - val_recall_1: 0.7757 - val_precision_1: 0.7635 - val_auc_1: 0.8598\n",
      "Epoch 38/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.7434 - recall_1: 0.7539 - precision_1: 0.7385 - auc_1: 0.8346 - val_loss: 0.4695 - val_accuracy: 0.7681 - val_recall_1: 0.7905 - val_precision_1: 0.7561 - val_auc_1: 0.8604\n",
      "Epoch 39/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7423 - recall_1: 0.7523 - precision_1: 0.7376 - auc_1: 0.8337 - val_loss: 0.4737 - val_accuracy: 0.7632 - val_recall_1: 0.8375 - val_precision_1: 0.7287 - val_auc_1: 0.8586\n",
      "Epoch 40/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7447 - recall_1: 0.7611 - precision_1: 0.7370 - auc_1: 0.8362 - val_loss: 0.4653 - val_accuracy: 0.7665 - val_recall_1: 0.7487 - val_precision_1: 0.7758 - val_auc_1: 0.8616\n",
      "Epoch 41/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.7471 - recall_1: 0.7574 - precision_1: 0.7423 - auc_1: 0.8375 - val_loss: 0.4643 - val_accuracy: 0.7705 - val_recall_1: 0.7898 - val_precision_1: 0.7600 - val_auc_1: 0.8627\n",
      "Epoch 42/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7480 - recall_1: 0.7580 - precision_1: 0.7433 - auc_1: 0.8391 - val_loss: 0.4640 - val_accuracy: 0.7716 - val_recall_1: 0.7632 - val_precision_1: 0.7757 - val_auc_1: 0.8637\n",
      "Epoch 43/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7478 - recall_1: 0.7577 - precision_1: 0.7431 - auc_1: 0.8392 - val_loss: 0.4630 - val_accuracy: 0.7734 - val_recall_1: 0.7856 - val_precision_1: 0.7663 - val_auc_1: 0.8647\n",
      "Epoch 44/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7492 - recall_1: 0.7590 - precision_1: 0.7446 - auc_1: 0.8400 - val_loss: 0.4615 - val_accuracy: 0.7725 - val_recall_1: 0.7728 - val_precision_1: 0.7719 - val_auc_1: 0.8647\n",
      "Epoch 45/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7491 - recall_1: 0.7581 - precision_1: 0.7448 - auc_1: 0.8402 - val_loss: 0.4602 - val_accuracy: 0.7754 - val_recall_1: 0.7761 - val_precision_1: 0.7745 - val_auc_1: 0.8670\n",
      "Epoch 46/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7503 - recall_1: 0.7600 - precision_1: 0.7457 - auc_1: 0.8418 - val_loss: 0.4604 - val_accuracy: 0.7733 - val_recall_1: 0.8009 - val_precision_1: 0.7584 - val_auc_1: 0.8664\n",
      "Epoch 47/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.7524 - recall_1: 0.7641 - precision_1: 0.7468 - auc_1: 0.8446 - val_loss: 0.4576 - val_accuracy: 0.7785 - val_recall_1: 0.7636 - val_precision_1: 0.7865 - val_auc_1: 0.8684\n",
      "Epoch 48/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7515 - recall_1: 0.7617 - precision_1: 0.7466 - auc_1: 0.8434 - val_loss: 0.4544 - val_accuracy: 0.7792 - val_recall_1: 0.8063 - val_precision_1: 0.7643 - val_auc_1: 0.8708\n",
      "Epoch 49/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7533 - recall_1: 0.7638 - precision_1: 0.7482 - auc_1: 0.8443 - val_loss: 0.4554 - val_accuracy: 0.7792 - val_recall_1: 0.7941 - val_precision_1: 0.7707 - val_auc_1: 0.8700\n",
      "Epoch 50/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.7535 - recall_1: 0.7638 - precision_1: 0.7485 - auc_1: 0.8445 - val_loss: 0.4551 - val_accuracy: 0.7788 - val_recall_1: 0.8140 - val_precision_1: 0.7600 - val_auc_1: 0.8717\n",
      "Epoch 51/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.7540 - recall_1: 0.7650 - precision_1: 0.7486 - auc_1: 0.8464 - val_loss: 0.4537 - val_accuracy: 0.7790 - val_recall_1: 0.7987 - val_precision_1: 0.7679 - val_auc_1: 0.8710\n",
      "Epoch 52/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4787 - accuracy: 0.7548 - recall_1: 0.7665 - precision_1: 0.7492 - auc_1: 0.8464 - val_loss: 0.4516 - val_accuracy: 0.7813 - val_recall_1: 0.8095 - val_precision_1: 0.7658 - val_auc_1: 0.8728\n",
      "Epoch 53/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4774 - accuracy: 0.7545 - recall_1: 0.7631 - precision_1: 0.7503 - auc_1: 0.8471 - val_loss: 0.4509 - val_accuracy: 0.7802 - val_recall_1: 0.7979 - val_precision_1: 0.7701 - val_auc_1: 0.8724\n",
      "Epoch 54/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4759 - accuracy: 0.7559 - recall_1: 0.7664 - precision_1: 0.7508 - auc_1: 0.8482 - val_loss: 0.4488 - val_accuracy: 0.7803 - val_recall_1: 0.7978 - val_precision_1: 0.7703 - val_auc_1: 0.8728\n",
      "Epoch 55/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4751 - accuracy: 0.7569 - recall_1: 0.7695 - precision_1: 0.7508 - auc_1: 0.8491 - val_loss: 0.4504 - val_accuracy: 0.7785 - val_recall_1: 0.7431 - val_precision_1: 0.7992 - val_auc_1: 0.8731\n",
      "Epoch 56/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.7586 - recall_1: 0.7667 - precision_1: 0.7546 - auc_1: 0.8499 - val_loss: 0.4478 - val_accuracy: 0.7806 - val_recall_1: 0.8198 - val_precision_1: 0.7598 - val_auc_1: 0.8744\n",
      "Epoch 57/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4736 - accuracy: 0.7568 - recall_1: 0.7657 - precision_1: 0.7524 - auc_1: 0.8499 - val_loss: 0.4441 - val_accuracy: 0.7841 - val_recall_1: 0.7798 - val_precision_1: 0.7861 - val_auc_1: 0.8748\n",
      "Epoch 58/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4719 - accuracy: 0.7588 - recall_1: 0.7680 - precision_1: 0.7543 - auc_1: 0.8513 - val_loss: 0.4481 - val_accuracy: 0.7833 - val_recall_1: 0.7605 - val_precision_1: 0.7964 - val_auc_1: 0.8741\n",
      "Epoch 59/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4741 - accuracy: 0.7581 - recall_1: 0.7653 - precision_1: 0.7546 - auc_1: 0.8496 - val_loss: 0.4445 - val_accuracy: 0.7831 - val_recall_1: 0.7815 - val_precision_1: 0.7835 - val_auc_1: 0.8762\n",
      "Epoch 60/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.7607 - recall_1: 0.7707 - precision_1: 0.7557 - auc_1: 0.8528 - val_loss: 0.4418 - val_accuracy: 0.7838 - val_recall_1: 0.7686 - val_precision_1: 0.7921 - val_auc_1: 0.8776\n",
      "Epoch 61/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.7621 - recall_1: 0.7710 - precision_1: 0.7577 - auc_1: 0.8540 - val_loss: 0.4444 - val_accuracy: 0.7828 - val_recall_1: 0.7833 - val_precision_1: 0.7820 - val_auc_1: 0.8765\n",
      "Epoch 62/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.7619 - recall_1: 0.7697 - precision_1: 0.7581 - auc_1: 0.8540 - val_loss: 0.4428 - val_accuracy: 0.7844 - val_recall_1: 0.7953 - val_precision_1: 0.7778 - val_auc_1: 0.8761\n",
      "Epoch 63/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4679 - accuracy: 0.7617 - recall_1: 0.7708 - precision_1: 0.7571 - auc_1: 0.8542 - val_loss: 0.4424 - val_accuracy: 0.7842 - val_recall_1: 0.8446 - val_precision_1: 0.7532 - val_auc_1: 0.8781\n",
      "Epoch 64/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.7633 - recall_1: 0.7735 - precision_1: 0.7582 - auc_1: 0.8551 - val_loss: 0.4451 - val_accuracy: 0.7843 - val_recall_1: 0.8311 - val_precision_1: 0.7596 - val_auc_1: 0.8776\n",
      "Epoch 65/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7644 - recall_1: 0.7750 - precision_1: 0.7590 - auc_1: 0.8561 - val_loss: 0.4430 - val_accuracy: 0.7865 - val_recall_1: 0.8093 - val_precision_1: 0.7735 - val_auc_1: 0.8785\n",
      "Epoch 66/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.7641 - recall_1: 0.7741 - precision_1: 0.7591 - auc_1: 0.8567 - val_loss: 0.4368 - val_accuracy: 0.7904 - val_recall_1: 0.8013 - val_precision_1: 0.7837 - val_auc_1: 0.8816\n",
      "Epoch 67/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4637 - accuracy: 0.7657 - recall_1: 0.7749 - precision_1: 0.7611 - auc_1: 0.8575 - val_loss: 0.4374 - val_accuracy: 0.7900 - val_recall_1: 0.8102 - val_precision_1: 0.7782 - val_auc_1: 0.8808\n",
      "Epoch 68/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.7654 - recall_1: 0.7754 - precision_1: 0.7604 - auc_1: 0.8585 - val_loss: 0.4386 - val_accuracy: 0.7874 - val_recall_1: 0.7930 - val_precision_1: 0.7837 - val_auc_1: 0.8794\n",
      "Epoch 69/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.7640 - recall_1: 0.7718 - precision_1: 0.7601 - auc_1: 0.8572 - val_loss: 0.4353 - val_accuracy: 0.7922 - val_recall_1: 0.8059 - val_precision_1: 0.7839 - val_auc_1: 0.8823\n",
      "Epoch 70/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4631 - accuracy: 0.7659 - recall_1: 0.7735 - precision_1: 0.7621 - auc_1: 0.8579 - val_loss: 0.4349 - val_accuracy: 0.7911 - val_recall_1: 0.8164 - val_precision_1: 0.7766 - val_auc_1: 0.8816\n",
      "Epoch 71/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7665 - recall_1: 0.7755 - precision_1: 0.7619 - auc_1: 0.8600 - val_loss: 0.4355 - val_accuracy: 0.7913 - val_recall_1: 0.7910 - val_precision_1: 0.7910 - val_auc_1: 0.8822\n",
      "Epoch 72/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4628 - accuracy: 0.7666 - recall_1: 0.7753 - precision_1: 0.7621 - auc_1: 0.8585 - val_loss: 0.4340 - val_accuracy: 0.7915 - val_recall_1: 0.8044 - val_precision_1: 0.7837 - val_auc_1: 0.8828\n",
      "Epoch 73/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.7660 - recall_1: 0.7749 - precision_1: 0.7614 - auc_1: 0.8586 - val_loss: 0.4338 - val_accuracy: 0.7919 - val_recall_1: 0.8076 - val_precision_1: 0.7825 - val_auc_1: 0.8833\n",
      "Epoch 74/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4599 - accuracy: 0.7664 - recall_1: 0.7737 - precision_1: 0.7627 - auc_1: 0.8596 - val_loss: 0.4329 - val_accuracy: 0.7910 - val_recall_1: 0.8329 - val_precision_1: 0.7680 - val_auc_1: 0.8839\n",
      "Epoch 75/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.7674 - recall_1: 0.7786 - precision_1: 0.7616 - auc_1: 0.8594 - val_loss: 0.4341 - val_accuracy: 0.7906 - val_recall_1: 0.8060 - val_precision_1: 0.7814 - val_auc_1: 0.8820\n",
      "Epoch 76/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.7672 - recall_1: 0.7718 - precision_1: 0.7649 - auc_1: 0.8605 - val_loss: 0.4341 - val_accuracy: 0.7891 - val_recall_1: 0.8105 - val_precision_1: 0.7767 - val_auc_1: 0.8823\n",
      "Epoch 77/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4561 - accuracy: 0.7698 - recall_1: 0.7782 - precision_1: 0.7655 - auc_1: 0.8629 - val_loss: 0.4303 - val_accuracy: 0.7924 - val_recall_1: 0.7761 - val_precision_1: 0.8018 - val_auc_1: 0.8840\n",
      "Epoch 78/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.7696 - recall_1: 0.7768 - precision_1: 0.7659 - auc_1: 0.8620 - val_loss: 0.4300 - val_accuracy: 0.7938 - val_recall_1: 0.7982 - val_precision_1: 0.7908 - val_auc_1: 0.8852\n",
      "Epoch 79/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.7698 - recall_1: 0.7779 - precision_1: 0.7656 - auc_1: 0.8631 - val_loss: 0.4305 - val_accuracy: 0.7924 - val_recall_1: 0.8011 - val_precision_1: 0.7868 - val_auc_1: 0.8843\n",
      "Epoch 80/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4559 - accuracy: 0.7695 - recall_1: 0.7791 - precision_1: 0.7646 - auc_1: 0.8627 - val_loss: 0.4320 - val_accuracy: 0.7928 - val_recall_1: 0.8069 - val_precision_1: 0.7842 - val_auc_1: 0.8842\n",
      "Epoch 81/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.7704 - recall_1: 0.7789 - precision_1: 0.7660 - auc_1: 0.8636 - val_loss: 0.4271 - val_accuracy: 0.7950 - val_recall_1: 0.8052 - val_precision_1: 0.7886 - val_auc_1: 0.8864\n",
      "Epoch 82/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7714 - recall_1: 0.7776 - precision_1: 0.7683 - auc_1: 0.8639 - val_loss: 0.4298 - val_accuracy: 0.7936 - val_recall_1: 0.8016 - val_precision_1: 0.7884 - val_auc_1: 0.8854\n",
      "Epoch 83/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4542 - accuracy: 0.7704 - recall_1: 0.7788 - precision_1: 0.7660 - auc_1: 0.8635 - val_loss: 0.4290 - val_accuracy: 0.7932 - val_recall_1: 0.7978 - val_precision_1: 0.7900 - val_auc_1: 0.8852\n",
      "Epoch 84/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4548 - accuracy: 0.7706 - recall_1: 0.7788 - precision_1: 0.7663 - auc_1: 0.8631 - val_loss: 0.4297 - val_accuracy: 0.7927 - val_recall_1: 0.8162 - val_precision_1: 0.7792 - val_auc_1: 0.8849\n",
      "Epoch 85/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4529 - accuracy: 0.7709 - recall_1: 0.7802 - precision_1: 0.7661 - auc_1: 0.8643 - val_loss: 0.4266 - val_accuracy: 0.7923 - val_recall_1: 0.8146 - val_precision_1: 0.7793 - val_auc_1: 0.8865\n",
      "Epoch 86/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.7736 - recall_1: 0.7802 - precision_1: 0.7702 - auc_1: 0.8663 - val_loss: 0.4294 - val_accuracy: 0.7907 - val_recall_1: 0.8200 - val_precision_1: 0.7742 - val_auc_1: 0.8846\n",
      "Epoch 87/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4537 - accuracy: 0.7720 - recall_1: 0.7783 - precision_1: 0.7687 - auc_1: 0.8642 - val_loss: 0.4261 - val_accuracy: 0.7952 - val_recall_1: 0.8250 - val_precision_1: 0.7782 - val_auc_1: 0.8871\n",
      "Epoch 88/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4521 - accuracy: 0.7718 - recall_1: 0.7784 - precision_1: 0.7685 - auc_1: 0.8653 - val_loss: 0.4245 - val_accuracy: 0.7953 - val_recall_1: 0.7942 - val_precision_1: 0.7954 - val_auc_1: 0.8872\n",
      "Epoch 89/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.7734 - recall_1: 0.7797 - precision_1: 0.7702 - auc_1: 0.8659 - val_loss: 0.4282 - val_accuracy: 0.7923 - val_recall_1: 0.8366 - val_precision_1: 0.7680 - val_auc_1: 0.8857\n",
      "Epoch 90/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.7750 - recall_1: 0.7824 - precision_1: 0.7711 - auc_1: 0.8676 - val_loss: 0.4265 - val_accuracy: 0.7943 - val_recall_1: 0.8126 - val_precision_1: 0.7835 - val_auc_1: 0.8868\n",
      "Epoch 91/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.7730 - recall_1: 0.7785 - precision_1: 0.7701 - auc_1: 0.8661 - val_loss: 0.4262 - val_accuracy: 0.7951 - val_recall_1: 0.8102 - val_precision_1: 0.7860 - val_auc_1: 0.8875\n",
      "Epoch 92/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.7761 - recall_1: 0.7837 - precision_1: 0.7721 - auc_1: 0.8678 - val_loss: 0.4248 - val_accuracy: 0.7949 - val_recall_1: 0.8160 - val_precision_1: 0.7825 - val_auc_1: 0.8875\n",
      "Epoch 93/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4499 - accuracy: 0.7733 - recall_1: 0.7797 - precision_1: 0.7699 - auc_1: 0.8668 - val_loss: 0.4237 - val_accuracy: 0.7959 - val_recall_1: 0.8057 - val_precision_1: 0.7898 - val_auc_1: 0.8877\n",
      "Epoch 94/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.7746 - recall_1: 0.7818 - precision_1: 0.7708 - auc_1: 0.8677 - val_loss: 0.4270 - val_accuracy: 0.7941 - val_recall_1: 0.8326 - val_precision_1: 0.7726 - val_auc_1: 0.8872\n",
      "Epoch 95/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.7763 - recall_1: 0.7842 - precision_1: 0.7721 - auc_1: 0.8686 - val_loss: 0.4241 - val_accuracy: 0.7950 - val_recall_1: 0.7696 - val_precision_1: 0.8103 - val_auc_1: 0.8880\n",
      "Epoch 96/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.7766 - recall_1: 0.7821 - precision_1: 0.7737 - auc_1: 0.8699 - val_loss: 0.4231 - val_accuracy: 0.7957 - val_recall_1: 0.7849 - val_precision_1: 0.8018 - val_auc_1: 0.8879\n",
      "Epoch 97/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.7756 - recall_1: 0.7822 - precision_1: 0.7722 - auc_1: 0.8681 - val_loss: 0.4255 - val_accuracy: 0.7963 - val_recall_1: 0.8034 - val_precision_1: 0.7917 - val_auc_1: 0.8872\n",
      "Epoch 98/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.7759 - recall_1: 0.7820 - precision_1: 0.7727 - auc_1: 0.8698 - val_loss: 0.4233 - val_accuracy: 0.7978 - val_recall_1: 0.7987 - val_precision_1: 0.7968 - val_auc_1: 0.8885\n",
      "Epoch 99/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7758 - recall_1: 0.7821 - precision_1: 0.7725 - auc_1: 0.8690 - val_loss: 0.4217 - val_accuracy: 0.7984 - val_recall_1: 0.8141 - val_precision_1: 0.7890 - val_auc_1: 0.8898\n",
      "Epoch 100/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4446 - accuracy: 0.7789 - recall_1: 0.7834 - precision_1: 0.7766 - auc_1: 0.8707 - val_loss: 0.4240 - val_accuracy: 0.7953 - val_recall_1: 0.8413 - val_precision_1: 0.7701 - val_auc_1: 0.8891\n",
      "Epoch 101/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.7779 - recall_1: 0.7849 - precision_1: 0.7741 - auc_1: 0.8704 - val_loss: 0.4238 - val_accuracy: 0.7958 - val_recall_1: 0.8190 - val_precision_1: 0.7822 - val_auc_1: 0.8882\n",
      "Epoch 102/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4447 - accuracy: 0.7771 - recall_1: 0.7853 - precision_1: 0.7728 - auc_1: 0.8703 - val_loss: 0.4219 - val_accuracy: 0.7967 - val_recall_1: 0.8009 - val_precision_1: 0.7938 - val_auc_1: 0.8894\n",
      "Epoch 103/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4438 - accuracy: 0.7780 - recall_1: 0.7837 - precision_1: 0.7751 - auc_1: 0.8709 - val_loss: 0.4196 - val_accuracy: 0.7963 - val_recall_1: 0.8310 - val_precision_1: 0.7766 - val_auc_1: 0.8904\n",
      "Epoch 104/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4456 - accuracy: 0.7765 - recall_1: 0.7809 - precision_1: 0.7742 - auc_1: 0.8696 - val_loss: 0.4224 - val_accuracy: 0.7984 - val_recall_1: 0.8345 - val_precision_1: 0.7779 - val_auc_1: 0.8905\n",
      "Epoch 105/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4402 - accuracy: 0.7791 - recall_1: 0.7854 - precision_1: 0.7758 - auc_1: 0.8731 - val_loss: 0.4211 - val_accuracy: 0.7975 - val_recall_1: 0.8483 - val_precision_1: 0.7696 - val_auc_1: 0.8909\n",
      "Epoch 106/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4437 - accuracy: 0.7783 - recall_1: 0.7861 - precision_1: 0.7741 - auc_1: 0.8709 - val_loss: 0.4191 - val_accuracy: 0.7977 - val_recall_1: 0.8439 - val_precision_1: 0.7722 - val_auc_1: 0.8915\n",
      "Epoch 107/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4439 - accuracy: 0.7778 - recall_1: 0.7870 - precision_1: 0.7729 - auc_1: 0.8708 - val_loss: 0.4196 - val_accuracy: 0.8007 - val_recall_1: 0.8218 - val_precision_1: 0.7881 - val_auc_1: 0.8915\n",
      "Epoch 108/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4416 - accuracy: 0.7791 - recall_1: 0.7847 - precision_1: 0.7762 - auc_1: 0.8722 - val_loss: 0.4179 - val_accuracy: 0.7999 - val_recall_1: 0.8063 - val_precision_1: 0.7957 - val_auc_1: 0.8914\n",
      "Epoch 109/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4429 - accuracy: 0.7781 - recall_1: 0.7828 - precision_1: 0.7756 - auc_1: 0.8712 - val_loss: 0.4190 - val_accuracy: 0.7988 - val_recall_1: 0.8035 - val_precision_1: 0.7956 - val_auc_1: 0.8902\n",
      "Epoch 110/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4433 - accuracy: 0.7789 - recall_1: 0.7844 - precision_1: 0.7760 - auc_1: 0.8713 - val_loss: 0.4212 - val_accuracy: 0.7995 - val_recall_1: 0.8134 - val_precision_1: 0.7910 - val_auc_1: 0.8900\n",
      "Epoch 111/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4442 - accuracy: 0.7774 - recall_1: 0.7844 - precision_1: 0.7737 - auc_1: 0.8706 - val_loss: 0.4192 - val_accuracy: 0.7998 - val_recall_1: 0.8211 - val_precision_1: 0.7870 - val_auc_1: 0.8913\n",
      "Epoch 112/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4402 - accuracy: 0.7794 - recall_1: 0.7841 - precision_1: 0.7769 - auc_1: 0.8730 - val_loss: 0.4202 - val_accuracy: 0.8002 - val_recall_1: 0.8358 - val_precision_1: 0.7798 - val_auc_1: 0.8910\n",
      "Epoch 113/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.7804 - recall_1: 0.7885 - precision_1: 0.7761 - auc_1: 0.8726 - val_loss: 0.4166 - val_accuracy: 0.7991 - val_recall_1: 0.7951 - val_precision_1: 0.8010 - val_auc_1: 0.8922\n",
      "Epoch 114/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4396 - accuracy: 0.7800 - recall_1: 0.7880 - precision_1: 0.7757 - auc_1: 0.8733 - val_loss: 0.4155 - val_accuracy: 0.8011 - val_recall_1: 0.8276 - val_precision_1: 0.7855 - val_auc_1: 0.8934\n",
      "Epoch 115/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4398 - accuracy: 0.7789 - recall_1: 0.7862 - precision_1: 0.7751 - auc_1: 0.8732 - val_loss: 0.4166 - val_accuracy: 0.7998 - val_recall_1: 0.8222 - val_precision_1: 0.7865 - val_auc_1: 0.8915\n",
      "Epoch 116/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.7804 - recall_1: 0.7860 - precision_1: 0.7775 - auc_1: 0.8734 - val_loss: 0.4192 - val_accuracy: 0.8003 - val_recall_1: 0.8107 - val_precision_1: 0.7937 - val_auc_1: 0.8912\n",
      "Epoch 117/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4376 - accuracy: 0.7822 - recall_1: 0.7861 - precision_1: 0.7802 - auc_1: 0.8747 - val_loss: 0.4178 - val_accuracy: 0.8001 - val_recall_1: 0.8284 - val_precision_1: 0.7835 - val_auc_1: 0.8919\n",
      "Epoch 118/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4404 - accuracy: 0.7805 - recall_1: 0.7876 - precision_1: 0.7766 - auc_1: 0.8731 - val_loss: 0.4170 - val_accuracy: 0.7999 - val_recall_1: 0.8081 - val_precision_1: 0.7946 - val_auc_1: 0.8922\n",
      "Epoch 119/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4381 - accuracy: 0.7830 - recall_1: 0.7896 - precision_1: 0.7794 - auc_1: 0.8749 - val_loss: 0.4154 - val_accuracy: 0.8023 - val_recall_1: 0.8091 - val_precision_1: 0.7979 - val_auc_1: 0.8934\n",
      "Epoch 120/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.7813 - recall_1: 0.7878 - precision_1: 0.7778 - auc_1: 0.8742 - val_loss: 0.4155 - val_accuracy: 0.8034 - val_recall_1: 0.8257 - val_precision_1: 0.7899 - val_auc_1: 0.8931\n",
      "Epoch 121/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.7814 - recall_1: 0.7876 - precision_1: 0.7780 - auc_1: 0.8741 - val_loss: 0.4146 - val_accuracy: 0.8017 - val_recall_1: 0.8069 - val_precision_1: 0.7982 - val_auc_1: 0.8933\n",
      "Epoch 122/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4365 - accuracy: 0.7833 - recall_1: 0.7885 - precision_1: 0.7806 - auc_1: 0.8757 - val_loss: 0.4132 - val_accuracy: 0.8023 - val_recall_1: 0.8215 - val_precision_1: 0.7907 - val_auc_1: 0.8934\n",
      "Epoch 123/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.7823 - recall_1: 0.7900 - precision_1: 0.7782 - auc_1: 0.8744 - val_loss: 0.4167 - val_accuracy: 0.8022 - val_recall_1: 0.8490 - val_precision_1: 0.7759 - val_auc_1: 0.8931\n",
      "Epoch 124/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.7811 - recall_1: 0.7875 - precision_1: 0.7777 - auc_1: 0.8749 - val_loss: 0.4161 - val_accuracy: 0.8013 - val_recall_1: 0.8181 - val_precision_1: 0.7910 - val_auc_1: 0.8923\n",
      "Epoch 125/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4377 - accuracy: 0.7822 - recall_1: 0.7864 - precision_1: 0.7800 - auc_1: 0.8748 - val_loss: 0.4143 - val_accuracy: 0.8016 - val_recall_1: 0.8341 - val_precision_1: 0.7828 - val_auc_1: 0.8937\n",
      "Epoch 126/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.7839 - recall_1: 0.7920 - precision_1: 0.7795 - auc_1: 0.8768 - val_loss: 0.4110 - val_accuracy: 0.8022 - val_recall_1: 0.8150 - val_precision_1: 0.7942 - val_auc_1: 0.8949\n",
      "Epoch 127/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7845 - recall_1: 0.7945 - precision_1: 0.7790 - auc_1: 0.8770 - val_loss: 0.4109 - val_accuracy: 0.8036 - val_recall_1: 0.7882 - val_precision_1: 0.8127 - val_auc_1: 0.8950\n",
      "Epoch 128/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4360 - accuracy: 0.7819 - recall_1: 0.7866 - precision_1: 0.7794 - auc_1: 0.8756 - val_loss: 0.4122 - val_accuracy: 0.8022 - val_recall_1: 0.8326 - val_precision_1: 0.7845 - val_auc_1: 0.8945\n",
      "Epoch 129/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.7842 - recall_1: 0.7930 - precision_1: 0.7793 - auc_1: 0.8770 - val_loss: 0.4133 - val_accuracy: 0.8038 - val_recall_1: 0.8133 - val_precision_1: 0.7976 - val_auc_1: 0.8944\n",
      "Epoch 130/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4334 - accuracy: 0.7851 - recall_1: 0.7922 - precision_1: 0.7812 - auc_1: 0.8777 - val_loss: 0.4134 - val_accuracy: 0.8026 - val_recall_1: 0.8298 - val_precision_1: 0.7866 - val_auc_1: 0.8945\n",
      "Epoch 131/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.7833 - recall_1: 0.7911 - precision_1: 0.7791 - auc_1: 0.8756 - val_loss: 0.4141 - val_accuracy: 0.8028 - val_recall_1: 0.8206 - val_precision_1: 0.7919 - val_auc_1: 0.8939\n",
      "Epoch 132/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4362 - accuracy: 0.7828 - recall_1: 0.7896 - precision_1: 0.7792 - auc_1: 0.8757 - val_loss: 0.4138 - val_accuracy: 0.8041 - val_recall_1: 0.8259 - val_precision_1: 0.7910 - val_auc_1: 0.8945\n",
      "Epoch 133/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.7859 - recall_1: 0.7942 - precision_1: 0.7813 - auc_1: 0.8786 - val_loss: 0.4119 - val_accuracy: 0.8015 - val_recall_1: 0.8013 - val_precision_1: 0.8012 - val_auc_1: 0.8946\n",
      "Epoch 134/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.7839 - recall_1: 0.7905 - precision_1: 0.7803 - auc_1: 0.8778 - val_loss: 0.4144 - val_accuracy: 0.8024 - val_recall_1: 0.8338 - val_precision_1: 0.7841 - val_auc_1: 0.8943\n",
      "Epoch 135/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.7849 - recall_1: 0.7907 - precision_1: 0.7817 - auc_1: 0.8775 - val_loss: 0.4104 - val_accuracy: 0.8030 - val_recall_1: 0.8343 - val_precision_1: 0.7848 - val_auc_1: 0.8962\n",
      "Epoch 136/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.7845 - recall_1: 0.7920 - precision_1: 0.7805 - auc_1: 0.8773 - val_loss: 0.4126 - val_accuracy: 0.8018 - val_recall_1: 0.8323 - val_precision_1: 0.7839 - val_auc_1: 0.8951\n",
      "Epoch 137/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7846 - recall_1: 0.7934 - precision_1: 0.7798 - auc_1: 0.8788 - val_loss: 0.4119 - val_accuracy: 0.8032 - val_recall_1: 0.8168 - val_precision_1: 0.7947 - val_auc_1: 0.8950\n",
      "Epoch 138/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.7849 - recall_1: 0.7916 - precision_1: 0.7813 - auc_1: 0.8773 - val_loss: 0.4118 - val_accuracy: 0.8030 - val_recall_1: 0.8258 - val_precision_1: 0.7894 - val_auc_1: 0.8951\n",
      "Epoch 139/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.7860 - recall_1: 0.7934 - precision_1: 0.7819 - auc_1: 0.8786 - val_loss: 0.4110 - val_accuracy: 0.8049 - val_recall_1: 0.8298 - val_precision_1: 0.7900 - val_auc_1: 0.8961\n",
      "Epoch 140/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.7862 - recall_1: 0.7896 - precision_1: 0.7844 - auc_1: 0.8794 - val_loss: 0.4109 - val_accuracy: 0.8038 - val_recall_1: 0.8382 - val_precision_1: 0.7838 - val_auc_1: 0.8955\n",
      "Epoch 141/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.7844 - recall_1: 0.7910 - precision_1: 0.7808 - auc_1: 0.8777 - val_loss: 0.4096 - val_accuracy: 0.8051 - val_recall_1: 0.8244 - val_precision_1: 0.7932 - val_auc_1: 0.8958\n",
      "Epoch 142/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7865 - recall_1: 0.7950 - precision_1: 0.7818 - auc_1: 0.8794 - val_loss: 0.4090 - val_accuracy: 0.8046 - val_recall_1: 0.8211 - val_precision_1: 0.7944 - val_auc_1: 0.8962\n",
      "Epoch 143/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.7865 - recall_1: 0.7935 - precision_1: 0.7826 - auc_1: 0.8794 - val_loss: 0.4091 - val_accuracy: 0.8034 - val_recall_1: 0.8170 - val_precision_1: 0.7950 - val_auc_1: 0.8957\n",
      "Epoch 144/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.7864 - recall_1: 0.7940 - precision_1: 0.7822 - auc_1: 0.8803 - val_loss: 0.4120 - val_accuracy: 0.8036 - val_recall_1: 0.8381 - val_precision_1: 0.7836 - val_auc_1: 0.8956\n",
      "Epoch 145/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.7867 - recall_1: 0.7906 - precision_1: 0.7847 - auc_1: 0.8802 - val_loss: 0.4090 - val_accuracy: 0.8042 - val_recall_1: 0.8155 - val_precision_1: 0.7970 - val_auc_1: 0.8959\n",
      "Epoch 146/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.7878 - recall_1: 0.7920 - precision_1: 0.7855 - auc_1: 0.8802 - val_loss: 0.4084 - val_accuracy: 0.8058 - val_recall_1: 0.8389 - val_precision_1: 0.7864 - val_auc_1: 0.8973\n",
      "Epoch 147/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7874 - recall_1: 0.7946 - precision_1: 0.7835 - auc_1: 0.8801 - val_loss: 0.4090 - val_accuracy: 0.8058 - val_recall_1: 0.8211 - val_precision_1: 0.7963 - val_auc_1: 0.8968\n",
      "Epoch 148/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.7882 - recall_1: 0.7958 - precision_1: 0.7841 - auc_1: 0.8794 - val_loss: 0.4084 - val_accuracy: 0.8065 - val_recall_1: 0.8074 - val_precision_1: 0.8054 - val_auc_1: 0.8969\n",
      "Epoch 149/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.7888 - recall_1: 0.7946 - precision_1: 0.7856 - auc_1: 0.8807 - val_loss: 0.4111 - val_accuracy: 0.8048 - val_recall_1: 0.8369 - val_precision_1: 0.7859 - val_auc_1: 0.8961\n",
      "Epoch 150/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.7878 - recall_1: 0.7924 - precision_1: 0.7853 - auc_1: 0.8806 - val_loss: 0.4067 - val_accuracy: 0.8057 - val_recall_1: 0.8083 - val_precision_1: 0.8036 - val_auc_1: 0.8972\n",
      "Epoch 151/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.7868 - recall_1: 0.7924 - precision_1: 0.7838 - auc_1: 0.8802 - val_loss: 0.4080 - val_accuracy: 0.8051 - val_recall_1: 0.8284 - val_precision_1: 0.7910 - val_auc_1: 0.8976\n",
      "Epoch 152/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7876 - recall_1: 0.7931 - precision_1: 0.7846 - auc_1: 0.8802 - val_loss: 0.4101 - val_accuracy: 0.8041 - val_recall_1: 0.8396 - val_precision_1: 0.7835 - val_auc_1: 0.8963\n",
      "Epoch 153/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4265 - accuracy: 0.7895 - recall_1: 0.7951 - precision_1: 0.7864 - auc_1: 0.8820 - val_loss: 0.4089 - val_accuracy: 0.8053 - val_recall_1: 0.8159 - val_precision_1: 0.7984 - val_auc_1: 0.8967\n",
      "Epoch 154/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.7875 - recall_1: 0.7953 - precision_1: 0.7832 - auc_1: 0.8808 - val_loss: 0.4074 - val_accuracy: 0.8057 - val_recall_1: 0.8020 - val_precision_1: 0.8076 - val_auc_1: 0.8968\n",
      "Epoch 155/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.7882 - recall_1: 0.7915 - precision_1: 0.7864 - auc_1: 0.8816 - val_loss: 0.4094 - val_accuracy: 0.8044 - val_recall_1: 0.8236 - val_precision_1: 0.7927 - val_auc_1: 0.8960\n",
      "Epoch 156/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.7876 - recall_1: 0.7920 - precision_1: 0.7852 - auc_1: 0.8800 - val_loss: 0.4055 - val_accuracy: 0.8068 - val_recall_1: 0.8220 - val_precision_1: 0.7973 - val_auc_1: 0.8982\n",
      "Epoch 157/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4272 - accuracy: 0.7886 - recall_1: 0.7922 - precision_1: 0.7867 - auc_1: 0.8814 - val_loss: 0.4053 - val_accuracy: 0.8066 - val_recall_1: 0.8330 - val_precision_1: 0.7909 - val_auc_1: 0.8981\n",
      "Epoch 158/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.7893 - recall_1: 0.7942 - precision_1: 0.7867 - auc_1: 0.8818 - val_loss: 0.4078 - val_accuracy: 0.8062 - val_recall_1: 0.8301 - val_precision_1: 0.7918 - val_auc_1: 0.8973\n",
      "Epoch 159/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.7876 - recall_1: 0.7924 - precision_1: 0.7850 - auc_1: 0.8805 - val_loss: 0.4088 - val_accuracy: 0.8051 - val_recall_1: 0.8261 - val_precision_1: 0.7923 - val_auc_1: 0.8966\n",
      "Epoch 160/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.7868 - recall_1: 0.7937 - precision_1: 0.7830 - auc_1: 0.8802 - val_loss: 0.4067 - val_accuracy: 0.8090 - val_recall_1: 0.8319 - val_precision_1: 0.7950 - val_auc_1: 0.8983\n",
      "Epoch 161/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4265 - accuracy: 0.7890 - recall_1: 0.7960 - precision_1: 0.7851 - auc_1: 0.8817 - val_loss: 0.4048 - val_accuracy: 0.8050 - val_recall_1: 0.8101 - val_precision_1: 0.8015 - val_auc_1: 0.8976\n",
      "Epoch 162/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.7890 - recall_1: 0.7968 - precision_1: 0.7847 - auc_1: 0.8821 - val_loss: 0.4068 - val_accuracy: 0.8054 - val_recall_1: 0.8167 - val_precision_1: 0.7982 - val_auc_1: 0.8971\n",
      "Epoch 163/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.7906 - recall_1: 0.7962 - precision_1: 0.7874 - auc_1: 0.8829 - val_loss: 0.4068 - val_accuracy: 0.8063 - val_recall_1: 0.8146 - val_precision_1: 0.8008 - val_auc_1: 0.8971\n",
      "Epoch 164/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.7890 - recall_1: 0.7952 - precision_1: 0.7855 - auc_1: 0.8817 - val_loss: 0.4064 - val_accuracy: 0.8052 - val_recall_1: 0.8544 - val_precision_1: 0.7774 - val_auc_1: 0.8984\n",
      "Epoch 165/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.7915 - recall_1: 0.8002 - precision_1: 0.7867 - auc_1: 0.8833 - val_loss: 0.4073 - val_accuracy: 0.8041 - val_recall_1: 0.8101 - val_precision_1: 0.8000 - val_auc_1: 0.8964\n",
      "Epoch 166/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.7929 - recall_1: 0.7989 - precision_1: 0.7896 - auc_1: 0.8845 - val_loss: 0.4075 - val_accuracy: 0.8064 - val_recall_1: 0.8246 - val_precision_1: 0.7952 - val_auc_1: 0.8973\n",
      "Epoch 167/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.7897 - recall_1: 0.7944 - precision_1: 0.7871 - auc_1: 0.8821 - val_loss: 0.4063 - val_accuracy: 0.8065 - val_recall_1: 0.8438 - val_precision_1: 0.7848 - val_auc_1: 0.8984\n",
      "Epoch 168/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.7901 - recall_1: 0.7953 - precision_1: 0.7873 - auc_1: 0.8823 - val_loss: 0.4073 - val_accuracy: 0.8067 - val_recall_1: 0.8217 - val_precision_1: 0.7973 - val_auc_1: 0.8976\n",
      "Epoch 169/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.7900 - recall_1: 0.7943 - precision_1: 0.7876 - auc_1: 0.8832 - val_loss: 0.4059 - val_accuracy: 0.8054 - val_recall_1: 0.8424 - val_precision_1: 0.7840 - val_auc_1: 0.8982\n",
      "Epoch 170/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4240 - accuracy: 0.7914 - recall_1: 0.7980 - precision_1: 0.7878 - auc_1: 0.8835 - val_loss: 0.4048 - val_accuracy: 0.8049 - val_recall_1: 0.8361 - val_precision_1: 0.7866 - val_auc_1: 0.8982\n",
      "Epoch 171/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.7900 - recall_1: 0.7945 - precision_1: 0.7875 - auc_1: 0.8823 - val_loss: 0.4057 - val_accuracy: 0.8040 - val_recall_1: 0.8265 - val_precision_1: 0.7904 - val_auc_1: 0.8981\n",
      "Epoch 172/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.7903 - recall_1: 0.7954 - precision_1: 0.7875 - auc_1: 0.8833 - val_loss: 0.4053 - val_accuracy: 0.8081 - val_recall_1: 0.8219 - val_precision_1: 0.7994 - val_auc_1: 0.8984\n",
      "Epoch 173/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4232 - accuracy: 0.7915 - recall_1: 0.7956 - precision_1: 0.7892 - auc_1: 0.8840 - val_loss: 0.4048 - val_accuracy: 0.8074 - val_recall_1: 0.8383 - val_precision_1: 0.7891 - val_auc_1: 0.8991\n",
      "Epoch 174/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4249 - accuracy: 0.7895 - recall_1: 0.7961 - precision_1: 0.7858 - auc_1: 0.8830 - val_loss: 0.4051 - val_accuracy: 0.8083 - val_recall_1: 0.8221 - val_precision_1: 0.7996 - val_auc_1: 0.8986\n",
      "Epoch 175/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4256 - accuracy: 0.7907 - recall_1: 0.7941 - precision_1: 0.7888 - auc_1: 0.8827 - val_loss: 0.4039 - val_accuracy: 0.8073 - val_recall_1: 0.8467 - val_precision_1: 0.7844 - val_auc_1: 0.8997\n",
      "Epoch 176/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4246 - accuracy: 0.7905 - recall_1: 0.7962 - precision_1: 0.7873 - auc_1: 0.8830 - val_loss: 0.4049 - val_accuracy: 0.8069 - val_recall_1: 0.8377 - val_precision_1: 0.7886 - val_auc_1: 0.8991\n",
      "Epoch 177/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4227 - accuracy: 0.7914 - recall_1: 0.7981 - precision_1: 0.7877 - auc_1: 0.8841 - val_loss: 0.4067 - val_accuracy: 0.8045 - val_recall_1: 0.8302 - val_precision_1: 0.7892 - val_auc_1: 0.8982\n",
      "Epoch 178/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.7912 - recall_1: 0.7966 - precision_1: 0.7881 - auc_1: 0.8841 - val_loss: 0.4038 - val_accuracy: 0.8059 - val_recall_1: 0.8292 - val_precision_1: 0.7919 - val_auc_1: 0.8990\n",
      "Epoch 179/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4227 - accuracy: 0.7915 - recall_1: 0.7991 - precision_1: 0.7873 - auc_1: 0.8841 - val_loss: 0.4030 - val_accuracy: 0.8083 - val_recall_1: 0.8083 - val_precision_1: 0.8078 - val_auc_1: 0.8994\n",
      "Epoch 180/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4213 - accuracy: 0.7935 - recall_1: 0.7999 - precision_1: 0.7899 - auc_1: 0.8853 - val_loss: 0.4016 - val_accuracy: 0.8093 - val_recall_1: 0.8135 - val_precision_1: 0.8062 - val_auc_1: 0.9003\n",
      "Epoch 181/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4238 - accuracy: 0.7914 - recall_1: 0.7964 - precision_1: 0.7886 - auc_1: 0.8837 - val_loss: 0.4038 - val_accuracy: 0.8069 - val_recall_1: 0.8198 - val_precision_1: 0.7987 - val_auc_1: 0.8993\n",
      "Epoch 182/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.7915 - recall_1: 0.7972 - precision_1: 0.7884 - auc_1: 0.8846 - val_loss: 0.4016 - val_accuracy: 0.8072 - val_recall_1: 0.8106 - val_precision_1: 0.8046 - val_auc_1: 0.9000\n",
      "Epoch 183/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4204 - accuracy: 0.7932 - recall_1: 0.7978 - precision_1: 0.7906 - auc_1: 0.8856 - val_loss: 0.4017 - val_accuracy: 0.8079 - val_recall_1: 0.8359 - val_precision_1: 0.7911 - val_auc_1: 0.9000\n",
      "Epoch 184/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4215 - accuracy: 0.7926 - recall_1: 0.7966 - precision_1: 0.7904 - auc_1: 0.8850 - val_loss: 0.4040 - val_accuracy: 0.8089 - val_recall_1: 0.8270 - val_precision_1: 0.7977 - val_auc_1: 0.8995\n",
      "Epoch 185/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4203 - accuracy: 0.7926 - recall_1: 0.7961 - precision_1: 0.7906 - auc_1: 0.8855 - val_loss: 0.4022 - val_accuracy: 0.8092 - val_recall_1: 0.8320 - val_precision_1: 0.7954 - val_auc_1: 0.8998\n",
      "Epoch 186/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4195 - accuracy: 0.7934 - recall_1: 0.7957 - precision_1: 0.7922 - auc_1: 0.8860 - val_loss: 0.4007 - val_accuracy: 0.8096 - val_recall_1: 0.8492 - val_precision_1: 0.7865 - val_auc_1: 0.9015\n",
      "Epoch 187/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4232 - accuracy: 0.7923 - recall_1: 0.7986 - precision_1: 0.7888 - auc_1: 0.8840 - val_loss: 0.3999 - val_accuracy: 0.8121 - val_recall_1: 0.8219 - val_precision_1: 0.8056 - val_auc_1: 0.9016\n",
      "Epoch 188/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4203 - accuracy: 0.7939 - recall_1: 0.8002 - precision_1: 0.7905 - auc_1: 0.8860 - val_loss: 0.3995 - val_accuracy: 0.8098 - val_recall_1: 0.8239 - val_precision_1: 0.8008 - val_auc_1: 0.9013\n",
      "Epoch 189/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4206 - accuracy: 0.7935 - recall_1: 0.7969 - precision_1: 0.7916 - auc_1: 0.8857 - val_loss: 0.4044 - val_accuracy: 0.8060 - val_recall_1: 0.8332 - val_precision_1: 0.7897 - val_auc_1: 0.8994\n",
      "Epoch 190/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4209 - accuracy: 0.7925 - recall_1: 0.7970 - precision_1: 0.7901 - auc_1: 0.8851 - val_loss: 0.4036 - val_accuracy: 0.8087 - val_recall_1: 0.8359 - val_precision_1: 0.7923 - val_auc_1: 0.9001\n",
      "Epoch 191/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4207 - accuracy: 0.7938 - recall_1: 0.7973 - precision_1: 0.7918 - auc_1: 0.8855 - val_loss: 0.4014 - val_accuracy: 0.8111 - val_recall_1: 0.8233 - val_precision_1: 0.8032 - val_auc_1: 0.9004\n",
      "Epoch 192/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4199 - accuracy: 0.7927 - recall_1: 0.7972 - precision_1: 0.7902 - auc_1: 0.8858 - val_loss: 0.4016 - val_accuracy: 0.8090 - val_recall_1: 0.8265 - val_precision_1: 0.7982 - val_auc_1: 0.8998\n",
      "Epoch 193/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.7911 - recall_1: 0.7989 - precision_1: 0.7867 - auc_1: 0.8851 - val_loss: 0.3988 - val_accuracy: 0.8104 - val_recall_1: 0.8109 - val_precision_1: 0.8097 - val_auc_1: 0.9015\n",
      "Epoch 194/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4203 - accuracy: 0.7945 - recall_1: 0.8003 - precision_1: 0.7913 - auc_1: 0.8857 - val_loss: 0.4015 - val_accuracy: 0.8085 - val_recall_1: 0.8282 - val_precision_1: 0.7963 - val_auc_1: 0.9003\n",
      "Epoch 195/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4205 - accuracy: 0.7936 - recall_1: 0.7956 - precision_1: 0.7926 - auc_1: 0.8858 - val_loss: 0.4006 - val_accuracy: 0.8106 - val_recall_1: 0.8314 - val_precision_1: 0.7978 - val_auc_1: 0.9006\n",
      "Epoch 196/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4185 - accuracy: 0.7937 - recall_1: 0.7983 - precision_1: 0.7911 - auc_1: 0.8868 - val_loss: 0.3997 - val_accuracy: 0.8113 - val_recall_1: 0.8313 - val_precision_1: 0.7989 - val_auc_1: 0.9010\n",
      "Epoch 197/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4200 - accuracy: 0.7931 - recall_1: 0.7974 - precision_1: 0.7908 - auc_1: 0.8858 - val_loss: 0.4034 - val_accuracy: 0.8094 - val_recall_1: 0.8353 - val_precision_1: 0.7938 - val_auc_1: 0.8997\n",
      "Epoch 198/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4188 - accuracy: 0.7933 - recall_1: 0.7979 - precision_1: 0.7908 - auc_1: 0.8866 - val_loss: 0.4000 - val_accuracy: 0.8101 - val_recall_1: 0.8126 - val_precision_1: 0.8082 - val_auc_1: 0.9003\n",
      "Epoch 199/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4174 - accuracy: 0.7942 - recall_1: 0.8002 - precision_1: 0.7909 - auc_1: 0.8873 - val_loss: 0.4004 - val_accuracy: 0.8092 - val_recall_1: 0.8354 - val_precision_1: 0.7934 - val_auc_1: 0.9010\n",
      "Epoch 200/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.7944 - recall_1: 0.8000 - precision_1: 0.7912 - auc_1: 0.8868 - val_loss: 0.3993 - val_accuracy: 0.8120 - val_recall_1: 0.8168 - val_precision_1: 0.8085 - val_auc_1: 0.9012\n",
      "Epoch 201/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4192 - accuracy: 0.7945 - recall_1: 0.7982 - precision_1: 0.7925 - auc_1: 0.8864 - val_loss: 0.4000 - val_accuracy: 0.8116 - val_recall_1: 0.8376 - val_precision_1: 0.7959 - val_auc_1: 0.9016\n",
      "Epoch 202/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4182 - accuracy: 0.7950 - recall_1: 0.7997 - precision_1: 0.7924 - auc_1: 0.8869 - val_loss: 0.3997 - val_accuracy: 0.8117 - val_recall_1: 0.8374 - val_precision_1: 0.7960 - val_auc_1: 0.9013\n",
      "Epoch 203/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4180 - accuracy: 0.7941 - recall_1: 0.7969 - precision_1: 0.7925 - auc_1: 0.8871 - val_loss: 0.3990 - val_accuracy: 0.8108 - val_recall_1: 0.8170 - val_precision_1: 0.8066 - val_auc_1: 0.9016\n",
      "Epoch 204/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4183 - accuracy: 0.7939 - recall_1: 0.7965 - precision_1: 0.7925 - auc_1: 0.8868 - val_loss: 0.3990 - val_accuracy: 0.8109 - val_recall_1: 0.8333 - val_precision_1: 0.7971 - val_auc_1: 0.9014\n",
      "Epoch 205/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4188 - accuracy: 0.7945 - recall_1: 0.7986 - precision_1: 0.7922 - auc_1: 0.8869 - val_loss: 0.3995 - val_accuracy: 0.8112 - val_recall_1: 0.8374 - val_precision_1: 0.7953 - val_auc_1: 0.9025\n",
      "Epoch 206/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4191 - accuracy: 0.7939 - recall_1: 0.7982 - precision_1: 0.7915 - auc_1: 0.8865 - val_loss: 0.3988 - val_accuracy: 0.8139 - val_recall_1: 0.8248 - val_precision_1: 0.8068 - val_auc_1: 0.9023\n",
      "Epoch 207/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4190 - accuracy: 0.7940 - recall_1: 0.7961 - precision_1: 0.7929 - auc_1: 0.8865 - val_loss: 0.3986 - val_accuracy: 0.8109 - val_recall_1: 0.8389 - val_precision_1: 0.7941 - val_auc_1: 0.9019\n",
      "Epoch 208/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4181 - accuracy: 0.7950 - recall_1: 0.7990 - precision_1: 0.7927 - auc_1: 0.8869 - val_loss: 0.3996 - val_accuracy: 0.8097 - val_recall_1: 0.8615 - val_precision_1: 0.7803 - val_auc_1: 0.9027\n",
      "Epoch 209/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4183 - accuracy: 0.7946 - recall_1: 0.8022 - precision_1: 0.7903 - auc_1: 0.8870 - val_loss: 0.4002 - val_accuracy: 0.8110 - val_recall_1: 0.8459 - val_precision_1: 0.7903 - val_auc_1: 0.9014\n",
      "Epoch 210/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4164 - accuracy: 0.7953 - recall_1: 0.8006 - precision_1: 0.7923 - auc_1: 0.8879 - val_loss: 0.3986 - val_accuracy: 0.8122 - val_recall_1: 0.8290 - val_precision_1: 0.8016 - val_auc_1: 0.9021\n",
      "Epoch 211/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4179 - accuracy: 0.7954 - recall_1: 0.8007 - precision_1: 0.7924 - auc_1: 0.8873 - val_loss: 0.3997 - val_accuracy: 0.8103 - val_recall_1: 0.8311 - val_precision_1: 0.7976 - val_auc_1: 0.9014\n",
      "Epoch 212/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4176 - accuracy: 0.7956 - recall_1: 0.7985 - precision_1: 0.7939 - auc_1: 0.8873 - val_loss: 0.4001 - val_accuracy: 0.8103 - val_recall_1: 0.8422 - val_precision_1: 0.7913 - val_auc_1: 0.9020\n",
      "Epoch 213/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4155 - accuracy: 0.7960 - recall_1: 0.8025 - precision_1: 0.7923 - auc_1: 0.8887 - val_loss: 0.4002 - val_accuracy: 0.8106 - val_recall_1: 0.8206 - val_precision_1: 0.8041 - val_auc_1: 0.9011\n",
      "Epoch 214/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4181 - accuracy: 0.7948 - recall_1: 0.7983 - precision_1: 0.7929 - auc_1: 0.8871 - val_loss: 0.4002 - val_accuracy: 0.8112 - val_recall_1: 0.8435 - val_precision_1: 0.7919 - val_auc_1: 0.9023\n",
      "Epoch 215/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4169 - accuracy: 0.7965 - recall_1: 0.7992 - precision_1: 0.7950 - auc_1: 0.8881 - val_loss: 0.3977 - val_accuracy: 0.8147 - val_recall_1: 0.8263 - val_precision_1: 0.8071 - val_auc_1: 0.9031\n",
      "Epoch 216/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4182 - accuracy: 0.7955 - recall_1: 0.7991 - precision_1: 0.7936 - auc_1: 0.8872 - val_loss: 0.3968 - val_accuracy: 0.8152 - val_recall_1: 0.8180 - val_precision_1: 0.8130 - val_auc_1: 0.9035\n",
      "Epoch 217/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4178 - accuracy: 0.7957 - recall_1: 0.7985 - precision_1: 0.7941 - auc_1: 0.8872 - val_loss: 0.4003 - val_accuracy: 0.8134 - val_recall_1: 0.8405 - val_precision_1: 0.7969 - val_auc_1: 0.9025\n",
      "Epoch 218/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4147 - accuracy: 0.7967 - recall_1: 0.8032 - precision_1: 0.7930 - auc_1: 0.8893 - val_loss: 0.3970 - val_accuracy: 0.8137 - val_recall_1: 0.8338 - val_precision_1: 0.8012 - val_auc_1: 0.9028\n",
      "Epoch 219/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4134 - accuracy: 0.7981 - recall_1: 0.8025 - precision_1: 0.7956 - auc_1: 0.8901 - val_loss: 0.3988 - val_accuracy: 0.8112 - val_recall_1: 0.8320 - val_precision_1: 0.7983 - val_auc_1: 0.9017\n",
      "Epoch 220/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4164 - accuracy: 0.7957 - recall_1: 0.8003 - precision_1: 0.7931 - auc_1: 0.8880 - val_loss: 0.3950 - val_accuracy: 0.8157 - val_recall_1: 0.8241 - val_precision_1: 0.8100 - val_auc_1: 0.9038\n",
      "Epoch 221/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4167 - accuracy: 0.7949 - recall_1: 0.7982 - precision_1: 0.7931 - auc_1: 0.8880 - val_loss: 0.3984 - val_accuracy: 0.8138 - val_recall_1: 0.8322 - val_precision_1: 0.8022 - val_auc_1: 0.9026\n",
      "Epoch 222/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4164 - accuracy: 0.7950 - recall_1: 0.7974 - precision_1: 0.7937 - auc_1: 0.8879 - val_loss: 0.3973 - val_accuracy: 0.8119 - val_recall_1: 0.8380 - val_precision_1: 0.7959 - val_auc_1: 0.9032\n",
      "Epoch 223/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4160 - accuracy: 0.7952 - recall_1: 0.7997 - precision_1: 0.7928 - auc_1: 0.8882 - val_loss: 0.3984 - val_accuracy: 0.8123 - val_recall_1: 0.8352 - val_precision_1: 0.7982 - val_auc_1: 0.9021\n",
      "Epoch 224/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4139 - accuracy: 0.7969 - recall_1: 0.8022 - precision_1: 0.7940 - auc_1: 0.8895 - val_loss: 0.3982 - val_accuracy: 0.8127 - val_recall_1: 0.8220 - val_precision_1: 0.8065 - val_auc_1: 0.9020\n",
      "Epoch 225/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4159 - accuracy: 0.7954 - recall_1: 0.7994 - precision_1: 0.7931 - auc_1: 0.8882 - val_loss: 0.4000 - val_accuracy: 0.8105 - val_recall_1: 0.8460 - val_precision_1: 0.7895 - val_auc_1: 0.9020\n",
      "Epoch 226/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4131 - accuracy: 0.7965 - recall_1: 0.8032 - precision_1: 0.7926 - auc_1: 0.8898 - val_loss: 0.3972 - val_accuracy: 0.8132 - val_recall_1: 0.8364 - val_precision_1: 0.7989 - val_auc_1: 0.9028\n",
      "Epoch 227/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4133 - accuracy: 0.7964 - recall_1: 0.8017 - precision_1: 0.7934 - auc_1: 0.8896 - val_loss: 0.3957 - val_accuracy: 0.8135 - val_recall_1: 0.8115 - val_precision_1: 0.8143 - val_auc_1: 0.9030\n",
      "Epoch 228/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4137 - accuracy: 0.7977 - recall_1: 0.8015 - precision_1: 0.7955 - auc_1: 0.8899 - val_loss: 0.3972 - val_accuracy: 0.8132 - val_recall_1: 0.8336 - val_precision_1: 0.8005 - val_auc_1: 0.9027\n",
      "Epoch 229/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4150 - accuracy: 0.7964 - recall_1: 0.8014 - precision_1: 0.7937 - auc_1: 0.8889 - val_loss: 0.3989 - val_accuracy: 0.8107 - val_recall_1: 0.8300 - val_precision_1: 0.7988 - val_auc_1: 0.9020\n",
      "Epoch 230/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4137 - accuracy: 0.7980 - recall_1: 0.8021 - precision_1: 0.7957 - auc_1: 0.8894 - val_loss: 0.3952 - val_accuracy: 0.8152 - val_recall_1: 0.8313 - val_precision_1: 0.8050 - val_auc_1: 0.9044\n",
      "Epoch 231/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4137 - accuracy: 0.7968 - recall_1: 0.8019 - precision_1: 0.7939 - auc_1: 0.8896 - val_loss: 0.3961 - val_accuracy: 0.8114 - val_recall_1: 0.8138 - val_precision_1: 0.8095 - val_auc_1: 0.9024\n",
      "Epoch 232/500\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 0.4148 - accuracy: 0.7965 - recall_1: 0.8026 - precision_1: 0.7930 - auc_1: 0.8889 - val_loss: 0.3990 - val_accuracy: 0.8122 - val_recall_1: 0.8376 - val_precision_1: 0.7967 - val_auc_1: 0.9020\n",
      "Epoch 233/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4138 - accuracy: 0.7972 - recall_1: 0.8012 - precision_1: 0.7949 - auc_1: 0.8897 - val_loss: 0.3961 - val_accuracy: 0.8117 - val_recall_1: 0.8289 - val_precision_1: 0.8010 - val_auc_1: 0.9027\n",
      "Epoch 234/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4143 - accuracy: 0.7989 - recall_1: 0.8037 - precision_1: 0.7962 - auc_1: 0.8897 - val_loss: 0.3963 - val_accuracy: 0.8123 - val_recall_1: 0.8250 - val_precision_1: 0.8041 - val_auc_1: 0.9028\n",
      "Epoch 235/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4151 - accuracy: 0.7970 - recall_1: 0.8021 - precision_1: 0.7941 - auc_1: 0.8893 - val_loss: 0.3976 - val_accuracy: 0.8103 - val_recall_1: 0.8367 - val_precision_1: 0.7943 - val_auc_1: 0.9026\n",
      "Epoch 236/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4140 - accuracy: 0.7970 - recall_1: 0.8020 - precision_1: 0.7942 - auc_1: 0.8897 - val_loss: 0.3955 - val_accuracy: 0.8108 - val_recall_1: 0.8331 - val_precision_1: 0.7971 - val_auc_1: 0.9032\n",
      "Epoch 237/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4142 - accuracy: 0.7979 - recall_1: 0.8024 - precision_1: 0.7953 - auc_1: 0.8894 - val_loss: 0.3957 - val_accuracy: 0.8144 - val_recall_1: 0.8371 - val_precision_1: 0.8003 - val_auc_1: 0.9037\n",
      "Epoch 238/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4127 - accuracy: 0.7973 - recall_1: 0.8011 - precision_1: 0.7952 - auc_1: 0.8902 - val_loss: 0.3964 - val_accuracy: 0.8124 - val_recall_1: 0.8418 - val_precision_1: 0.7946 - val_auc_1: 0.9034\n",
      "Epoch 239/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4137 - accuracy: 0.7973 - recall_1: 0.8031 - precision_1: 0.7939 - auc_1: 0.8897 - val_loss: 0.3967 - val_accuracy: 0.8128 - val_recall_1: 0.8427 - val_precision_1: 0.7948 - val_auc_1: 0.9037\n",
      "Epoch 240/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4120 - accuracy: 0.7970 - recall_1: 0.8026 - precision_1: 0.7939 - auc_1: 0.8904 - val_loss: 0.3954 - val_accuracy: 0.8136 - val_recall_1: 0.8337 - val_precision_1: 0.8010 - val_auc_1: 0.9040\n",
      "Epoch 241/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.7983 - recall_1: 0.8033 - precision_1: 0.7955 - auc_1: 0.8899 - val_loss: 0.3948 - val_accuracy: 0.8140 - val_recall_1: 0.8380 - val_precision_1: 0.7991 - val_auc_1: 0.9043\n",
      "Epoch 242/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.7982 - recall_1: 0.8042 - precision_1: 0.7948 - auc_1: 0.8900 - val_loss: 0.3947 - val_accuracy: 0.8137 - val_recall_1: 0.8305 - val_precision_1: 0.8031 - val_auc_1: 0.9040\n",
      "Epoch 243/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4102 - accuracy: 0.7980 - recall_1: 0.8021 - precision_1: 0.7957 - auc_1: 0.8916 - val_loss: 0.3944 - val_accuracy: 0.8134 - val_recall_1: 0.8326 - val_precision_1: 0.8014 - val_auc_1: 0.9040\n",
      "Epoch 244/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4123 - accuracy: 0.7977 - recall_1: 0.8034 - precision_1: 0.7944 - auc_1: 0.8904 - val_loss: 0.3950 - val_accuracy: 0.8148 - val_recall_1: 0.8149 - val_precision_1: 0.8144 - val_auc_1: 0.9034\n",
      "Epoch 245/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.7975 - recall_1: 0.8005 - precision_1: 0.7958 - auc_1: 0.8893 - val_loss: 0.3959 - val_accuracy: 0.8144 - val_recall_1: 0.8468 - val_precision_1: 0.7949 - val_auc_1: 0.9041\n",
      "Epoch 246/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8002 - recall_1: 0.8061 - precision_1: 0.7968 - auc_1: 0.8917 - val_loss: 0.3943 - val_accuracy: 0.8147 - val_recall_1: 0.8313 - val_precision_1: 0.8042 - val_auc_1: 0.9041\n",
      "Epoch 247/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4138 - accuracy: 0.7970 - recall_1: 0.8019 - precision_1: 0.7942 - auc_1: 0.8897 - val_loss: 0.3952 - val_accuracy: 0.8142 - val_recall_1: 0.8466 - val_precision_1: 0.7946 - val_auc_1: 0.9046\n",
      "Epoch 248/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.7985 - recall_1: 0.8038 - precision_1: 0.7955 - auc_1: 0.8906 - val_loss: 0.3926 - val_accuracy: 0.8153 - val_recall_1: 0.8411 - val_precision_1: 0.7995 - val_auc_1: 0.9052\n",
      "Epoch 249/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4112 - accuracy: 0.7989 - recall_1: 0.8051 - precision_1: 0.7953 - auc_1: 0.8912 - val_loss: 0.3906 - val_accuracy: 0.8159 - val_recall_1: 0.8181 - val_precision_1: 0.8140 - val_auc_1: 0.9061\n",
      "Epoch 250/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.7970 - recall_1: 0.8004 - precision_1: 0.7952 - auc_1: 0.8899 - val_loss: 0.3916 - val_accuracy: 0.8150 - val_recall_1: 0.8127 - val_precision_1: 0.8160 - val_auc_1: 0.9053\n",
      "Epoch 251/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.7983 - recall_1: 0.8014 - precision_1: 0.7967 - auc_1: 0.8906 - val_loss: 0.3908 - val_accuracy: 0.8163 - val_recall_1: 0.8265 - val_precision_1: 0.8095 - val_auc_1: 0.9060\n",
      "Epoch 252/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4104 - accuracy: 0.7994 - recall_1: 0.8054 - precision_1: 0.7959 - auc_1: 0.8916 - val_loss: 0.3922 - val_accuracy: 0.8142 - val_recall_1: 0.8284 - val_precision_1: 0.8051 - val_auc_1: 0.9048\n",
      "Epoch 253/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.7974 - recall_1: 0.8026 - precision_1: 0.7944 - auc_1: 0.8897 - val_loss: 0.3943 - val_accuracy: 0.8163 - val_recall_1: 0.8439 - val_precision_1: 0.7993 - val_auc_1: 0.9054\n",
      "Epoch 254/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4105 - accuracy: 0.7982 - recall_1: 0.8018 - precision_1: 0.7961 - auc_1: 0.8912 - val_loss: 0.3928 - val_accuracy: 0.8155 - val_recall_1: 0.8265 - val_precision_1: 0.8082 - val_auc_1: 0.9051\n",
      "Epoch 255/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4137 - accuracy: 0.7984 - recall_1: 0.8009 - precision_1: 0.7970 - auc_1: 0.8898 - val_loss: 0.3936 - val_accuracy: 0.8143 - val_recall_1: 0.8431 - val_precision_1: 0.7968 - val_auc_1: 0.9052\n",
      "Epoch 256/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4093 - accuracy: 0.8004 - recall_1: 0.8035 - precision_1: 0.7986 - auc_1: 0.8922 - val_loss: 0.3909 - val_accuracy: 0.8168 - val_recall_1: 0.8309 - val_precision_1: 0.8076 - val_auc_1: 0.9056\n",
      "Epoch 257/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4115 - accuracy: 0.7987 - recall_1: 0.8016 - precision_1: 0.7971 - auc_1: 0.8909 - val_loss: 0.3938 - val_accuracy: 0.8168 - val_recall_1: 0.8342 - val_precision_1: 0.8056 - val_auc_1: 0.9052\n",
      "Epoch 258/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4110 - accuracy: 0.7997 - recall_1: 0.8031 - precision_1: 0.7977 - auc_1: 0.8913 - val_loss: 0.3916 - val_accuracy: 0.8172 - val_recall_1: 0.8158 - val_precision_1: 0.8177 - val_auc_1: 0.9056\n",
      "Epoch 259/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8011 - recall_1: 0.8049 - precision_1: 0.7989 - auc_1: 0.8929 - val_loss: 0.3925 - val_accuracy: 0.8157 - val_recall_1: 0.8359 - val_precision_1: 0.8030 - val_auc_1: 0.9052\n",
      "Epoch 260/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4107 - accuracy: 0.7985 - recall_1: 0.8026 - precision_1: 0.7962 - auc_1: 0.8912 - val_loss: 0.3907 - val_accuracy: 0.8164 - val_recall_1: 0.8199 - val_precision_1: 0.8137 - val_auc_1: 0.9057\n",
      "Epoch 261/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4100 - accuracy: 0.7995 - recall_1: 0.8049 - precision_1: 0.7964 - auc_1: 0.8916 - val_loss: 0.3947 - val_accuracy: 0.8152 - val_recall_1: 0.8394 - val_precision_1: 0.8002 - val_auc_1: 0.9047\n",
      "Epoch 262/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.7994 - recall_1: 0.8047 - precision_1: 0.7964 - auc_1: 0.8916 - val_loss: 0.3910 - val_accuracy: 0.8165 - val_recall_1: 0.8196 - val_precision_1: 0.8142 - val_auc_1: 0.9059\n",
      "Epoch 263/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4098 - accuracy: 0.8019 - recall_1: 0.8055 - precision_1: 0.8000 - auc_1: 0.8923 - val_loss: 0.3928 - val_accuracy: 0.8165 - val_recall_1: 0.8379 - val_precision_1: 0.8030 - val_auc_1: 0.9050\n",
      "Epoch 264/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4098 - accuracy: 0.8007 - recall_1: 0.8050 - precision_1: 0.7983 - auc_1: 0.8920 - val_loss: 0.3914 - val_accuracy: 0.8173 - val_recall_1: 0.8436 - val_precision_1: 0.8010 - val_auc_1: 0.9061\n",
      "Epoch 265/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8010 - recall_1: 0.8034 - precision_1: 0.7996 - auc_1: 0.8932 - val_loss: 0.3897 - val_accuracy: 0.8164 - val_recall_1: 0.8359 - val_precision_1: 0.8041 - val_auc_1: 0.9062\n",
      "Epoch 266/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4086 - accuracy: 0.8004 - recall_1: 0.8036 - precision_1: 0.7986 - auc_1: 0.8927 - val_loss: 0.3874 - val_accuracy: 0.8182 - val_recall_1: 0.8086 - val_precision_1: 0.8239 - val_auc_1: 0.9079\n",
      "Epoch 267/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4101 - accuracy: 0.7997 - recall_1: 0.8020 - precision_1: 0.7985 - auc_1: 0.8918 - val_loss: 0.3895 - val_accuracy: 0.8166 - val_recall_1: 0.8428 - val_precision_1: 0.8005 - val_auc_1: 0.9074\n",
      "Epoch 268/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8001 - recall_1: 0.8068 - precision_1: 0.7962 - auc_1: 0.8919 - val_loss: 0.3910 - val_accuracy: 0.8174 - val_recall_1: 0.8233 - val_precision_1: 0.8132 - val_auc_1: 0.9060\n",
      "Epoch 269/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4083 - accuracy: 0.8006 - recall_1: 0.8027 - precision_1: 0.7994 - auc_1: 0.8928 - val_loss: 0.3881 - val_accuracy: 0.8175 - val_recall_1: 0.8303 - val_precision_1: 0.8092 - val_auc_1: 0.9076\n",
      "Epoch 270/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4076 - accuracy: 0.8015 - recall_1: 0.8062 - precision_1: 0.7987 - auc_1: 0.8932 - val_loss: 0.3894 - val_accuracy: 0.8176 - val_recall_1: 0.8158 - val_precision_1: 0.8184 - val_auc_1: 0.9067\n",
      "Epoch 271/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4089 - accuracy: 0.8013 - recall_1: 0.8040 - precision_1: 0.7998 - auc_1: 0.8925 - val_loss: 0.3912 - val_accuracy: 0.8161 - val_recall_1: 0.8437 - val_precision_1: 0.7992 - val_auc_1: 0.9057\n",
      "Epoch 272/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4094 - accuracy: 0.8009 - recall_1: 0.8055 - precision_1: 0.7982 - auc_1: 0.8924 - val_loss: 0.3919 - val_accuracy: 0.8169 - val_recall_1: 0.8274 - val_precision_1: 0.8099 - val_auc_1: 0.9056\n",
      "Epoch 273/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4076 - accuracy: 0.8006 - recall_1: 0.8031 - precision_1: 0.7992 - auc_1: 0.8932 - val_loss: 0.3888 - val_accuracy: 0.8197 - val_recall_1: 0.8312 - val_precision_1: 0.8121 - val_auc_1: 0.9074\n",
      "Epoch 274/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8006 - recall_1: 0.8026 - precision_1: 0.7996 - auc_1: 0.8935 - val_loss: 0.3920 - val_accuracy: 0.8169 - val_recall_1: 0.8509 - val_precision_1: 0.7963 - val_auc_1: 0.9062\n",
      "Epoch 275/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4088 - accuracy: 0.8010 - recall_1: 0.8037 - precision_1: 0.7995 - auc_1: 0.8926 - val_loss: 0.3904 - val_accuracy: 0.8187 - val_recall_1: 0.8459 - val_precision_1: 0.8018 - val_auc_1: 0.9065\n",
      "Epoch 276/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4084 - accuracy: 0.8013 - recall_1: 0.8049 - precision_1: 0.7993 - auc_1: 0.8928 - val_loss: 0.3906 - val_accuracy: 0.8160 - val_recall_1: 0.8261 - val_precision_1: 0.8094 - val_auc_1: 0.9061\n",
      "Epoch 277/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4084 - accuracy: 0.8017 - recall_1: 0.8018 - precision_1: 0.8017 - auc_1: 0.8929 - val_loss: 0.3905 - val_accuracy: 0.8187 - val_recall_1: 0.8445 - val_precision_1: 0.8027 - val_auc_1: 0.9065\n",
      "Epoch 278/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.7984 - recall_1: 0.8024 - precision_1: 0.7962 - auc_1: 0.8908 - val_loss: 0.3915 - val_accuracy: 0.8165 - val_recall_1: 0.8146 - val_precision_1: 0.8172 - val_auc_1: 0.9060\n",
      "Epoch 279/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8008 - recall_1: 0.8048 - precision_1: 0.7985 - auc_1: 0.8931 - val_loss: 0.3927 - val_accuracy: 0.8147 - val_recall_1: 0.8253 - val_precision_1: 0.8077 - val_auc_1: 0.9050\n",
      "Epoch 280/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4070 - accuracy: 0.8024 - recall_1: 0.8066 - precision_1: 0.8000 - auc_1: 0.8938 - val_loss: 0.3911 - val_accuracy: 0.8159 - val_recall_1: 0.8184 - val_precision_1: 0.8139 - val_auc_1: 0.9060\n",
      "Epoch 281/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8013 - recall_1: 0.8012 - precision_1: 0.8014 - auc_1: 0.8934 - val_loss: 0.3885 - val_accuracy: 0.8185 - val_recall_1: 0.8192 - val_precision_1: 0.8175 - val_auc_1: 0.9073\n",
      "Epoch 282/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4071 - accuracy: 0.8006 - recall_1: 0.8043 - precision_1: 0.7985 - auc_1: 0.8934 - val_loss: 0.3920 - val_accuracy: 0.8156 - val_recall_1: 0.8352 - val_precision_1: 0.8033 - val_auc_1: 0.9056\n",
      "Epoch 283/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4087 - accuracy: 0.8007 - recall_1: 0.8049 - precision_1: 0.7984 - auc_1: 0.8927 - val_loss: 0.3878 - val_accuracy: 0.8158 - val_recall_1: 0.8168 - val_precision_1: 0.8147 - val_auc_1: 0.9069\n",
      "Epoch 284/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8000 - recall_1: 0.8022 - precision_1: 0.7988 - auc_1: 0.8928 - val_loss: 0.3889 - val_accuracy: 0.8182 - val_recall_1: 0.8337 - val_precision_1: 0.8082 - val_auc_1: 0.9068\n",
      "Epoch 285/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4072 - accuracy: 0.8019 - recall_1: 0.8031 - precision_1: 0.8012 - auc_1: 0.8936 - val_loss: 0.3934 - val_accuracy: 0.8155 - val_recall_1: 0.8539 - val_precision_1: 0.7926 - val_auc_1: 0.9058\n",
      "Epoch 286/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4078 - accuracy: 0.8009 - recall_1: 0.8056 - precision_1: 0.7983 - auc_1: 0.8928 - val_loss: 0.3892 - val_accuracy: 0.8164 - val_recall_1: 0.8364 - val_precision_1: 0.8038 - val_auc_1: 0.9068\n",
      "Epoch 287/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4069 - accuracy: 0.8010 - recall_1: 0.8055 - precision_1: 0.7985 - auc_1: 0.8936 - val_loss: 0.3929 - val_accuracy: 0.8171 - val_recall_1: 0.8276 - val_precision_1: 0.8102 - val_auc_1: 0.9054\n",
      "Epoch 288/500\n",
      "483/483 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8012 - recall_1: 0.8030 - precision_1: 0.8003 - auc_1: 0.8935 - val_loss: 0.3909 - val_accuracy: 0.8189 - val_recall_1: 0.8438 - val_precision_1: 0.8034 - val_auc_1: 0.9064\n",
      "Epoch 289/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4064 - accuracy: 0.8014 - recall_1: 0.8037 - precision_1: 0.8002 - auc_1: 0.8938 - val_loss: 0.3912 - val_accuracy: 0.8168 - val_recall_1: 0.8545 - val_precision_1: 0.7942 - val_auc_1: 0.9071\n",
      "Epoch 290/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4072 - accuracy: 0.8023 - recall_1: 0.8066 - precision_1: 0.7998 - auc_1: 0.8936 - val_loss: 0.3897 - val_accuracy: 0.8190 - val_recall_1: 0.8326 - val_precision_1: 0.8101 - val_auc_1: 0.9075\n",
      "Epoch 291/500\n",
      "483/483 [==============================] - 2s 3ms/step - loss: 0.4097 - accuracy: 0.8002 - recall_1: 0.8024 - precision_1: 0.7990 - auc_1: 0.8923 - val_loss: 0.3915 - val_accuracy: 0.8158 - val_recall_1: 0.8296 - val_precision_1: 0.8069 - val_auc_1: 0.9060\n",
      "3857/3857 [==============================] - 3s 758us/step\n",
      "965/965 [==============================] - 1s 823us/step\n",
      "Acurácia no conjunto de treinamento: 0.8918800354003906\n",
      "Acurácia no conjunto de teste: 0.8181523680686951\n",
      "AUC no conjunto de treinamento: 0.9680042331336707\n",
      "AUC no conjunto de teste: 0.9078807331713091\n",
      "965/965 [==============================] - 1s 796us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.81      0.83      0.82     15448\n",
      "    Classe 1       0.82      0.81      0.82     15402\n",
      "\n",
      "    accuracy                           0.82     30850\n",
      "   macro avg       0.82      0.82      0.82     30850\n",
      "weighted avg       0.82      0.82      0.82     30850\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2, l1_l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "# classes = np.unique(y_train)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "# class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Criação do modelo com possivelmente mais capacidade\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.25))  # Ajuste fino do dropout\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.15))  # Ajuste fino do dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Otimizador com taxa de aprendizado inicial mais alta \n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', tf.metrics.Recall(), tf.metrics.Precision(), tf.metrics.AUC()])\n",
    "\n",
    "# Ajuste no callback de EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "\n",
    "# Treinamento do modelo com pesos das classes se o conjunto for desbalanceado\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=256,  # Alteração do batch size\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva de Aprendizado: A curva de aprendizado mostra que a acurácia de validação e treinamento estão se aproximando uma da outra conforme o número de épocas aumenta, o que é um bom sinal de que o modelo não está sofrendo de overfitting significativo.\n",
    "\n",
    "Acurácia e AUC: A acurácia e a Área Sob a Curva ROC (AUC) no conjunto de teste são bastante altas, o que sugere que o modelo tem um bom desempenho geral.\n",
    "\n",
    "Recall e Precision: Os valores de recall e precisão são bastante equilibrados para as previsões no conjunto de validação, indicando que o modelo tem um desempenho bom e equilibrado em relação a ambas as classes.\n",
    "\n",
    "Relatório de Classificação: O relatório de classificação mostra resultados quase simétricos para as classes 0 e 1, com uma precisão, recall e pontuação F1 bastante semelhantes para ambas, o que sugere que o modelo está tratando ambas as classes de forma equitativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965/965 [==============================] - 1s 728us/step\n",
      "Threshold: 0.10, Precision: 0.587, Recall: 0.998, F1 Score: 0.739, Accuracy: 0.648\n",
      "Threshold: 0.11, Precision: 0.593, Recall: 0.997, F1 Score: 0.744, Accuracy: 0.657\n",
      "Threshold: 0.12, Precision: 0.599, Recall: 0.996, F1 Score: 0.748, Accuracy: 0.665\n",
      "Threshold: 0.13, Precision: 0.605, Recall: 0.996, F1 Score: 0.753, Accuracy: 0.674\n",
      "Threshold: 0.14, Precision: 0.611, Recall: 0.995, F1 Score: 0.757, Accuracy: 0.681\n",
      "Threshold: 0.15, Precision: 0.616, Recall: 0.995, F1 Score: 0.761, Accuracy: 0.688\n",
      "Threshold: 0.16, Precision: 0.621, Recall: 0.994, F1 Score: 0.764, Accuracy: 0.694\n",
      "Threshold: 0.17, Precision: 0.627, Recall: 0.993, F1 Score: 0.768, Accuracy: 0.701\n",
      "Threshold: 0.18, Precision: 0.632, Recall: 0.992, F1 Score: 0.772, Accuracy: 0.708\n",
      "Threshold: 0.19, Precision: 0.637, Recall: 0.990, F1 Score: 0.775, Accuracy: 0.713\n",
      "Threshold: 0.20, Precision: 0.641, Recall: 0.989, F1 Score: 0.778, Accuracy: 0.718\n",
      "Threshold: 0.21, Precision: 0.646, Recall: 0.987, F1 Score: 0.781, Accuracy: 0.724\n",
      "Threshold: 0.22, Precision: 0.651, Recall: 0.986, F1 Score: 0.784, Accuracy: 0.729\n",
      "Threshold: 0.23, Precision: 0.655, Recall: 0.984, F1 Score: 0.787, Accuracy: 0.733\n",
      "Threshold: 0.24, Precision: 0.659, Recall: 0.983, F1 Score: 0.789, Accuracy: 0.738\n",
      "Threshold: 0.25, Precision: 0.664, Recall: 0.982, F1 Score: 0.792, Accuracy: 0.743\n",
      "Threshold: 0.26, Precision: 0.668, Recall: 0.980, F1 Score: 0.795, Accuracy: 0.747\n",
      "Threshold: 0.27, Precision: 0.672, Recall: 0.977, F1 Score: 0.796, Accuracy: 0.750\n",
      "Threshold: 0.28, Precision: 0.676, Recall: 0.975, F1 Score: 0.798, Accuracy: 0.754\n",
      "Threshold: 0.29, Precision: 0.681, Recall: 0.973, F1 Score: 0.801, Accuracy: 0.759\n",
      "Threshold: 0.30, Precision: 0.685, Recall: 0.971, F1 Score: 0.803, Accuracy: 0.763\n",
      "Threshold: 0.31, Precision: 0.689, Recall: 0.969, F1 Score: 0.805, Accuracy: 0.766\n",
      "Threshold: 0.32, Precision: 0.693, Recall: 0.966, F1 Score: 0.807, Accuracy: 0.770\n",
      "Threshold: 0.33, Precision: 0.698, Recall: 0.962, F1 Score: 0.809, Accuracy: 0.773\n",
      "Threshold: 0.34, Precision: 0.701, Recall: 0.959, F1 Score: 0.810, Accuracy: 0.776\n",
      "Threshold: 0.35, Precision: 0.706, Recall: 0.955, F1 Score: 0.812, Accuracy: 0.779\n",
      "Threshold: 0.36, Precision: 0.710, Recall: 0.951, F1 Score: 0.813, Accuracy: 0.781\n",
      "Threshold: 0.37, Precision: 0.714, Recall: 0.947, F1 Score: 0.814, Accuracy: 0.784\n",
      "Threshold: 0.38, Precision: 0.719, Recall: 0.942, F1 Score: 0.816, Accuracy: 0.787\n",
      "Threshold: 0.39, Precision: 0.724, Recall: 0.937, F1 Score: 0.817, Accuracy: 0.790\n",
      "Threshold: 0.40, Precision: 0.730, Recall: 0.931, F1 Score: 0.818, Accuracy: 0.793\n",
      "Threshold: 0.41, Precision: 0.735, Recall: 0.924, F1 Score: 0.819, Accuracy: 0.796\n",
      "Threshold: 0.42, Precision: 0.741, Recall: 0.917, F1 Score: 0.819, Accuracy: 0.798\n",
      "Threshold: 0.43, Precision: 0.747, Recall: 0.908, F1 Score: 0.819, Accuracy: 0.800\n",
      "Threshold: 0.44, Precision: 0.752, Recall: 0.897, F1 Score: 0.819, Accuracy: 0.801\n",
      "Threshold: 0.45, Precision: 0.760, Recall: 0.883, F1 Score: 0.817, Accuracy: 0.803\n",
      "Threshold: 0.46, Precision: 0.770, Recall: 0.867, F1 Score: 0.816, Accuracy: 0.805\n",
      "Threshold: 0.47, Precision: 0.781, Recall: 0.851, F1 Score: 0.814, Accuracy: 0.806\n",
      "Threshold: 0.48, Precision: 0.793, Recall: 0.834, F1 Score: 0.813, Accuracy: 0.808\n",
      "Threshold: 0.49, Precision: 0.803, Recall: 0.818, F1 Score: 0.810, Accuracy: 0.809\n",
      "Threshold: 0.50, Precision: 0.813, Recall: 0.804, F1 Score: 0.809, Accuracy: 0.810\n",
      "Threshold: 0.51, Precision: 0.822, Recall: 0.793, F1 Score: 0.807, Accuracy: 0.811\n",
      "Threshold: 0.52, Precision: 0.829, Recall: 0.783, F1 Score: 0.805, Accuracy: 0.811\n",
      "Threshold: 0.53, Precision: 0.835, Recall: 0.773, F1 Score: 0.803, Accuracy: 0.810\n",
      "Threshold: 0.54, Precision: 0.840, Recall: 0.761, F1 Score: 0.799, Accuracy: 0.808\n",
      "Threshold: 0.55, Precision: 0.845, Recall: 0.752, F1 Score: 0.796, Accuracy: 0.807\n",
      "Threshold: 0.56, Precision: 0.850, Recall: 0.743, F1 Score: 0.793, Accuracy: 0.806\n",
      "Threshold: 0.57, Precision: 0.854, Recall: 0.735, F1 Score: 0.790, Accuracy: 0.805\n",
      "Threshold: 0.58, Precision: 0.858, Recall: 0.725, F1 Score: 0.786, Accuracy: 0.803\n",
      "Threshold: 0.59, Precision: 0.863, Recall: 0.716, F1 Score: 0.783, Accuracy: 0.801\n",
      "Threshold: 0.60, Precision: 0.868, Recall: 0.706, F1 Score: 0.778, Accuracy: 0.799\n",
      "Threshold: 0.61, Precision: 0.872, Recall: 0.696, F1 Score: 0.774, Accuracy: 0.797\n",
      "Threshold: 0.62, Precision: 0.876, Recall: 0.686, F1 Score: 0.770, Accuracy: 0.795\n",
      "Threshold: 0.63, Precision: 0.881, Recall: 0.678, F1 Score: 0.766, Accuracy: 0.793\n",
      "Threshold: 0.64, Precision: 0.884, Recall: 0.668, F1 Score: 0.761, Accuracy: 0.791\n",
      "Threshold: 0.65, Precision: 0.888, Recall: 0.658, F1 Score: 0.756, Accuracy: 0.788\n",
      "Threshold: 0.66, Precision: 0.892, Recall: 0.646, F1 Score: 0.750, Accuracy: 0.784\n",
      "Threshold: 0.67, Precision: 0.896, Recall: 0.637, F1 Score: 0.745, Accuracy: 0.782\n",
      "Threshold: 0.68, Precision: 0.899, Recall: 0.627, F1 Score: 0.739, Accuracy: 0.779\n",
      "Threshold: 0.69, Precision: 0.902, Recall: 0.617, F1 Score: 0.733, Accuracy: 0.775\n",
      "Threshold: 0.70, Precision: 0.903, Recall: 0.606, F1 Score: 0.725, Accuracy: 0.771\n",
      "Threshold: 0.71, Precision: 0.907, Recall: 0.596, F1 Score: 0.719, Accuracy: 0.768\n",
      "Threshold: 0.72, Precision: 0.910, Recall: 0.584, F1 Score: 0.712, Accuracy: 0.764\n",
      "Threshold: 0.73, Precision: 0.913, Recall: 0.570, F1 Score: 0.702, Accuracy: 0.758\n",
      "Threshold: 0.74, Precision: 0.915, Recall: 0.558, F1 Score: 0.694, Accuracy: 0.754\n",
      "Threshold: 0.75, Precision: 0.917, Recall: 0.547, F1 Score: 0.686, Accuracy: 0.749\n",
      "Threshold: 0.76, Precision: 0.921, Recall: 0.534, F1 Score: 0.676, Accuracy: 0.744\n",
      "Threshold: 0.77, Precision: 0.924, Recall: 0.519, F1 Score: 0.664, Accuracy: 0.738\n",
      "Threshold: 0.78, Precision: 0.927, Recall: 0.506, F1 Score: 0.654, Accuracy: 0.733\n",
      "Threshold: 0.79, Precision: 0.930, Recall: 0.491, F1 Score: 0.642, Accuracy: 0.727\n",
      "Threshold: 0.80, Precision: 0.934, Recall: 0.475, F1 Score: 0.630, Accuracy: 0.721\n",
      "Threshold: 0.81, Precision: 0.936, Recall: 0.459, F1 Score: 0.616, Accuracy: 0.714\n",
      "Threshold: 0.82, Precision: 0.938, Recall: 0.443, F1 Score: 0.602, Accuracy: 0.707\n",
      "Threshold: 0.83, Precision: 0.940, Recall: 0.426, F1 Score: 0.587, Accuracy: 0.700\n",
      "Threshold: 0.84, Precision: 0.943, Recall: 0.408, F1 Score: 0.570, Accuracy: 0.692\n",
      "Threshold: 0.85, Precision: 0.944, Recall: 0.389, F1 Score: 0.551, Accuracy: 0.684\n",
      "Threshold: 0.86, Precision: 0.947, Recall: 0.370, F1 Score: 0.532, Accuracy: 0.675\n",
      "Threshold: 0.87, Precision: 0.948, Recall: 0.349, F1 Score: 0.511, Accuracy: 0.666\n",
      "Threshold: 0.88, Precision: 0.948, Recall: 0.327, F1 Score: 0.486, Accuracy: 0.655\n",
      "Threshold: 0.89, Precision: 0.948, Recall: 0.302, F1 Score: 0.458, Accuracy: 0.643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
