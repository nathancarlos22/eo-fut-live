{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'league',\n",
       "       'corners_home', 'corners_away', 'shotsOffgoal_home',\n",
       "       'shotsOffgoal_away', 'shotsOngoal_home', 'shotsOngoal_away',\n",
       "       'fouls_home', 'fouls_away', 'tackles_home', 'tackles_away', 'result',\n",
       "       'match_id', 'possessiontime_away', 'possessiontime_home',\n",
       "       'shotsOnGoalEfficiency', 'attackPressure', 'shotAccuracy_home',\n",
       "       'shotAccuracy_away', 'possessionControl', 'passRisk',\n",
       "       'defensiveDiscipline', 'defensiveEfficacy', 'defensiveAggression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.6680 - accuracy: 0.7566 - recall: 0.7565 - precision: 0.7571 - val_loss: 0.5777 - val_accuracy: 0.7858 - val_recall: 0.7645 - val_precision: 0.7971\n",
      "Epoch 2/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.5654 - accuracy: 0.7858 - recall: 0.7444 - precision: 0.8119 - val_loss: 0.5114 - val_accuracy: 0.7968 - val_recall: 0.7405 - val_precision: 0.8329\n",
      "Epoch 3/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.5141 - accuracy: 0.7959 - recall: 0.7228 - precision: 0.8470 - val_loss: 0.4764 - val_accuracy: 0.8008 - val_recall: 0.7290 - val_precision: 0.8496\n",
      "Epoch 4/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4824 - accuracy: 0.8009 - recall: 0.7093 - precision: 0.8687 - val_loss: 0.4505 - val_accuracy: 0.8076 - val_recall: 0.7082 - val_precision: 0.8822\n",
      "Epoch 5/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4614 - accuracy: 0.8039 - recall: 0.6975 - precision: 0.8864 - val_loss: 0.4340 - val_accuracy: 0.8117 - val_recall: 0.6946 - val_precision: 0.9052\n",
      "Epoch 6/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4464 - accuracy: 0.8064 - recall: 0.6894 - precision: 0.9004 - val_loss: 0.4231 - val_accuracy: 0.8134 - val_recall: 0.6909 - val_precision: 0.9133\n",
      "Epoch 7/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4356 - accuracy: 0.8087 - recall: 0.6847 - precision: 0.9109 - val_loss: 0.4170 - val_accuracy: 0.8121 - val_recall: 0.6911 - val_precision: 0.9099\n",
      "Epoch 8/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4284 - accuracy: 0.8097 - recall: 0.6820 - precision: 0.9165 - val_loss: 0.4110 - val_accuracy: 0.8148 - val_recall: 0.6875 - val_precision: 0.9204\n",
      "Epoch 9/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4217 - accuracy: 0.8107 - recall: 0.6786 - precision: 0.9228 - val_loss: 0.4062 - val_accuracy: 0.8151 - val_recall: 0.6847 - val_precision: 0.9243\n",
      "Epoch 10/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4177 - accuracy: 0.8115 - recall: 0.6765 - precision: 0.9271 - val_loss: 0.4042 - val_accuracy: 0.8167 - val_recall: 0.6782 - val_precision: 0.9361\n",
      "Epoch 11/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.4136 - accuracy: 0.8119 - recall: 0.6746 - precision: 0.9306 - val_loss: 0.4006 - val_accuracy: 0.8164 - val_recall: 0.6803 - val_precision: 0.9328\n",
      "Epoch 12/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.4121 - accuracy: 0.8117 - recall: 0.6731 - precision: 0.9318 - val_loss: 0.3991 - val_accuracy: 0.8159 - val_recall: 0.6813 - val_precision: 0.9305\n",
      "Epoch 13/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.4088 - accuracy: 0.8124 - recall: 0.6731 - precision: 0.9335 - val_loss: 0.3972 - val_accuracy: 0.8171 - val_recall: 0.6777 - val_precision: 0.9376\n",
      "Epoch 14/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.4064 - accuracy: 0.8130 - recall: 0.6727 - precision: 0.9357 - val_loss: 0.3956 - val_accuracy: 0.8180 - val_recall: 0.6762 - val_precision: 0.9419\n",
      "Epoch 15/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.4052 - accuracy: 0.8130 - recall: 0.6716 - precision: 0.9368 - val_loss: 0.3947 - val_accuracy: 0.8168 - val_recall: 0.6787 - val_precision: 0.9358\n",
      "Epoch 16/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.4041 - accuracy: 0.8130 - recall: 0.6715 - precision: 0.9369 - val_loss: 0.3933 - val_accuracy: 0.8175 - val_recall: 0.6764 - val_precision: 0.9404\n",
      "Epoch 17/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.4029 - accuracy: 0.8133 - recall: 0.6713 - precision: 0.9380 - val_loss: 0.3931 - val_accuracy: 0.8177 - val_recall: 0.6778 - val_precision: 0.9392\n",
      "Epoch 18/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.4016 - accuracy: 0.8134 - recall: 0.6707 - precision: 0.9391 - val_loss: 0.3916 - val_accuracy: 0.8171 - val_recall: 0.6788 - val_precision: 0.9365\n",
      "Epoch 19/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3999 - accuracy: 0.8138 - recall: 0.6714 - precision: 0.9393 - val_loss: 0.3912 - val_accuracy: 0.8166 - val_recall: 0.6778 - val_precision: 0.9363\n",
      "Epoch 20/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3996 - accuracy: 0.8141 - recall: 0.6721 - precision: 0.9392 - val_loss: 0.3910 - val_accuracy: 0.8166 - val_recall: 0.6767 - val_precision: 0.9377\n",
      "Epoch 21/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3986 - accuracy: 0.8136 - recall: 0.6722 - precision: 0.9378 - val_loss: 0.3903 - val_accuracy: 0.8168 - val_recall: 0.6800 - val_precision: 0.9343\n",
      "Epoch 22/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3979 - accuracy: 0.8143 - recall: 0.6739 - precision: 0.9376 - val_loss: 0.3894 - val_accuracy: 0.8175 - val_recall: 0.6760 - val_precision: 0.9409\n",
      "Epoch 23/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3975 - accuracy: 0.8140 - recall: 0.6748 - precision: 0.9357 - val_loss: 0.3887 - val_accuracy: 0.8168 - val_recall: 0.6787 - val_precision: 0.9357\n",
      "Epoch 24/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3961 - accuracy: 0.8140 - recall: 0.6767 - precision: 0.9332 - val_loss: 0.3880 - val_accuracy: 0.8176 - val_recall: 0.6742 - val_precision: 0.9434\n",
      "Epoch 25/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3955 - accuracy: 0.8148 - recall: 0.6810 - precision: 0.9304 - val_loss: 0.3885 - val_accuracy: 0.8168 - val_recall: 0.6937 - val_precision: 0.9185\n",
      "Epoch 26/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3947 - accuracy: 0.8140 - recall: 0.6823 - precision: 0.9269 - val_loss: 0.3878 - val_accuracy: 0.8166 - val_recall: 0.6832 - val_precision: 0.9299\n",
      "Epoch 27/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3940 - accuracy: 0.8150 - recall: 0.6872 - precision: 0.9236 - val_loss: 0.3870 - val_accuracy: 0.8171 - val_recall: 0.6855 - val_precision: 0.9286\n",
      "Epoch 28/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3936 - accuracy: 0.8157 - recall: 0.6909 - precision: 0.9212 - val_loss: 0.3854 - val_accuracy: 0.8177 - val_recall: 0.6810 - val_precision: 0.9354\n",
      "Epoch 29/500\n",
      "2902/2902 [==============================] - 8s 3ms/step - loss: 0.3934 - accuracy: 0.8156 - recall: 0.6922 - precision: 0.9193 - val_loss: 0.3851 - val_accuracy: 0.8184 - val_recall: 0.6974 - val_precision: 0.9181\n",
      "Epoch 30/500\n",
      "2902/2902 [==============================] - 7s 2ms/step - loss: 0.3918 - accuracy: 0.8165 - recall: 0.6942 - precision: 0.9195 - val_loss: 0.3846 - val_accuracy: 0.8193 - val_recall: 0.7072 - val_precision: 0.9100\n",
      "Epoch 31/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3919 - accuracy: 0.8161 - recall: 0.6969 - precision: 0.9155 - val_loss: 0.3839 - val_accuracy: 0.8180 - val_recall: 0.6954 - val_precision: 0.9195\n",
      "Epoch 32/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3905 - accuracy: 0.8179 - recall: 0.7017 - precision: 0.9145 - val_loss: 0.3824 - val_accuracy: 0.8191 - val_recall: 0.6816 - val_precision: 0.9382\n",
      "Epoch 33/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3900 - accuracy: 0.8180 - recall: 0.7029 - precision: 0.9135 - val_loss: 0.3827 - val_accuracy: 0.8186 - val_recall: 0.6992 - val_precision: 0.9169\n",
      "Epoch 34/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3897 - accuracy: 0.8174 - recall: 0.7038 - precision: 0.9111 - val_loss: 0.3815 - val_accuracy: 0.8197 - val_recall: 0.7018 - val_precision: 0.9165\n",
      "Epoch 35/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3890 - accuracy: 0.8190 - recall: 0.7102 - precision: 0.9080 - val_loss: 0.3815 - val_accuracy: 0.8193 - val_recall: 0.6978 - val_precision: 0.9199\n",
      "Epoch 36/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3883 - accuracy: 0.8188 - recall: 0.7124 - precision: 0.9054 - val_loss: 0.3818 - val_accuracy: 0.8200 - val_recall: 0.7080 - val_precision: 0.9108\n",
      "Epoch 37/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3882 - accuracy: 0.8198 - recall: 0.7125 - precision: 0.9075 - val_loss: 0.3806 - val_accuracy: 0.8207 - val_recall: 0.6985 - val_precision: 0.9226\n",
      "Epoch 38/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3869 - accuracy: 0.8209 - recall: 0.7183 - precision: 0.9041 - val_loss: 0.3793 - val_accuracy: 0.8232 - val_recall: 0.7196 - val_precision: 0.9060\n",
      "Epoch 39/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3866 - accuracy: 0.8209 - recall: 0.7217 - precision: 0.9008 - val_loss: 0.3792 - val_accuracy: 0.8226 - val_recall: 0.7069 - val_precision: 0.9180\n",
      "Epoch 40/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3857 - accuracy: 0.8217 - recall: 0.7216 - precision: 0.9027 - val_loss: 0.3787 - val_accuracy: 0.8243 - val_recall: 0.7228 - val_precision: 0.9052\n",
      "Epoch 41/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3858 - accuracy: 0.8219 - recall: 0.7235 - precision: 0.9011 - val_loss: 0.3787 - val_accuracy: 0.8237 - val_recall: 0.7226 - val_precision: 0.9041\n",
      "Epoch 42/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3851 - accuracy: 0.8245 - recall: 0.7289 - precision: 0.9015 - val_loss: 0.3771 - val_accuracy: 0.8249 - val_recall: 0.7223 - val_precision: 0.9071\n",
      "Epoch 43/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3839 - accuracy: 0.8254 - recall: 0.7316 - precision: 0.9009 - val_loss: 0.3762 - val_accuracy: 0.8240 - val_recall: 0.7037 - val_precision: 0.9248\n",
      "Epoch 44/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3836 - accuracy: 0.8245 - recall: 0.7305 - precision: 0.9000 - val_loss: 0.3764 - val_accuracy: 0.8247 - val_recall: 0.7271 - val_precision: 0.9019\n",
      "Epoch 45/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3838 - accuracy: 0.8241 - recall: 0.7319 - precision: 0.8976 - val_loss: 0.3756 - val_accuracy: 0.8269 - val_recall: 0.7364 - val_precision: 0.8975\n",
      "Epoch 46/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3832 - accuracy: 0.8249 - recall: 0.7343 - precision: 0.8971 - val_loss: 0.3751 - val_accuracy: 0.8252 - val_recall: 0.7190 - val_precision: 0.9114\n",
      "Epoch 47/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3820 - accuracy: 0.8252 - recall: 0.7365 - precision: 0.8957 - val_loss: 0.3749 - val_accuracy: 0.8271 - val_recall: 0.7333 - val_precision: 0.9011\n",
      "Epoch 48/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3816 - accuracy: 0.8267 - recall: 0.7393 - precision: 0.8964 - val_loss: 0.3735 - val_accuracy: 0.8270 - val_recall: 0.7288 - val_precision: 0.9053\n",
      "Epoch 49/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3800 - accuracy: 0.8280 - recall: 0.7434 - precision: 0.8953 - val_loss: 0.3739 - val_accuracy: 0.8254 - val_recall: 0.7127 - val_precision: 0.9183\n",
      "Epoch 50/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3807 - accuracy: 0.8276 - recall: 0.7430 - precision: 0.8948 - val_loss: 0.3724 - val_accuracy: 0.8290 - val_recall: 0.7367 - val_precision: 0.9020\n",
      "Epoch 51/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3807 - accuracy: 0.8275 - recall: 0.7427 - precision: 0.8948 - val_loss: 0.3749 - val_accuracy: 0.8323 - val_recall: 0.7705 - val_precision: 0.8778\n",
      "Epoch 52/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3800 - accuracy: 0.8289 - recall: 0.7458 - precision: 0.8948 - val_loss: 0.3720 - val_accuracy: 0.8311 - val_recall: 0.7455 - val_precision: 0.8981\n",
      "Epoch 53/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3790 - accuracy: 0.8280 - recall: 0.7454 - precision: 0.8933 - val_loss: 0.3716 - val_accuracy: 0.8335 - val_recall: 0.7535 - val_precision: 0.8955\n",
      "Epoch 54/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3789 - accuracy: 0.8300 - recall: 0.7496 - precision: 0.8936 - val_loss: 0.3705 - val_accuracy: 0.8297 - val_recall: 0.7323 - val_precision: 0.9079\n",
      "Epoch 55/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3772 - accuracy: 0.8308 - recall: 0.7519 - precision: 0.8931 - val_loss: 0.3700 - val_accuracy: 0.8309 - val_recall: 0.7293 - val_precision: 0.9137\n",
      "Epoch 56/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3774 - accuracy: 0.8315 - recall: 0.7551 - precision: 0.8917 - val_loss: 0.3686 - val_accuracy: 0.8299 - val_recall: 0.7267 - val_precision: 0.9140\n",
      "Epoch 57/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3765 - accuracy: 0.8316 - recall: 0.7542 - precision: 0.8927 - val_loss: 0.3676 - val_accuracy: 0.8342 - val_recall: 0.7479 - val_precision: 0.9025\n",
      "Epoch 58/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3771 - accuracy: 0.8316 - recall: 0.7559 - precision: 0.8911 - val_loss: 0.3680 - val_accuracy: 0.8324 - val_recall: 0.7394 - val_precision: 0.9069\n",
      "Epoch 59/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3767 - accuracy: 0.8305 - recall: 0.7565 - precision: 0.8882 - val_loss: 0.3679 - val_accuracy: 0.8359 - val_recall: 0.7568 - val_precision: 0.8977\n",
      "Epoch 60/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3750 - accuracy: 0.8322 - recall: 0.7575 - precision: 0.8909 - val_loss: 0.3663 - val_accuracy: 0.8329 - val_recall: 0.7276 - val_precision: 0.9200\n",
      "Epoch 61/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8318 - recall: 0.7596 - precision: 0.8882 - val_loss: 0.3677 - val_accuracy: 0.8371 - val_recall: 0.7615 - val_precision: 0.8957\n",
      "Epoch 62/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3742 - accuracy: 0.8328 - recall: 0.7601 - precision: 0.8898 - val_loss: 0.3655 - val_accuracy: 0.8371 - val_recall: 0.7562 - val_precision: 0.9007\n",
      "Epoch 63/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3744 - accuracy: 0.8338 - recall: 0.7619 - precision: 0.8902 - val_loss: 0.3675 - val_accuracy: 0.8307 - val_recall: 0.7192 - val_precision: 0.9240\n",
      "Epoch 64/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3733 - accuracy: 0.8347 - recall: 0.7640 - precision: 0.8902 - val_loss: 0.3647 - val_accuracy: 0.8373 - val_recall: 0.7505 - val_precision: 0.9066\n",
      "Epoch 65/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3734 - accuracy: 0.8344 - recall: 0.7636 - precision: 0.8900 - val_loss: 0.3653 - val_accuracy: 0.8362 - val_recall: 0.7487 - val_precision: 0.9061\n",
      "Epoch 66/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3736 - accuracy: 0.8343 - recall: 0.7647 - precision: 0.8888 - val_loss: 0.3675 - val_accuracy: 0.8429 - val_recall: 0.7991 - val_precision: 0.8746\n",
      "Epoch 67/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3735 - accuracy: 0.8355 - recall: 0.7676 - precision: 0.8885 - val_loss: 0.3642 - val_accuracy: 0.8380 - val_recall: 0.7531 - val_precision: 0.9057\n",
      "Epoch 68/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3718 - accuracy: 0.8375 - recall: 0.7695 - precision: 0.8910 - val_loss: 0.3642 - val_accuracy: 0.8345 - val_recall: 0.7384 - val_precision: 0.9125\n",
      "Epoch 69/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3727 - accuracy: 0.8356 - recall: 0.7678 - precision: 0.8886 - val_loss: 0.3648 - val_accuracy: 0.8394 - val_recall: 0.7668 - val_precision: 0.8957\n",
      "Epoch 70/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3723 - accuracy: 0.8370 - recall: 0.7701 - precision: 0.8893 - val_loss: 0.3633 - val_accuracy: 0.8358 - val_recall: 0.7363 - val_precision: 0.9176\n",
      "Epoch 71/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3722 - accuracy: 0.8365 - recall: 0.7704 - precision: 0.8881 - val_loss: 0.3637 - val_accuracy: 0.8359 - val_recall: 0.7431 - val_precision: 0.9109\n",
      "Epoch 72/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3707 - accuracy: 0.8383 - recall: 0.7716 - precision: 0.8908 - val_loss: 0.3625 - val_accuracy: 0.8383 - val_recall: 0.7589 - val_precision: 0.9007\n",
      "Epoch 73/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3701 - accuracy: 0.8373 - recall: 0.7723 - precision: 0.8880 - val_loss: 0.3629 - val_accuracy: 0.8447 - val_recall: 0.7850 - val_precision: 0.8901\n",
      "Epoch 74/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3693 - accuracy: 0.8385 - recall: 0.7738 - precision: 0.8892 - val_loss: 0.3614 - val_accuracy: 0.8434 - val_recall: 0.7872 - val_precision: 0.8856\n",
      "Epoch 75/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3700 - accuracy: 0.8393 - recall: 0.7778 - precision: 0.8872 - val_loss: 0.3638 - val_accuracy: 0.8354 - val_recall: 0.7387 - val_precision: 0.9143\n",
      "Epoch 76/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3699 - accuracy: 0.8384 - recall: 0.7754 - precision: 0.8876 - val_loss: 0.3629 - val_accuracy: 0.8356 - val_recall: 0.7327 - val_precision: 0.9211\n",
      "Epoch 77/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3688 - accuracy: 0.8402 - recall: 0.7792 - precision: 0.8879 - val_loss: 0.3603 - val_accuracy: 0.8434 - val_recall: 0.7681 - val_precision: 0.9030\n",
      "Epoch 78/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3688 - accuracy: 0.8389 - recall: 0.7768 - precision: 0.8874 - val_loss: 0.3617 - val_accuracy: 0.8469 - val_recall: 0.7933 - val_precision: 0.8873\n",
      "Epoch 79/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3687 - accuracy: 0.8394 - recall: 0.7794 - precision: 0.8860 - val_loss: 0.3609 - val_accuracy: 0.8454 - val_recall: 0.7886 - val_precision: 0.8884\n",
      "Epoch 80/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3682 - accuracy: 0.8389 - recall: 0.7766 - precision: 0.8874 - val_loss: 0.3607 - val_accuracy: 0.8413 - val_recall: 0.7605 - val_precision: 0.9057\n",
      "Epoch 81/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3682 - accuracy: 0.8399 - recall: 0.7780 - precision: 0.8883 - val_loss: 0.3588 - val_accuracy: 0.8443 - val_recall: 0.7779 - val_precision: 0.8957\n",
      "Epoch 82/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3675 - accuracy: 0.8402 - recall: 0.7802 - precision: 0.8870 - val_loss: 0.3608 - val_accuracy: 0.8402 - val_recall: 0.7616 - val_precision: 0.9023\n",
      "Epoch 83/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3668 - accuracy: 0.8414 - recall: 0.7814 - precision: 0.8882 - val_loss: 0.3608 - val_accuracy: 0.8404 - val_recall: 0.7585 - val_precision: 0.9058\n",
      "Epoch 84/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3681 - accuracy: 0.8406 - recall: 0.7818 - precision: 0.8863 - val_loss: 0.3601 - val_accuracy: 0.8474 - val_recall: 0.8072 - val_precision: 0.8766\n",
      "Epoch 85/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3664 - accuracy: 0.8419 - recall: 0.7837 - precision: 0.8873 - val_loss: 0.3582 - val_accuracy: 0.8443 - val_recall: 0.7668 - val_precision: 0.9062\n",
      "Epoch 86/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3658 - accuracy: 0.8413 - recall: 0.7847 - precision: 0.8853 - val_loss: 0.3563 - val_accuracy: 0.8467 - val_recall: 0.7717 - val_precision: 0.9065\n",
      "Epoch 87/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3651 - accuracy: 0.8423 - recall: 0.7846 - precision: 0.8872 - val_loss: 0.3582 - val_accuracy: 0.8484 - val_recall: 0.8081 - val_precision: 0.8778\n",
      "Epoch 88/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3652 - accuracy: 0.8418 - recall: 0.7845 - precision: 0.8864 - val_loss: 0.3562 - val_accuracy: 0.8473 - val_recall: 0.7832 - val_precision: 0.8971\n",
      "Epoch 89/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3653 - accuracy: 0.8422 - recall: 0.7870 - precision: 0.8850 - val_loss: 0.3559 - val_accuracy: 0.8472 - val_recall: 0.7809 - val_precision: 0.8989\n",
      "Epoch 90/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3649 - accuracy: 0.8432 - recall: 0.7860 - precision: 0.8879 - val_loss: 0.3563 - val_accuracy: 0.8509 - val_recall: 0.8063 - val_precision: 0.8840\n",
      "Epoch 91/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3642 - accuracy: 0.8440 - recall: 0.7877 - precision: 0.8881 - val_loss: 0.3547 - val_accuracy: 0.8481 - val_recall: 0.7768 - val_precision: 0.9047\n",
      "Epoch 92/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3638 - accuracy: 0.8432 - recall: 0.7881 - precision: 0.8861 - val_loss: 0.3559 - val_accuracy: 0.8499 - val_recall: 0.7903 - val_precision: 0.8960\n",
      "Epoch 93/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3655 - accuracy: 0.8410 - recall: 0.7847 - precision: 0.8846 - val_loss: 0.3565 - val_accuracy: 0.8455 - val_recall: 0.7701 - val_precision: 0.9055\n",
      "Epoch 94/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3635 - accuracy: 0.8433 - recall: 0.7890 - precision: 0.8854 - val_loss: 0.3549 - val_accuracy: 0.8508 - val_recall: 0.7927 - val_precision: 0.8958\n",
      "Epoch 95/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3631 - accuracy: 0.8435 - recall: 0.7892 - precision: 0.8855 - val_loss: 0.3547 - val_accuracy: 0.8488 - val_recall: 0.7876 - val_precision: 0.8962\n",
      "Epoch 96/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3630 - accuracy: 0.8442 - recall: 0.7900 - precision: 0.8864 - val_loss: 0.3544 - val_accuracy: 0.8460 - val_recall: 0.7637 - val_precision: 0.9127\n",
      "Epoch 97/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3631 - accuracy: 0.8441 - recall: 0.7912 - precision: 0.8850 - val_loss: 0.3535 - val_accuracy: 0.8508 - val_recall: 0.7893 - val_precision: 0.8988\n",
      "Epoch 98/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3629 - accuracy: 0.8438 - recall: 0.7903 - precision: 0.8853 - val_loss: 0.3549 - val_accuracy: 0.8448 - val_recall: 0.7575 - val_precision: 0.9164\n",
      "Epoch 99/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3630 - accuracy: 0.8432 - recall: 0.7898 - precision: 0.8846 - val_loss: 0.3544 - val_accuracy: 0.8507 - val_recall: 0.8004 - val_precision: 0.8888\n",
      "Epoch 100/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3622 - accuracy: 0.8451 - recall: 0.7910 - precision: 0.8873 - val_loss: 0.3552 - val_accuracy: 0.8432 - val_recall: 0.7479 - val_precision: 0.9227\n",
      "Epoch 101/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3615 - accuracy: 0.8442 - recall: 0.7911 - precision: 0.8854 - val_loss: 0.3527 - val_accuracy: 0.8495 - val_recall: 0.7830 - val_precision: 0.9019\n",
      "Epoch 102/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3610 - accuracy: 0.8447 - recall: 0.7925 - precision: 0.8852 - val_loss: 0.3529 - val_accuracy: 0.8497 - val_recall: 0.7894 - val_precision: 0.8964\n",
      "Epoch 103/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3615 - accuracy: 0.8453 - recall: 0.7926 - precision: 0.8863 - val_loss: 0.3528 - val_accuracy: 0.8476 - val_recall: 0.7853 - val_precision: 0.8958\n",
      "Epoch 104/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3606 - accuracy: 0.8463 - recall: 0.7949 - precision: 0.8863 - val_loss: 0.3518 - val_accuracy: 0.8493 - val_recall: 0.7712 - val_precision: 0.9127\n",
      "Epoch 105/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3611 - accuracy: 0.8454 - recall: 0.7928 - precision: 0.8863 - val_loss: 0.3526 - val_accuracy: 0.8510 - val_recall: 0.7941 - val_precision: 0.8948\n",
      "Epoch 106/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3610 - accuracy: 0.8465 - recall: 0.7947 - precision: 0.8870 - val_loss: 0.3504 - val_accuracy: 0.8525 - val_recall: 0.7879 - val_precision: 0.9035\n",
      "Epoch 107/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3593 - accuracy: 0.8466 - recall: 0.7955 - precision: 0.8863 - val_loss: 0.3501 - val_accuracy: 0.8513 - val_recall: 0.7926 - val_precision: 0.8969\n",
      "Epoch 108/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3596 - accuracy: 0.8469 - recall: 0.7959 - precision: 0.8865 - val_loss: 0.3494 - val_accuracy: 0.8537 - val_recall: 0.7991 - val_precision: 0.8958\n",
      "Epoch 109/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3599 - accuracy: 0.8455 - recall: 0.7940 - precision: 0.8854 - val_loss: 0.3503 - val_accuracy: 0.8541 - val_recall: 0.8122 - val_precision: 0.8853\n",
      "Epoch 110/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3602 - accuracy: 0.8470 - recall: 0.7968 - precision: 0.8861 - val_loss: 0.3502 - val_accuracy: 0.8519 - val_recall: 0.7860 - val_precision: 0.9041\n",
      "Epoch 111/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3580 - accuracy: 0.8482 - recall: 0.7996 - precision: 0.8860 - val_loss: 0.3495 - val_accuracy: 0.8543 - val_recall: 0.7996 - val_precision: 0.8967\n",
      "Epoch 112/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3591 - accuracy: 0.8467 - recall: 0.7978 - precision: 0.8847 - val_loss: 0.3498 - val_accuracy: 0.8484 - val_recall: 0.7720 - val_precision: 0.9099\n",
      "Epoch 113/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3590 - accuracy: 0.8480 - recall: 0.7980 - precision: 0.8871 - val_loss: 0.3490 - val_accuracy: 0.8520 - val_recall: 0.7859 - val_precision: 0.9044\n",
      "Epoch 114/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3581 - accuracy: 0.8471 - recall: 0.7976 - precision: 0.8855 - val_loss: 0.3494 - val_accuracy: 0.8517 - val_recall: 0.7850 - val_precision: 0.9046\n",
      "Epoch 115/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3587 - accuracy: 0.8469 - recall: 0.7980 - precision: 0.8847 - val_loss: 0.3483 - val_accuracy: 0.8499 - val_recall: 0.7677 - val_precision: 0.9174\n",
      "Epoch 116/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3574 - accuracy: 0.8486 - recall: 0.8006 - precision: 0.8860 - val_loss: 0.3475 - val_accuracy: 0.8523 - val_recall: 0.7860 - val_precision: 0.9049\n",
      "Epoch 117/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3585 - accuracy: 0.8489 - recall: 0.7995 - precision: 0.8874 - val_loss: 0.3479 - val_accuracy: 0.8524 - val_recall: 0.7784 - val_precision: 0.9124\n",
      "Epoch 118/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3576 - accuracy: 0.8489 - recall: 0.8005 - precision: 0.8867 - val_loss: 0.3493 - val_accuracy: 0.8549 - val_recall: 0.8022 - val_precision: 0.8956\n",
      "Epoch 119/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3557 - accuracy: 0.8496 - recall: 0.8026 - precision: 0.8862 - val_loss: 0.3467 - val_accuracy: 0.8571 - val_recall: 0.8105 - val_precision: 0.8926\n",
      "Epoch 120/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3564 - accuracy: 0.8504 - recall: 0.8036 - precision: 0.8869 - val_loss: 0.3469 - val_accuracy: 0.8557 - val_recall: 0.8011 - val_precision: 0.8982\n",
      "Epoch 121/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3566 - accuracy: 0.8500 - recall: 0.8028 - precision: 0.8868 - val_loss: 0.3469 - val_accuracy: 0.8538 - val_recall: 0.7869 - val_precision: 0.9073\n",
      "Epoch 122/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3548 - accuracy: 0.8500 - recall: 0.8034 - precision: 0.8863 - val_loss: 0.3455 - val_accuracy: 0.8547 - val_recall: 0.7875 - val_precision: 0.9085\n",
      "Epoch 123/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3562 - accuracy: 0.8491 - recall: 0.8024 - precision: 0.8853 - val_loss: 0.3463 - val_accuracy: 0.8582 - val_recall: 0.8275 - val_precision: 0.8805\n",
      "Epoch 124/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3552 - accuracy: 0.8497 - recall: 0.8038 - precision: 0.8854 - val_loss: 0.3462 - val_accuracy: 0.8520 - val_recall: 0.7774 - val_precision: 0.9126\n",
      "Epoch 125/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3568 - accuracy: 0.8490 - recall: 0.8037 - precision: 0.8840 - val_loss: 0.3455 - val_accuracy: 0.8545 - val_recall: 0.7854 - val_precision: 0.9102\n",
      "Epoch 126/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3560 - accuracy: 0.8498 - recall: 0.8036 - precision: 0.8857 - val_loss: 0.3457 - val_accuracy: 0.8513 - val_recall: 0.7722 - val_precision: 0.9162\n",
      "Epoch 127/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3559 - accuracy: 0.8495 - recall: 0.8037 - precision: 0.8850 - val_loss: 0.3460 - val_accuracy: 0.8574 - val_recall: 0.8227 - val_precision: 0.8829\n",
      "Epoch 128/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3550 - accuracy: 0.8501 - recall: 0.8046 - precision: 0.8854 - val_loss: 0.3444 - val_accuracy: 0.8534 - val_recall: 0.7877 - val_precision: 0.9056\n",
      "Epoch 129/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3544 - accuracy: 0.8510 - recall: 0.8061 - precision: 0.8858 - val_loss: 0.3435 - val_accuracy: 0.8588 - val_recall: 0.8195 - val_precision: 0.8883\n",
      "Epoch 130/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3546 - accuracy: 0.8509 - recall: 0.8057 - precision: 0.8861 - val_loss: 0.3449 - val_accuracy: 0.8581 - val_recall: 0.8194 - val_precision: 0.8870\n",
      "Epoch 131/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3534 - accuracy: 0.8519 - recall: 0.8072 - precision: 0.8868 - val_loss: 0.3427 - val_accuracy: 0.8572 - val_recall: 0.8026 - val_precision: 0.8997\n",
      "Epoch 132/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3530 - accuracy: 0.8517 - recall: 0.8069 - precision: 0.8865 - val_loss: 0.3441 - val_accuracy: 0.8606 - val_recall: 0.8320 - val_precision: 0.8814\n",
      "Epoch 133/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3551 - accuracy: 0.8510 - recall: 0.8059 - precision: 0.8862 - val_loss: 0.3448 - val_accuracy: 0.8605 - val_recall: 0.8234 - val_precision: 0.8883\n",
      "Epoch 134/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3529 - accuracy: 0.8525 - recall: 0.8093 - precision: 0.8861 - val_loss: 0.3436 - val_accuracy: 0.8560 - val_recall: 0.7988 - val_precision: 0.9008\n",
      "Epoch 135/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3527 - accuracy: 0.8517 - recall: 0.8092 - precision: 0.8847 - val_loss: 0.3431 - val_accuracy: 0.8563 - val_recall: 0.8051 - val_precision: 0.8959\n",
      "Epoch 136/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3522 - accuracy: 0.8530 - recall: 0.8106 - precision: 0.8860 - val_loss: 0.3422 - val_accuracy: 0.8564 - val_recall: 0.7970 - val_precision: 0.9032\n",
      "Epoch 137/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3525 - accuracy: 0.8534 - recall: 0.8118 - precision: 0.8857 - val_loss: 0.3433 - val_accuracy: 0.8616 - val_recall: 0.8415 - val_precision: 0.8757\n",
      "Epoch 138/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3531 - accuracy: 0.8524 - recall: 0.8109 - precision: 0.8846 - val_loss: 0.3417 - val_accuracy: 0.8600 - val_recall: 0.8120 - val_precision: 0.8972\n",
      "Epoch 139/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3525 - accuracy: 0.8529 - recall: 0.8115 - precision: 0.8850 - val_loss: 0.3425 - val_accuracy: 0.8597 - val_recall: 0.8166 - val_precision: 0.8925\n",
      "Epoch 140/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3524 - accuracy: 0.8528 - recall: 0.8085 - precision: 0.8873 - val_loss: 0.3411 - val_accuracy: 0.8598 - val_recall: 0.8060 - val_precision: 0.9020\n",
      "Epoch 141/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3517 - accuracy: 0.8540 - recall: 0.8134 - precision: 0.8855 - val_loss: 0.3415 - val_accuracy: 0.8557 - val_recall: 0.7876 - val_precision: 0.9105\n",
      "Epoch 142/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3517 - accuracy: 0.8532 - recall: 0.8114 - precision: 0.8856 - val_loss: 0.3416 - val_accuracy: 0.8576 - val_recall: 0.8058 - val_precision: 0.8978\n",
      "Epoch 143/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3510 - accuracy: 0.8528 - recall: 0.8128 - precision: 0.8837 - val_loss: 0.3421 - val_accuracy: 0.8605 - val_recall: 0.8252 - val_precision: 0.8868\n",
      "Epoch 144/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3508 - accuracy: 0.8537 - recall: 0.8119 - precision: 0.8863 - val_loss: 0.3395 - val_accuracy: 0.8591 - val_recall: 0.8075 - val_precision: 0.8992\n",
      "Epoch 145/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3516 - accuracy: 0.8532 - recall: 0.8114 - precision: 0.8858 - val_loss: 0.3421 - val_accuracy: 0.8566 - val_recall: 0.7914 - val_precision: 0.9088\n",
      "Epoch 146/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3508 - accuracy: 0.8531 - recall: 0.8121 - precision: 0.8849 - val_loss: 0.3415 - val_accuracy: 0.8575 - val_recall: 0.8008 - val_precision: 0.9020\n",
      "Epoch 147/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3496 - accuracy: 0.8551 - recall: 0.8141 - precision: 0.8871 - val_loss: 0.3405 - val_accuracy: 0.8605 - val_recall: 0.8131 - val_precision: 0.8972\n",
      "Epoch 148/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3519 - accuracy: 0.8530 - recall: 0.8120 - precision: 0.8849 - val_loss: 0.3422 - val_accuracy: 0.8591 - val_recall: 0.8162 - val_precision: 0.8917\n",
      "Epoch 149/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3519 - accuracy: 0.8521 - recall: 0.8108 - precision: 0.8841 - val_loss: 0.3389 - val_accuracy: 0.8610 - val_recall: 0.8062 - val_precision: 0.9044\n",
      "Epoch 150/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3498 - accuracy: 0.8531 - recall: 0.8129 - precision: 0.8843 - val_loss: 0.3397 - val_accuracy: 0.8578 - val_recall: 0.8043 - val_precision: 0.8995\n",
      "Epoch 151/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3495 - accuracy: 0.8540 - recall: 0.8145 - precision: 0.8846 - val_loss: 0.3406 - val_accuracy: 0.8609 - val_recall: 0.8161 - val_precision: 0.8953\n",
      "Epoch 152/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3502 - accuracy: 0.8534 - recall: 0.8129 - precision: 0.8849 - val_loss: 0.3405 - val_accuracy: 0.8583 - val_recall: 0.7957 - val_precision: 0.9084\n",
      "Epoch 153/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3499 - accuracy: 0.8535 - recall: 0.8137 - precision: 0.8844 - val_loss: 0.3382 - val_accuracy: 0.8588 - val_recall: 0.8003 - val_precision: 0.9053\n",
      "Epoch 154/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3499 - accuracy: 0.8557 - recall: 0.8164 - precision: 0.8864 - val_loss: 0.3387 - val_accuracy: 0.8568 - val_recall: 0.7935 - val_precision: 0.9072\n",
      "Epoch 155/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3506 - accuracy: 0.8547 - recall: 0.8148 - precision: 0.8857 - val_loss: 0.3382 - val_accuracy: 0.8638 - val_recall: 0.8318 - val_precision: 0.8877\n",
      "Epoch 156/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3504 - accuracy: 0.8545 - recall: 0.8158 - precision: 0.8846 - val_loss: 0.3381 - val_accuracy: 0.8604 - val_recall: 0.8151 - val_precision: 0.8953\n",
      "Epoch 157/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3479 - accuracy: 0.8561 - recall: 0.8166 - precision: 0.8869 - val_loss: 0.3383 - val_accuracy: 0.8609 - val_recall: 0.8124 - val_precision: 0.8985\n",
      "Epoch 158/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3502 - accuracy: 0.8535 - recall: 0.8144 - precision: 0.8837 - val_loss: 0.3377 - val_accuracy: 0.8596 - val_recall: 0.8031 - val_precision: 0.9042\n",
      "Epoch 159/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3487 - accuracy: 0.8555 - recall: 0.8175 - precision: 0.8850 - val_loss: 0.3379 - val_accuracy: 0.8572 - val_recall: 0.7954 - val_precision: 0.9063\n",
      "Epoch 160/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3489 - accuracy: 0.8551 - recall: 0.8173 - precision: 0.8844 - val_loss: 0.3386 - val_accuracy: 0.8594 - val_recall: 0.8094 - val_precision: 0.8983\n",
      "Epoch 161/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3489 - accuracy: 0.8545 - recall: 0.8151 - precision: 0.8851 - val_loss: 0.3369 - val_accuracy: 0.8599 - val_recall: 0.8065 - val_precision: 0.9017\n",
      "Epoch 162/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3477 - accuracy: 0.8552 - recall: 0.8169 - precision: 0.8850 - val_loss: 0.3375 - val_accuracy: 0.8594 - val_recall: 0.8011 - val_precision: 0.9056\n",
      "Epoch 163/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3484 - accuracy: 0.8557 - recall: 0.8187 - precision: 0.8844 - val_loss: 0.3378 - val_accuracy: 0.8614 - val_recall: 0.8226 - val_precision: 0.8908\n",
      "Epoch 164/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3484 - accuracy: 0.8559 - recall: 0.8176 - precision: 0.8858 - val_loss: 0.3361 - val_accuracy: 0.8634 - val_recall: 0.8141 - val_precision: 0.9020\n",
      "Epoch 165/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3473 - accuracy: 0.8560 - recall: 0.8173 - precision: 0.8862 - val_loss: 0.3367 - val_accuracy: 0.8603 - val_recall: 0.8011 - val_precision: 0.9076\n",
      "Epoch 166/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3474 - accuracy: 0.8565 - recall: 0.8192 - precision: 0.8856 - val_loss: 0.3352 - val_accuracy: 0.8631 - val_recall: 0.8071 - val_precision: 0.9079\n",
      "Epoch 167/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3477 - accuracy: 0.8558 - recall: 0.8201 - precision: 0.8835 - val_loss: 0.3386 - val_accuracy: 0.8593 - val_recall: 0.8054 - val_precision: 0.9016\n",
      "Epoch 168/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3477 - accuracy: 0.8566 - recall: 0.8201 - precision: 0.8850 - val_loss: 0.3349 - val_accuracy: 0.8634 - val_recall: 0.8153 - val_precision: 0.9010\n",
      "Epoch 169/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3479 - accuracy: 0.8560 - recall: 0.8191 - precision: 0.8846 - val_loss: 0.3380 - val_accuracy: 0.8616 - val_recall: 0.8181 - val_precision: 0.8949\n",
      "Epoch 170/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3483 - accuracy: 0.8567 - recall: 0.8179 - precision: 0.8870 - val_loss: 0.3382 - val_accuracy: 0.8589 - val_recall: 0.7941 - val_precision: 0.9112\n",
      "Epoch 171/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3463 - accuracy: 0.8578 - recall: 0.8208 - precision: 0.8866 - val_loss: 0.3360 - val_accuracy: 0.8616 - val_recall: 0.8123 - val_precision: 0.9000\n",
      "Epoch 172/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3465 - accuracy: 0.8557 - recall: 0.8188 - precision: 0.8844 - val_loss: 0.3368 - val_accuracy: 0.8641 - val_recall: 0.8500 - val_precision: 0.8736\n",
      "Epoch 173/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3471 - accuracy: 0.8571 - recall: 0.8216 - precision: 0.8847 - val_loss: 0.3358 - val_accuracy: 0.8631 - val_recall: 0.8183 - val_precision: 0.8979\n",
      "Epoch 174/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3467 - accuracy: 0.8576 - recall: 0.8204 - precision: 0.8866 - val_loss: 0.3350 - val_accuracy: 0.8616 - val_recall: 0.8003 - val_precision: 0.9110\n",
      "Epoch 175/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3455 - accuracy: 0.8580 - recall: 0.8220 - precision: 0.8861 - val_loss: 0.3333 - val_accuracy: 0.8621 - val_recall: 0.8107 - val_precision: 0.9025\n",
      "Epoch 176/500\n",
      "2902/2902 [==============================] - 7s 3ms/step - loss: 0.3457 - accuracy: 0.8566 - recall: 0.8207 - precision: 0.8845 - val_loss: 0.3338 - val_accuracy: 0.8661 - val_recall: 0.8346 - val_precision: 0.8897\n",
      "Epoch 177/500\n",
      "2902/2902 [==============================] - 32s 11ms/step - loss: 0.3468 - accuracy: 0.8563 - recall: 0.8188 - precision: 0.8854 - val_loss: 0.3325 - val_accuracy: 0.8645 - val_recall: 0.8165 - val_precision: 0.9021\n",
      "Epoch 178/500\n",
      "2902/2902 [==============================] - 54s 19ms/step - loss: 0.3465 - accuracy: 0.8572 - recall: 0.8198 - precision: 0.8863 - val_loss: 0.3359 - val_accuracy: 0.8630 - val_recall: 0.8295 - val_precision: 0.8880\n",
      "Epoch 179/500\n",
      "2902/2902 [==============================] - 50s 17ms/step - loss: 0.3464 - accuracy: 0.8578 - recall: 0.8208 - precision: 0.8866 - val_loss: 0.3353 - val_accuracy: 0.8587 - val_recall: 0.7876 - val_precision: 0.9168\n",
      "Epoch 180/500\n",
      "2902/2902 [==============================] - 38s 13ms/step - loss: 0.3448 - accuracy: 0.8584 - recall: 0.8224 - precision: 0.8866 - val_loss: 0.3342 - val_accuracy: 0.8663 - val_recall: 0.8549 - val_precision: 0.8738\n",
      "Epoch 181/500\n",
      "2902/2902 [==============================] - 23s 8ms/step - loss: 0.3450 - accuracy: 0.8580 - recall: 0.8219 - precision: 0.8862 - val_loss: 0.3343 - val_accuracy: 0.8594 - val_recall: 0.7966 - val_precision: 0.9098\n",
      "Epoch 182/500\n",
      "2902/2902 [==============================] - 23s 8ms/step - loss: 0.3448 - accuracy: 0.8578 - recall: 0.8229 - precision: 0.8850 - val_loss: 0.3329 - val_accuracy: 0.8660 - val_recall: 0.8323 - val_precision: 0.8914\n",
      "Epoch 183/500\n",
      "2902/2902 [==============================] - 20s 7ms/step - loss: 0.3451 - accuracy: 0.8584 - recall: 0.8231 - precision: 0.8859 - val_loss: 0.3332 - val_accuracy: 0.8625 - val_recall: 0.8075 - val_precision: 0.9063\n",
      "Epoch 184/500\n",
      "2902/2902 [==============================] - 14s 5ms/step - loss: 0.3439 - accuracy: 0.8594 - recall: 0.8239 - precision: 0.8871 - val_loss: 0.3323 - val_accuracy: 0.8615 - val_recall: 0.8036 - val_precision: 0.9078\n",
      "Epoch 185/500\n",
      "2902/2902 [==============================] - 11s 4ms/step - loss: 0.3440 - accuracy: 0.8601 - recall: 0.8248 - precision: 0.8876 - val_loss: 0.3345 - val_accuracy: 0.8632 - val_recall: 0.8350 - val_precision: 0.8839\n",
      "Epoch 186/500\n",
      "2902/2902 [==============================] - 11s 4ms/step - loss: 0.3451 - accuracy: 0.8587 - recall: 0.8230 - precision: 0.8865 - val_loss: 0.3327 - val_accuracy: 0.8644 - val_recall: 0.8113 - val_precision: 0.9065\n",
      "Epoch 187/500\n",
      "2902/2902 [==============================] - 11s 4ms/step - loss: 0.3435 - accuracy: 0.8591 - recall: 0.8239 - precision: 0.8865 - val_loss: 0.3329 - val_accuracy: 0.8628 - val_recall: 0.8066 - val_precision: 0.9077\n",
      "Epoch 188/500\n",
      "2902/2902 [==============================] - 10s 4ms/step - loss: 0.3433 - accuracy: 0.8597 - recall: 0.8247 - precision: 0.8870 - val_loss: 0.3366 - val_accuracy: 0.8574 - val_recall: 0.7811 - val_precision: 0.9206\n",
      "Epoch 189/500\n",
      "2902/2902 [==============================] - 13s 5ms/step - loss: 0.3450 - accuracy: 0.8582 - recall: 0.8235 - precision: 0.8853 - val_loss: 0.3335 - val_accuracy: 0.8629 - val_recall: 0.8079 - val_precision: 0.9067\n",
      "Epoch 190/500\n",
      "2902/2902 [==============================] - 46s 16ms/step - loss: 0.3436 - accuracy: 0.8583 - recall: 0.8223 - precision: 0.8863 - val_loss: 0.3325 - val_accuracy: 0.8647 - val_recall: 0.8273 - val_precision: 0.8931\n",
      "Epoch 191/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3442 - accuracy: 0.8584 - recall: 0.8226 - precision: 0.8864 - val_loss: 0.3326 - val_accuracy: 0.8668 - val_recall: 0.8369 - val_precision: 0.8891\n",
      "Epoch 192/500\n",
      "2902/2902 [==============================] - 20s 7ms/step - loss: 0.3435 - accuracy: 0.8602 - recall: 0.8252 - precision: 0.8876 - val_loss: 0.3319 - val_accuracy: 0.8662 - val_recall: 0.8361 - val_precision: 0.8886\n",
      "Epoch 193/500\n",
      "2902/2902 [==============================] - 51s 18ms/step - loss: 0.3436 - accuracy: 0.8589 - recall: 0.8252 - precision: 0.8850 - val_loss: 0.3325 - val_accuracy: 0.8639 - val_recall: 0.8008 - val_precision: 0.9153\n",
      "Epoch 194/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3436 - accuracy: 0.8591 - recall: 0.8242 - precision: 0.8864 - val_loss: 0.3327 - val_accuracy: 0.8620 - val_recall: 0.8021 - val_precision: 0.9102\n",
      "Epoch 195/500\n",
      "2902/2902 [==============================] - 18s 6ms/step - loss: 0.3429 - accuracy: 0.8596 - recall: 0.8262 - precision: 0.8856 - val_loss: 0.3315 - val_accuracy: 0.8677 - val_recall: 0.8414 - val_precision: 0.8872\n",
      "Epoch 196/500\n",
      "2902/2902 [==============================] - 36s 13ms/step - loss: 0.3439 - accuracy: 0.8598 - recall: 0.8262 - precision: 0.8859 - val_loss: 0.3308 - val_accuracy: 0.8620 - val_recall: 0.7995 - val_precision: 0.9126\n",
      "Epoch 197/500\n",
      "2902/2902 [==============================] - 54s 19ms/step - loss: 0.3427 - accuracy: 0.8596 - recall: 0.8251 - precision: 0.8865 - val_loss: 0.3322 - val_accuracy: 0.8630 - val_recall: 0.8068 - val_precision: 0.9078\n",
      "Epoch 198/500\n",
      "2902/2902 [==============================] - 20s 7ms/step - loss: 0.3435 - accuracy: 0.8595 - recall: 0.8255 - precision: 0.8860 - val_loss: 0.3309 - val_accuracy: 0.8629 - val_recall: 0.8004 - val_precision: 0.9135\n",
      "Epoch 199/500\n",
      "2902/2902 [==============================] - 19s 7ms/step - loss: 0.3416 - accuracy: 0.8609 - recall: 0.8282 - precision: 0.8865 - val_loss: 0.3310 - val_accuracy: 0.8632 - val_recall: 0.8099 - val_precision: 0.9055\n",
      "Epoch 200/500\n",
      "2902/2902 [==============================] - 19s 7ms/step - loss: 0.3417 - accuracy: 0.8598 - recall: 0.8269 - precision: 0.8853 - val_loss: 0.3309 - val_accuracy: 0.8687 - val_recall: 0.8434 - val_precision: 0.8873\n",
      "Epoch 201/500\n",
      "2902/2902 [==============================] - 12s 4ms/step - loss: 0.3425 - accuracy: 0.8598 - recall: 0.8268 - precision: 0.8854 - val_loss: 0.3329 - val_accuracy: 0.8627 - val_recall: 0.8043 - val_precision: 0.9095\n",
      "Epoch 202/500\n",
      "2902/2902 [==============================] - 12s 4ms/step - loss: 0.3414 - accuracy: 0.8610 - recall: 0.8284 - precision: 0.8865 - val_loss: 0.3296 - val_accuracy: 0.8657 - val_recall: 0.8204 - val_precision: 0.9011\n",
      "Epoch 203/500\n",
      "2902/2902 [==============================] - 11s 4ms/step - loss: 0.3422 - accuracy: 0.8598 - recall: 0.8267 - precision: 0.8855 - val_loss: 0.3307 - val_accuracy: 0.8637 - val_recall: 0.7988 - val_precision: 0.9168\n",
      "Epoch 204/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3416 - accuracy: 0.8599 - recall: 0.8264 - precision: 0.8860 - val_loss: 0.3301 - val_accuracy: 0.8672 - val_recall: 0.8239 - val_precision: 0.9010\n",
      "Epoch 205/500\n",
      "2902/2902 [==============================] - 43s 15ms/step - loss: 0.3409 - accuracy: 0.8622 - recall: 0.8300 - precision: 0.8874 - val_loss: 0.3294 - val_accuracy: 0.8683 - val_recall: 0.8427 - val_precision: 0.8872\n",
      "Epoch 206/500\n",
      "2902/2902 [==============================] - 18s 6ms/step - loss: 0.3425 - accuracy: 0.8608 - recall: 0.8279 - precision: 0.8865 - val_loss: 0.3295 - val_accuracy: 0.8669 - val_recall: 0.8242 - val_precision: 0.9001\n",
      "Epoch 207/500\n",
      "2902/2902 [==============================] - 20s 7ms/step - loss: 0.3403 - accuracy: 0.8624 - recall: 0.8294 - precision: 0.8882 - val_loss: 0.3296 - val_accuracy: 0.8669 - val_recall: 0.8325 - val_precision: 0.8931\n",
      "Epoch 208/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3418 - accuracy: 0.8601 - recall: 0.8278 - precision: 0.8853 - val_loss: 0.3284 - val_accuracy: 0.8659 - val_recall: 0.8132 - val_precision: 0.9079\n",
      "Epoch 209/500\n",
      "2902/2902 [==============================] - 15s 5ms/step - loss: 0.3407 - accuracy: 0.8607 - recall: 0.8273 - precision: 0.8868 - val_loss: 0.3291 - val_accuracy: 0.8712 - val_recall: 0.8395 - val_precision: 0.8954\n",
      "Epoch 210/500\n",
      "2902/2902 [==============================] - 16s 6ms/step - loss: 0.3414 - accuracy: 0.8627 - recall: 0.8304 - precision: 0.8881 - val_loss: 0.3283 - val_accuracy: 0.8689 - val_recall: 0.8240 - val_precision: 0.9042\n",
      "Epoch 211/500\n",
      "2902/2902 [==============================] - 15s 5ms/step - loss: 0.3401 - accuracy: 0.8609 - recall: 0.8292 - precision: 0.8855 - val_loss: 0.3288 - val_accuracy: 0.8700 - val_recall: 0.8459 - val_precision: 0.8878\n",
      "Epoch 212/500\n",
      "2902/2902 [==============================] - 17s 6ms/step - loss: 0.3399 - accuracy: 0.8621 - recall: 0.8308 - precision: 0.8865 - val_loss: 0.3266 - val_accuracy: 0.8669 - val_recall: 0.8171 - val_precision: 0.9065\n",
      "Epoch 213/500\n",
      "2902/2902 [==============================] - 8s 3ms/step - loss: 0.3404 - accuracy: 0.8620 - recall: 0.8301 - precision: 0.8870 - val_loss: 0.3287 - val_accuracy: 0.8683 - val_recall: 0.8220 - val_precision: 0.9048\n",
      "Epoch 214/500\n",
      "2902/2902 [==============================] - 9s 3ms/step - loss: 0.3412 - accuracy: 0.8612 - recall: 0.8289 - precision: 0.8864 - val_loss: 0.3294 - val_accuracy: 0.8707 - val_recall: 0.8549 - val_precision: 0.8818\n",
      "Epoch 215/500\n",
      "2902/2902 [==============================] - 11s 4ms/step - loss: 0.3399 - accuracy: 0.8624 - recall: 0.8319 - precision: 0.8861 - val_loss: 0.3302 - val_accuracy: 0.8697 - val_recall: 0.8394 - val_precision: 0.8927\n",
      "Epoch 216/500\n",
      "2902/2902 [==============================] - 10s 4ms/step - loss: 0.3402 - accuracy: 0.8613 - recall: 0.8304 - precision: 0.8853 - val_loss: 0.3266 - val_accuracy: 0.8700 - val_recall: 0.8376 - val_precision: 0.8946\n",
      "Epoch 217/500\n",
      "2902/2902 [==============================] - 9s 3ms/step - loss: 0.3395 - accuracy: 0.8616 - recall: 0.8320 - precision: 0.8846 - val_loss: 0.3300 - val_accuracy: 0.8617 - val_recall: 0.7920 - val_precision: 0.9191\n",
      "Epoch 218/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3403 - accuracy: 0.8620 - recall: 0.8316 - precision: 0.8858 - val_loss: 0.3284 - val_accuracy: 0.8689 - val_recall: 0.8429 - val_precision: 0.8882\n",
      "Epoch 219/500\n",
      "2902/2902 [==============================] - 18s 6ms/step - loss: 0.3394 - accuracy: 0.8626 - recall: 0.8318 - precision: 0.8868 - val_loss: 0.3268 - val_accuracy: 0.8678 - val_recall: 0.8154 - val_precision: 0.9098\n",
      "Epoch 220/500\n",
      "2902/2902 [==============================] - 18s 6ms/step - loss: 0.3402 - accuracy: 0.8607 - recall: 0.8292 - precision: 0.8852 - val_loss: 0.3271 - val_accuracy: 0.8666 - val_recall: 0.8138 - val_precision: 0.9089\n",
      "Epoch 221/500\n",
      "2902/2902 [==============================] - 16s 6ms/step - loss: 0.3402 - accuracy: 0.8627 - recall: 0.8308 - precision: 0.8878 - val_loss: 0.3268 - val_accuracy: 0.8673 - val_recall: 0.8086 - val_precision: 0.9151\n",
      "Epoch 222/500\n",
      "2902/2902 [==============================] - 10s 3ms/step - loss: 0.3396 - accuracy: 0.8635 - recall: 0.8327 - precision: 0.8876 - val_loss: 0.3267 - val_accuracy: 0.8678 - val_recall: 0.8221 - val_precision: 0.9037\n",
      "Epoch 223/500\n",
      "2902/2902 [==============================] - 10s 3ms/step - loss: 0.3399 - accuracy: 0.8624 - recall: 0.8325 - precision: 0.8857 - val_loss: 0.3271 - val_accuracy: 0.8665 - val_recall: 0.8096 - val_precision: 0.9124\n",
      "Epoch 224/500\n",
      "2902/2902 [==============================] - 16s 5ms/step - loss: 0.3386 - accuracy: 0.8634 - recall: 0.8334 - precision: 0.8869 - val_loss: 0.3264 - val_accuracy: 0.8725 - val_recall: 0.8445 - val_precision: 0.8937\n",
      "Epoch 225/500\n",
      "2902/2902 [==============================] - 49s 17ms/step - loss: 0.3394 - accuracy: 0.8627 - recall: 0.8327 - precision: 0.8861 - val_loss: 0.3259 - val_accuracy: 0.8696 - val_recall: 0.8230 - val_precision: 0.9065\n",
      "Epoch 226/500\n",
      "2902/2902 [==============================] - 42s 15ms/step - loss: 0.3371 - accuracy: 0.8637 - recall: 0.8346 - precision: 0.8864 - val_loss: 0.3264 - val_accuracy: 0.8686 - val_recall: 0.8198 - val_precision: 0.9074\n",
      "Epoch 227/500\n",
      "2902/2902 [==============================] - 21s 7ms/step - loss: 0.3404 - accuracy: 0.8629 - recall: 0.8318 - precision: 0.8872 - val_loss: 0.3260 - val_accuracy: 0.8691 - val_recall: 0.8235 - val_precision: 0.9050\n",
      "Epoch 228/500\n",
      "2902/2902 [==============================] - 23s 8ms/step - loss: 0.3384 - accuracy: 0.8634 - recall: 0.8335 - precision: 0.8869 - val_loss: 0.3264 - val_accuracy: 0.8721 - val_recall: 0.8411 - val_precision: 0.8956\n",
      "Epoch 229/500\n",
      "2902/2902 [==============================] - 31s 11ms/step - loss: 0.3387 - accuracy: 0.8631 - recall: 0.8332 - precision: 0.8865 - val_loss: 0.3251 - val_accuracy: 0.8706 - val_recall: 0.8375 - val_precision: 0.8959\n",
      "Epoch 230/500\n",
      "2902/2902 [==============================] - 35s 12ms/step - loss: 0.3380 - accuracy: 0.8633 - recall: 0.8334 - precision: 0.8866 - val_loss: 0.3271 - val_accuracy: 0.8719 - val_recall: 0.8443 - val_precision: 0.8927\n",
      "Epoch 231/500\n",
      "2902/2902 [==============================] - 39s 13ms/step - loss: 0.3377 - accuracy: 0.8631 - recall: 0.8330 - precision: 0.8865 - val_loss: 0.3266 - val_accuracy: 0.8685 - val_recall: 0.8220 - val_precision: 0.9053\n",
      "Epoch 232/500\n",
      "2902/2902 [==============================] - 36s 12ms/step - loss: 0.3388 - accuracy: 0.8631 - recall: 0.8330 - precision: 0.8866 - val_loss: 0.3255 - val_accuracy: 0.8723 - val_recall: 0.8306 - val_precision: 0.9052\n",
      "Epoch 233/500\n",
      "2902/2902 [==============================] - 31s 11ms/step - loss: 0.3373 - accuracy: 0.8638 - recall: 0.8345 - precision: 0.8867 - val_loss: 0.3244 - val_accuracy: 0.8713 - val_recall: 0.8358 - val_precision: 0.8986\n",
      "Epoch 234/500\n",
      "2902/2902 [==============================] - 29s 10ms/step - loss: 0.3380 - accuracy: 0.8633 - recall: 0.8328 - precision: 0.8871 - val_loss: 0.3252 - val_accuracy: 0.8702 - val_recall: 0.8340 - val_precision: 0.8981\n",
      "Epoch 235/500\n",
      "2902/2902 [==============================] - 30s 10ms/step - loss: 0.3372 - accuracy: 0.8650 - recall: 0.8372 - precision: 0.8868 - val_loss: 0.3255 - val_accuracy: 0.8670 - val_recall: 0.8104 - val_precision: 0.9127\n",
      "Epoch 236/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3369 - accuracy: 0.8648 - recall: 0.8352 - precision: 0.8881 - val_loss: 0.3251 - val_accuracy: 0.8731 - val_recall: 0.8482 - val_precision: 0.8917\n",
      "Epoch 237/500\n",
      "2902/2902 [==============================] - 26s 9ms/step - loss: 0.3380 - accuracy: 0.8631 - recall: 0.8338 - precision: 0.8859 - val_loss: 0.3237 - val_accuracy: 0.8719 - val_recall: 0.8351 - val_precision: 0.9005\n",
      "Epoch 238/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3377 - accuracy: 0.8635 - recall: 0.8340 - precision: 0.8866 - val_loss: 0.3236 - val_accuracy: 0.8709 - val_recall: 0.8323 - val_precision: 0.9010\n",
      "Epoch 239/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3364 - accuracy: 0.8657 - recall: 0.8374 - precision: 0.8879 - val_loss: 0.3250 - val_accuracy: 0.8680 - val_recall: 0.8144 - val_precision: 0.9112\n",
      "Epoch 240/500\n",
      "2902/2902 [==============================] - 26s 9ms/step - loss: 0.3366 - accuracy: 0.8651 - recall: 0.8376 - precision: 0.8865 - val_loss: 0.3245 - val_accuracy: 0.8687 - val_recall: 0.8138 - val_precision: 0.9130\n",
      "Epoch 241/500\n",
      "2902/2902 [==============================] - 26s 9ms/step - loss: 0.3371 - accuracy: 0.8643 - recall: 0.8369 - precision: 0.8857 - val_loss: 0.3273 - val_accuracy: 0.8678 - val_recall: 0.8024 - val_precision: 0.9220\n",
      "Epoch 242/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3373 - accuracy: 0.8645 - recall: 0.8365 - precision: 0.8863 - val_loss: 0.3244 - val_accuracy: 0.8738 - val_recall: 0.8477 - val_precision: 0.8935\n",
      "Epoch 243/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3380 - accuracy: 0.8641 - recall: 0.8360 - precision: 0.8862 - val_loss: 0.3247 - val_accuracy: 0.8696 - val_recall: 0.8194 - val_precision: 0.9097\n",
      "Epoch 244/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3376 - accuracy: 0.8637 - recall: 0.8352 - precision: 0.8859 - val_loss: 0.3236 - val_accuracy: 0.8709 - val_recall: 0.8289 - val_precision: 0.9039\n",
      "Epoch 245/500\n",
      "2902/2902 [==============================] - 22s 7ms/step - loss: 0.3366 - accuracy: 0.8649 - recall: 0.8354 - precision: 0.8881 - val_loss: 0.3249 - val_accuracy: 0.8727 - val_recall: 0.8445 - val_precision: 0.8940\n",
      "Epoch 246/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3366 - accuracy: 0.8646 - recall: 0.8354 - precision: 0.8874 - val_loss: 0.3231 - val_accuracy: 0.8720 - val_recall: 0.8309 - val_precision: 0.9043\n",
      "Epoch 247/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3350 - accuracy: 0.8651 - recall: 0.8372 - precision: 0.8870 - val_loss: 0.3257 - val_accuracy: 0.8673 - val_recall: 0.8086 - val_precision: 0.9150\n",
      "Epoch 248/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3368 - accuracy: 0.8640 - recall: 0.8360 - precision: 0.8858 - val_loss: 0.3247 - val_accuracy: 0.8701 - val_recall: 0.8302 - val_precision: 0.9012\n",
      "Epoch 249/500\n",
      "2902/2902 [==============================] - 22s 7ms/step - loss: 0.3361 - accuracy: 0.8645 - recall: 0.8360 - precision: 0.8868 - val_loss: 0.3243 - val_accuracy: 0.8662 - val_recall: 0.8013 - val_precision: 0.9197\n",
      "Epoch 250/500\n",
      "2902/2902 [==============================] - 22s 7ms/step - loss: 0.3360 - accuracy: 0.8671 - recall: 0.8390 - precision: 0.8892 - val_loss: 0.3219 - val_accuracy: 0.8754 - val_recall: 0.8543 - val_precision: 0.8910\n",
      "Epoch 251/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3353 - accuracy: 0.8646 - recall: 0.8359 - precision: 0.8870 - val_loss: 0.3237 - val_accuracy: 0.8690 - val_recall: 0.8208 - val_precision: 0.9073\n",
      "Epoch 252/500\n",
      "2902/2902 [==============================] - 29s 10ms/step - loss: 0.3350 - accuracy: 0.8651 - recall: 0.8369 - precision: 0.8871 - val_loss: 0.3241 - val_accuracy: 0.8678 - val_recall: 0.8103 - val_precision: 0.9146\n",
      "Epoch 253/500\n",
      "2902/2902 [==============================] - 29s 10ms/step - loss: 0.3364 - accuracy: 0.8644 - recall: 0.8363 - precision: 0.8864 - val_loss: 0.3218 - val_accuracy: 0.8731 - val_recall: 0.8370 - val_precision: 0.9011\n",
      "Epoch 254/500\n",
      "2902/2902 [==============================] - 27s 9ms/step - loss: 0.3349 - accuracy: 0.8655 - recall: 0.8376 - precision: 0.8874 - val_loss: 0.3231 - val_accuracy: 0.8736 - val_recall: 0.8547 - val_precision: 0.8874\n",
      "Epoch 255/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3351 - accuracy: 0.8645 - recall: 0.8363 - precision: 0.8866 - val_loss: 0.3213 - val_accuracy: 0.8746 - val_recall: 0.8452 - val_precision: 0.8970\n",
      "Epoch 256/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3345 - accuracy: 0.8655 - recall: 0.8390 - precision: 0.8862 - val_loss: 0.3211 - val_accuracy: 0.8709 - val_recall: 0.8261 - val_precision: 0.9065\n",
      "Epoch 257/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3359 - accuracy: 0.8659 - recall: 0.8394 - precision: 0.8867 - val_loss: 0.3228 - val_accuracy: 0.8747 - val_recall: 0.8590 - val_precision: 0.8859\n",
      "Epoch 258/500\n",
      "2902/2902 [==============================] - 28s 10ms/step - loss: 0.3369 - accuracy: 0.8647 - recall: 0.8372 - precision: 0.8861 - val_loss: 0.3228 - val_accuracy: 0.8725 - val_recall: 0.8377 - val_precision: 0.8993\n",
      "Epoch 259/500\n",
      "2902/2902 [==============================] - 21s 7ms/step - loss: 0.3351 - accuracy: 0.8659 - recall: 0.8388 - precision: 0.8871 - val_loss: 0.3213 - val_accuracy: 0.8728 - val_recall: 0.8524 - val_precision: 0.8878\n",
      "Epoch 260/500\n",
      "2902/2902 [==============================] - 24s 8ms/step - loss: 0.3353 - accuracy: 0.8654 - recall: 0.8386 - precision: 0.8864 - val_loss: 0.3212 - val_accuracy: 0.8743 - val_recall: 0.8481 - val_precision: 0.8940\n",
      "Epoch 261/500\n",
      "2902/2902 [==============================] - 22s 7ms/step - loss: 0.3343 - accuracy: 0.8662 - recall: 0.8397 - precision: 0.8868 - val_loss: 0.3209 - val_accuracy: 0.8731 - val_recall: 0.8351 - val_precision: 0.9028\n",
      "Epoch 262/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3345 - accuracy: 0.8662 - recall: 0.8404 - precision: 0.8864 - val_loss: 0.3196 - val_accuracy: 0.8753 - val_recall: 0.8429 - val_precision: 0.9004\n",
      "Epoch 263/500\n",
      "2902/2902 [==============================] - 31s 11ms/step - loss: 0.3339 - accuracy: 0.8661 - recall: 0.8384 - precision: 0.8879 - val_loss: 0.3240 - val_accuracy: 0.8749 - val_recall: 0.8589 - val_precision: 0.8863\n",
      "Epoch 264/500\n",
      "2902/2902 [==============================] - 43s 15ms/step - loss: 0.3331 - accuracy: 0.8659 - recall: 0.8392 - precision: 0.8867 - val_loss: 0.3199 - val_accuracy: 0.8726 - val_recall: 0.8314 - val_precision: 0.9051\n",
      "Epoch 265/500\n",
      "2902/2902 [==============================] - 42s 14ms/step - loss: 0.3351 - accuracy: 0.8655 - recall: 0.8377 - precision: 0.8874 - val_loss: 0.3222 - val_accuracy: 0.8722 - val_recall: 0.8362 - val_precision: 0.9001\n",
      "Epoch 266/500\n",
      "2902/2902 [==============================] - 39s 13ms/step - loss: 0.3344 - accuracy: 0.8673 - recall: 0.8403 - precision: 0.8885 - val_loss: 0.3211 - val_accuracy: 0.8722 - val_recall: 0.8357 - val_precision: 0.9005\n",
      "Epoch 267/500\n",
      "2902/2902 [==============================] - 26s 9ms/step - loss: 0.3346 - accuracy: 0.8662 - recall: 0.8392 - precision: 0.8873 - val_loss: 0.3227 - val_accuracy: 0.8703 - val_recall: 0.8269 - val_precision: 0.9044\n",
      "Epoch 268/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3336 - accuracy: 0.8662 - recall: 0.8388 - precision: 0.8878 - val_loss: 0.3193 - val_accuracy: 0.8748 - val_recall: 0.8449 - val_precision: 0.8976\n",
      "Epoch 269/500\n",
      "2902/2902 [==============================] - 22s 8ms/step - loss: 0.3347 - accuracy: 0.8660 - recall: 0.8390 - precision: 0.8872 - val_loss: 0.3221 - val_accuracy: 0.8740 - val_recall: 0.8503 - val_precision: 0.8916\n",
      "Epoch 270/500\n",
      "2902/2902 [==============================] - 21s 7ms/step - loss: 0.3349 - accuracy: 0.8665 - recall: 0.8395 - precision: 0.8877 - val_loss: 0.3204 - val_accuracy: 0.8758 - val_recall: 0.8576 - val_precision: 0.8890\n",
      "Epoch 271/500\n",
      "2902/2902 [==============================] - 23s 8ms/step - loss: 0.3356 - accuracy: 0.8654 - recall: 0.8392 - precision: 0.8859 - val_loss: 0.3183 - val_accuracy: 0.8758 - val_recall: 0.8370 - val_precision: 0.9064\n",
      "Epoch 272/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3324 - accuracy: 0.8680 - recall: 0.8416 - precision: 0.8888 - val_loss: 0.3198 - val_accuracy: 0.8732 - val_recall: 0.8389 - val_precision: 0.8996\n",
      "Epoch 273/500\n",
      "2902/2902 [==============================] - 22s 7ms/step - loss: 0.3341 - accuracy: 0.8662 - recall: 0.8392 - precision: 0.8874 - val_loss: 0.3213 - val_accuracy: 0.8747 - val_recall: 0.8632 - val_precision: 0.8825\n",
      "Epoch 274/500\n",
      "2902/2902 [==============================] - 25s 9ms/step - loss: 0.3336 - accuracy: 0.8678 - recall: 0.8414 - precision: 0.8886 - val_loss: 0.3217 - val_accuracy: 0.8663 - val_recall: 0.8051 - val_precision: 0.9162\n",
      "Epoch 275/500\n",
      "2902/2902 [==============================] - 12s 4ms/step - loss: 0.3339 - accuracy: 0.8658 - recall: 0.8395 - precision: 0.8864 - val_loss: 0.3220 - val_accuracy: 0.8759 - val_recall: 0.8687 - val_precision: 0.8806\n",
      "Epoch 276/500\n",
      "2902/2902 [==============================] - 9s 3ms/step - loss: 0.3338 - accuracy: 0.8668 - recall: 0.8417 - precision: 0.8864 - val_loss: 0.3227 - val_accuracy: 0.8708 - val_recall: 0.8242 - val_precision: 0.9078\n",
      "Epoch 277/500\n",
      "2902/2902 [==============================] - 10s 4ms/step - loss: 0.3343 - accuracy: 0.8656 - recall: 0.8385 - precision: 0.8867 - val_loss: 0.3202 - val_accuracy: 0.8722 - val_recall: 0.8266 - val_precision: 0.9085\n",
      "Epoch 278/500\n",
      "2902/2902 [==============================] - 10s 4ms/step - loss: 0.3324 - accuracy: 0.8672 - recall: 0.8402 - precision: 0.8885 - val_loss: 0.3211 - val_accuracy: 0.8705 - val_recall: 0.8179 - val_precision: 0.9129\n",
      "Epoch 279/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3341 - accuracy: 0.8661 - recall: 0.8390 - precision: 0.8873 - val_loss: 0.3223 - val_accuracy: 0.8741 - val_recall: 0.8519 - val_precision: 0.8906\n",
      "Epoch 280/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3323 - accuracy: 0.8679 - recall: 0.8406 - precision: 0.8893 - val_loss: 0.3213 - val_accuracy: 0.8759 - val_recall: 0.8534 - val_precision: 0.8927\n",
      "Epoch 281/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3327 - accuracy: 0.8671 - recall: 0.8410 - precision: 0.8875 - val_loss: 0.3189 - val_accuracy: 0.8736 - val_recall: 0.8277 - val_precision: 0.9103\n",
      "Epoch 282/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3335 - accuracy: 0.8667 - recall: 0.8402 - precision: 0.8874 - val_loss: 0.3192 - val_accuracy: 0.8747 - val_recall: 0.8449 - val_precision: 0.8975\n",
      "Epoch 283/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3313 - accuracy: 0.8675 - recall: 0.8429 - precision: 0.8869 - val_loss: 0.3189 - val_accuracy: 0.8735 - val_recall: 0.8391 - val_precision: 0.9002\n",
      "Epoch 284/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3327 - accuracy: 0.8674 - recall: 0.8418 - precision: 0.8875 - val_loss: 0.3190 - val_accuracy: 0.8745 - val_recall: 0.8445 - val_precision: 0.8975\n",
      "Epoch 285/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3323 - accuracy: 0.8676 - recall: 0.8421 - precision: 0.8875 - val_loss: 0.3195 - val_accuracy: 0.8730 - val_recall: 0.8288 - val_precision: 0.9082\n",
      "Epoch 286/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3329 - accuracy: 0.8672 - recall: 0.8419 - precision: 0.8870 - val_loss: 0.3188 - val_accuracy: 0.8725 - val_recall: 0.8382 - val_precision: 0.8989\n",
      "Epoch 287/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3321 - accuracy: 0.8674 - recall: 0.8423 - precision: 0.8871 - val_loss: 0.3211 - val_accuracy: 0.8761 - val_recall: 0.8555 - val_precision: 0.8912\n",
      "Epoch 288/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3313 - accuracy: 0.8691 - recall: 0.8435 - precision: 0.8892 - val_loss: 0.3233 - val_accuracy: 0.8640 - val_recall: 0.7948 - val_precision: 0.9212\n",
      "Epoch 289/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3324 - accuracy: 0.8675 - recall: 0.8417 - precision: 0.8878 - val_loss: 0.3196 - val_accuracy: 0.8758 - val_recall: 0.8484 - val_precision: 0.8967\n",
      "Epoch 290/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3320 - accuracy: 0.8683 - recall: 0.8441 - precision: 0.8873 - val_loss: 0.3187 - val_accuracy: 0.8732 - val_recall: 0.8323 - val_precision: 0.9054\n",
      "Epoch 291/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3321 - accuracy: 0.8672 - recall: 0.8416 - precision: 0.8873 - val_loss: 0.3160 - val_accuracy: 0.8759 - val_recall: 0.8454 - val_precision: 0.8993\n",
      "Epoch 292/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3313 - accuracy: 0.8677 - recall: 0.8431 - precision: 0.8870 - val_loss: 0.3192 - val_accuracy: 0.8707 - val_recall: 0.8144 - val_precision: 0.9167\n",
      "Epoch 293/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3320 - accuracy: 0.8687 - recall: 0.8429 - precision: 0.8890 - val_loss: 0.3193 - val_accuracy: 0.8700 - val_recall: 0.8153 - val_precision: 0.9143\n",
      "Epoch 294/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3312 - accuracy: 0.8680 - recall: 0.8419 - precision: 0.8884 - val_loss: 0.3168 - val_accuracy: 0.8751 - val_recall: 0.8392 - val_precision: 0.9032\n",
      "Epoch 295/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3320 - accuracy: 0.8677 - recall: 0.8426 - precision: 0.8873 - val_loss: 0.3196 - val_accuracy: 0.8719 - val_recall: 0.8216 - val_precision: 0.9125\n",
      "Epoch 296/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3325 - accuracy: 0.8671 - recall: 0.8411 - precision: 0.8875 - val_loss: 0.3196 - val_accuracy: 0.8769 - val_recall: 0.8648 - val_precision: 0.8854\n",
      "Epoch 297/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3314 - accuracy: 0.8664 - recall: 0.8406 - precision: 0.8867 - val_loss: 0.3163 - val_accuracy: 0.8767 - val_recall: 0.8419 - val_precision: 0.9040\n",
      "Epoch 298/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3289 - accuracy: 0.8695 - recall: 0.8446 - precision: 0.8892 - val_loss: 0.3174 - val_accuracy: 0.8733 - val_recall: 0.8370 - val_precision: 0.9015\n",
      "Epoch 299/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3311 - accuracy: 0.8688 - recall: 0.8431 - precision: 0.8890 - val_loss: 0.3163 - val_accuracy: 0.8762 - val_recall: 0.8446 - val_precision: 0.9006\n",
      "Epoch 300/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3317 - accuracy: 0.8679 - recall: 0.8429 - precision: 0.8875 - val_loss: 0.3165 - val_accuracy: 0.8756 - val_recall: 0.8377 - val_precision: 0.9055\n",
      "Epoch 301/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3322 - accuracy: 0.8675 - recall: 0.8426 - precision: 0.8869 - val_loss: 0.3157 - val_accuracy: 0.8752 - val_recall: 0.8344 - val_precision: 0.9076\n",
      "Epoch 302/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3314 - accuracy: 0.8697 - recall: 0.8449 - precision: 0.8892 - val_loss: 0.3169 - val_accuracy: 0.8770 - val_recall: 0.8575 - val_precision: 0.8914\n",
      "Epoch 303/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3297 - accuracy: 0.8679 - recall: 0.8436 - precision: 0.8869 - val_loss: 0.3169 - val_accuracy: 0.8764 - val_recall: 0.8376 - val_precision: 0.9071\n",
      "Epoch 304/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3313 - accuracy: 0.8688 - recall: 0.8432 - precision: 0.8889 - val_loss: 0.3178 - val_accuracy: 0.8790 - val_recall: 0.8652 - val_precision: 0.8888\n",
      "Epoch 305/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3315 - accuracy: 0.8683 - recall: 0.8445 - precision: 0.8869 - val_loss: 0.3173 - val_accuracy: 0.8750 - val_recall: 0.8329 - val_precision: 0.9084\n",
      "Epoch 306/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3301 - accuracy: 0.8685 - recall: 0.8438 - precision: 0.8879 - val_loss: 0.3189 - val_accuracy: 0.8744 - val_recall: 0.8350 - val_precision: 0.9055\n",
      "Epoch 307/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3317 - accuracy: 0.8691 - recall: 0.8443 - precision: 0.8886 - val_loss: 0.3186 - val_accuracy: 0.8712 - val_recall: 0.8190 - val_precision: 0.9135\n",
      "Epoch 308/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3292 - accuracy: 0.8683 - recall: 0.8439 - precision: 0.8875 - val_loss: 0.3184 - val_accuracy: 0.8725 - val_recall: 0.8285 - val_precision: 0.9074\n",
      "Epoch 309/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3303 - accuracy: 0.8686 - recall: 0.8443 - precision: 0.8876 - val_loss: 0.3227 - val_accuracy: 0.8681 - val_recall: 0.8042 - val_precision: 0.9210\n",
      "Epoch 310/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3299 - accuracy: 0.8675 - recall: 0.8437 - precision: 0.8861 - val_loss: 0.3167 - val_accuracy: 0.8766 - val_recall: 0.8488 - val_precision: 0.8978\n",
      "Epoch 311/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3307 - accuracy: 0.8682 - recall: 0.8454 - precision: 0.8859 - val_loss: 0.3184 - val_accuracy: 0.8786 - val_recall: 0.8679 - val_precision: 0.8860\n",
      "Epoch 312/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3299 - accuracy: 0.8704 - recall: 0.8472 - precision: 0.8887 - val_loss: 0.3157 - val_accuracy: 0.8779 - val_recall: 0.8525 - val_precision: 0.8972\n",
      "Epoch 313/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3297 - accuracy: 0.8697 - recall: 0.8464 - precision: 0.8881 - val_loss: 0.3224 - val_accuracy: 0.8671 - val_recall: 0.8011 - val_precision: 0.9219\n",
      "Epoch 314/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3300 - accuracy: 0.8702 - recall: 0.8462 - precision: 0.8891 - val_loss: 0.3170 - val_accuracy: 0.8727 - val_recall: 0.8285 - val_precision: 0.9078\n",
      "Epoch 315/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3316 - accuracy: 0.8681 - recall: 0.8438 - precision: 0.8870 - val_loss: 0.3174 - val_accuracy: 0.8718 - val_recall: 0.8253 - val_precision: 0.9089\n",
      "Epoch 316/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3304 - accuracy: 0.8686 - recall: 0.8434 - precision: 0.8884 - val_loss: 0.3167 - val_accuracy: 0.8763 - val_recall: 0.8382 - val_precision: 0.9065\n",
      "Epoch 317/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3313 - accuracy: 0.8680 - recall: 0.8431 - precision: 0.8875 - val_loss: 0.3206 - val_accuracy: 0.8763 - val_recall: 0.8759 - val_precision: 0.8758\n",
      "Epoch 318/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3308 - accuracy: 0.8690 - recall: 0.8455 - precision: 0.8874 - val_loss: 0.3163 - val_accuracy: 0.8771 - val_recall: 0.8543 - val_precision: 0.8941\n",
      "Epoch 319/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3304 - accuracy: 0.8686 - recall: 0.8461 - precision: 0.8862 - val_loss: 0.3160 - val_accuracy: 0.8787 - val_recall: 0.8577 - val_precision: 0.8943\n",
      "Epoch 320/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3289 - accuracy: 0.8701 - recall: 0.8465 - precision: 0.8887 - val_loss: 0.3154 - val_accuracy: 0.8772 - val_recall: 0.8495 - val_precision: 0.8984\n",
      "Epoch 321/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3297 - accuracy: 0.8696 - recall: 0.8454 - precision: 0.8886 - val_loss: 0.3188 - val_accuracy: 0.8741 - val_recall: 0.8376 - val_precision: 0.9025\n",
      "Epoch 322/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3296 - accuracy: 0.8692 - recall: 0.8475 - precision: 0.8863 - val_loss: 0.3161 - val_accuracy: 0.8789 - val_recall: 0.8607 - val_precision: 0.8923\n",
      "Epoch 323/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3318 - accuracy: 0.8681 - recall: 0.8441 - precision: 0.8869 - val_loss: 0.3169 - val_accuracy: 0.8711 - val_recall: 0.8244 - val_precision: 0.9083\n",
      "Epoch 324/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3294 - accuracy: 0.8699 - recall: 0.8459 - precision: 0.8887 - val_loss: 0.3164 - val_accuracy: 0.8773 - val_recall: 0.8639 - val_precision: 0.8869\n",
      "Epoch 325/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3292 - accuracy: 0.8695 - recall: 0.8483 - precision: 0.8862 - val_loss: 0.3166 - val_accuracy: 0.8737 - val_recall: 0.8365 - val_precision: 0.9028\n",
      "Epoch 326/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3287 - accuracy: 0.8711 - recall: 0.8482 - precision: 0.8891 - val_loss: 0.3181 - val_accuracy: 0.8780 - val_recall: 0.8648 - val_precision: 0.8873\n",
      "Epoch 327/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3290 - accuracy: 0.8694 - recall: 0.8481 - precision: 0.8860 - val_loss: 0.3157 - val_accuracy: 0.8748 - val_recall: 0.8397 - val_precision: 0.9021\n",
      "Epoch 328/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3294 - accuracy: 0.8695 - recall: 0.8465 - precision: 0.8876 - val_loss: 0.3169 - val_accuracy: 0.8770 - val_recall: 0.8556 - val_precision: 0.8929\n",
      "Epoch 329/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3286 - accuracy: 0.8707 - recall: 0.8476 - precision: 0.8889 - val_loss: 0.3149 - val_accuracy: 0.8753 - val_recall: 0.8364 - val_precision: 0.9059\n",
      "Epoch 330/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3272 - accuracy: 0.8713 - recall: 0.8481 - precision: 0.8897 - val_loss: 0.3159 - val_accuracy: 0.8737 - val_recall: 0.8280 - val_precision: 0.9102\n",
      "Epoch 331/500\n",
      "2902/2902 [==============================] - 5s 2ms/step - loss: 0.3288 - accuracy: 0.8700 - recall: 0.8479 - precision: 0.8874 - val_loss: 0.3139 - val_accuracy: 0.8761 - val_recall: 0.8400 - val_precision: 0.9044\n",
      "Epoch 332/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3277 - accuracy: 0.8699 - recall: 0.8472 - precision: 0.8877 - val_loss: 0.3159 - val_accuracy: 0.8782 - val_recall: 0.8557 - val_precision: 0.8951\n",
      "Epoch 333/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3270 - accuracy: 0.8716 - recall: 0.8497 - precision: 0.8889 - val_loss: 0.3163 - val_accuracy: 0.8764 - val_recall: 0.8559 - val_precision: 0.8915\n",
      "Epoch 334/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3280 - accuracy: 0.8709 - recall: 0.8489 - precision: 0.8883 - val_loss: 0.3156 - val_accuracy: 0.8768 - val_recall: 0.8498 - val_precision: 0.8973\n",
      "Epoch 335/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3285 - accuracy: 0.8697 - recall: 0.8479 - precision: 0.8869 - val_loss: 0.3134 - val_accuracy: 0.8796 - val_recall: 0.8530 - val_precision: 0.9001\n",
      "Epoch 336/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3289 - accuracy: 0.8695 - recall: 0.8476 - precision: 0.8867 - val_loss: 0.3132 - val_accuracy: 0.8773 - val_recall: 0.8427 - val_precision: 0.9044\n",
      "Epoch 337/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3269 - accuracy: 0.8712 - recall: 0.8498 - precision: 0.8882 - val_loss: 0.3142 - val_accuracy: 0.8787 - val_recall: 0.8536 - val_precision: 0.8978\n",
      "Epoch 338/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3289 - accuracy: 0.8696 - recall: 0.8472 - precision: 0.8872 - val_loss: 0.3152 - val_accuracy: 0.8791 - val_recall: 0.8607 - val_precision: 0.8927\n",
      "Epoch 339/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3276 - accuracy: 0.8710 - recall: 0.8487 - precision: 0.8885 - val_loss: 0.3162 - val_accuracy: 0.8713 - val_recall: 0.8120 - val_precision: 0.9202\n",
      "Epoch 340/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3278 - accuracy: 0.8713 - recall: 0.8493 - precision: 0.8886 - val_loss: 0.3176 - val_accuracy: 0.8713 - val_recall: 0.8109 - val_precision: 0.9213\n",
      "Epoch 341/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3280 - accuracy: 0.8698 - recall: 0.8480 - precision: 0.8869 - val_loss: 0.3167 - val_accuracy: 0.8732 - val_recall: 0.8282 - val_precision: 0.9091\n",
      "Epoch 342/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3284 - accuracy: 0.8710 - recall: 0.8490 - precision: 0.8883 - val_loss: 0.3148 - val_accuracy: 0.8749 - val_recall: 0.8328 - val_precision: 0.9083\n",
      "Epoch 343/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3269 - accuracy: 0.8703 - recall: 0.8473 - precision: 0.8884 - val_loss: 0.3153 - val_accuracy: 0.8752 - val_recall: 0.8427 - val_precision: 0.9003\n",
      "Epoch 344/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3270 - accuracy: 0.8710 - recall: 0.8480 - precision: 0.8891 - val_loss: 0.3148 - val_accuracy: 0.8756 - val_recall: 0.8427 - val_precision: 0.9010\n",
      "Epoch 345/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3283 - accuracy: 0.8698 - recall: 0.8484 - precision: 0.8866 - val_loss: 0.3159 - val_accuracy: 0.8740 - val_recall: 0.8362 - val_precision: 0.9036\n",
      "Epoch 346/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3288 - accuracy: 0.8697 - recall: 0.8473 - precision: 0.8874 - val_loss: 0.3136 - val_accuracy: 0.8790 - val_recall: 0.8607 - val_precision: 0.8925\n",
      "Epoch 347/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3266 - accuracy: 0.8718 - recall: 0.8498 - precision: 0.8891 - val_loss: 0.3158 - val_accuracy: 0.8728 - val_recall: 0.8199 - val_precision: 0.9159\n",
      "Epoch 348/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3275 - accuracy: 0.8707 - recall: 0.8486 - precision: 0.8881 - val_loss: 0.3149 - val_accuracy: 0.8774 - val_recall: 0.8545 - val_precision: 0.8947\n",
      "Epoch 349/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3284 - accuracy: 0.8711 - recall: 0.8488 - precision: 0.8887 - val_loss: 0.3150 - val_accuracy: 0.8733 - val_recall: 0.8323 - val_precision: 0.9057\n",
      "Epoch 350/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3280 - accuracy: 0.8701 - recall: 0.8482 - precision: 0.8873 - val_loss: 0.3138 - val_accuracy: 0.8769 - val_recall: 0.8360 - val_precision: 0.9096\n",
      "Epoch 351/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3273 - accuracy: 0.8713 - recall: 0.8493 - precision: 0.8886 - val_loss: 0.3153 - val_accuracy: 0.8763 - val_recall: 0.8331 - val_precision: 0.9110\n",
      "Epoch 352/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3272 - accuracy: 0.8709 - recall: 0.8487 - precision: 0.8883 - val_loss: 0.3179 - val_accuracy: 0.8714 - val_recall: 0.8128 - val_precision: 0.9196\n",
      "Epoch 353/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3278 - accuracy: 0.8714 - recall: 0.8500 - precision: 0.8882 - val_loss: 0.3148 - val_accuracy: 0.8778 - val_recall: 0.8652 - val_precision: 0.8868\n",
      "Epoch 354/500\n",
      "2902/2902 [==============================] - 4s 1ms/step - loss: 0.3275 - accuracy: 0.8701 - recall: 0.8476 - precision: 0.8877 - val_loss: 0.3167 - val_accuracy: 0.8761 - val_recall: 0.8488 - val_precision: 0.8969\n",
      "Epoch 355/500\n",
      "2902/2902 [==============================] - 6s 2ms/step - loss: 0.3284 - accuracy: 0.8692 - recall: 0.8471 - precision: 0.8865 - val_loss: 0.3151 - val_accuracy: 0.8747 - val_recall: 0.8375 - val_precision: 0.9038\n",
      "Epoch 356/500\n",
      "2902/2902 [==============================] - 4s 2ms/step - loss: 0.3275 - accuracy: 0.8704 - recall: 0.8482 - precision: 0.8879 - val_loss: 0.3141 - val_accuracy: 0.8758 - val_recall: 0.8438 - val_precision: 0.9005\n",
      "2902/2902 [==============================] - 2s 778us/step\n",
      "726/726 [==============================] - 1s 772us/step\n",
      "Acurácia no conjunto de treinamento: 0.8993850946426392\n",
      "Acurácia no conjunto de teste: 0.8772776126861572\n",
      "AUC no conjunto de treinamento: 0.9641576224288825\n",
      "AUC no conjunto de teste: 0.9521201639160509\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/726 [..............................] - ETA: 38s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 836us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.85      0.91      0.88     11654\n",
      "    Classe 1       0.90      0.84      0.87     11561\n",
      "\n",
      "    accuracy                           0.88     23215\n",
      "   macro avg       0.88      0.88      0.88     23215\n",
      "weighted avg       0.88      0.88      0.88     23215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 726us/step\n",
      "Threshold: 0.10, Precision: 0.671, Recall: 0.986, F1 Score: 0.798, Accuracy: 0.752\n",
      "Threshold: 0.11, Precision: 0.681, Recall: 0.985, F1 Score: 0.805, Accuracy: 0.763\n",
      "Threshold: 0.12, Precision: 0.691, Recall: 0.983, F1 Score: 0.811, Accuracy: 0.772\n",
      "Threshold: 0.13, Precision: 0.701, Recall: 0.981, F1 Score: 0.818, Accuracy: 0.782\n",
      "Threshold: 0.14, Precision: 0.712, Recall: 0.979, F1 Score: 0.824, Accuracy: 0.792\n",
      "Threshold: 0.15, Precision: 0.720, Recall: 0.978, F1 Score: 0.830, Accuracy: 0.800\n",
      "Threshold: 0.16, Precision: 0.728, Recall: 0.975, F1 Score: 0.834, Accuracy: 0.807\n",
      "Threshold: 0.17, Precision: 0.737, Recall: 0.973, F1 Score: 0.838, Accuracy: 0.813\n",
      "Threshold: 0.18, Precision: 0.745, Recall: 0.970, F1 Score: 0.843, Accuracy: 0.820\n",
      "Threshold: 0.19, Precision: 0.754, Recall: 0.967, F1 Score: 0.847, Accuracy: 0.826\n",
      "Threshold: 0.20, Precision: 0.761, Recall: 0.965, F1 Score: 0.851, Accuracy: 0.832\n",
      "Threshold: 0.21, Precision: 0.769, Recall: 0.963, F1 Score: 0.855, Accuracy: 0.838\n",
      "Threshold: 0.22, Precision: 0.777, Recall: 0.960, F1 Score: 0.859, Accuracy: 0.843\n",
      "Threshold: 0.23, Precision: 0.783, Recall: 0.956, F1 Score: 0.861, Accuracy: 0.846\n",
      "Threshold: 0.24, Precision: 0.790, Recall: 0.954, F1 Score: 0.864, Accuracy: 0.850\n",
      "Threshold: 0.25, Precision: 0.796, Recall: 0.951, F1 Score: 0.866, Accuracy: 0.854\n",
      "Threshold: 0.26, Precision: 0.802, Recall: 0.948, F1 Score: 0.869, Accuracy: 0.858\n",
      "Threshold: 0.27, Precision: 0.806, Recall: 0.945, F1 Score: 0.870, Accuracy: 0.860\n",
      "Threshold: 0.28, Precision: 0.812, Recall: 0.942, F1 Score: 0.872, Accuracy: 0.863\n",
      "Threshold: 0.29, Precision: 0.818, Recall: 0.938, F1 Score: 0.874, Accuracy: 0.865\n",
      "Threshold: 0.30, Precision: 0.823, Recall: 0.933, F1 Score: 0.874, Accuracy: 0.867\n",
      "Threshold: 0.31, Precision: 0.829, Recall: 0.931, F1 Score: 0.877, Accuracy: 0.870\n",
      "Threshold: 0.32, Precision: 0.833, Recall: 0.927, F1 Score: 0.878, Accuracy: 0.871\n",
      "Threshold: 0.33, Precision: 0.839, Recall: 0.922, F1 Score: 0.879, Accuracy: 0.873\n",
      "Threshold: 0.34, Precision: 0.844, Recall: 0.918, F1 Score: 0.879, Accuracy: 0.875\n",
      "Threshold: 0.35, Precision: 0.848, Recall: 0.914, F1 Score: 0.880, Accuracy: 0.876\n",
      "Threshold: 0.36, Precision: 0.853, Recall: 0.909, F1 Score: 0.881, Accuracy: 0.877\n",
      "Threshold: 0.37, Precision: 0.858, Recall: 0.905, F1 Score: 0.881, Accuracy: 0.878\n",
      "Threshold: 0.38, Precision: 0.863, Recall: 0.901, F1 Score: 0.882, Accuracy: 0.880\n",
      "Threshold: 0.39, Precision: 0.867, Recall: 0.896, F1 Score: 0.881, Accuracy: 0.880\n",
      "Threshold: 0.40, Precision: 0.872, Recall: 0.893, F1 Score: 0.882, Accuracy: 0.881\n",
      "Threshold: 0.41, Precision: 0.876, Recall: 0.887, F1 Score: 0.881, Accuracy: 0.881\n",
      "Threshold: 0.42, Precision: 0.879, Recall: 0.882, F1 Score: 0.881, Accuracy: 0.881\n",
      "Threshold: 0.43, Precision: 0.882, Recall: 0.876, F1 Score: 0.879, Accuracy: 0.880\n",
      "Threshold: 0.44, Precision: 0.885, Recall: 0.871, F1 Score: 0.878, Accuracy: 0.879\n",
      "Threshold: 0.45, Precision: 0.888, Recall: 0.866, F1 Score: 0.877, Accuracy: 0.879\n",
      "Threshold: 0.46, Precision: 0.891, Recall: 0.862, F1 Score: 0.876, Accuracy: 0.879\n",
      "Threshold: 0.47, Precision: 0.894, Recall: 0.857, F1 Score: 0.875, Accuracy: 0.878\n",
      "Threshold: 0.48, Precision: 0.898, Recall: 0.852, F1 Score: 0.874, Accuracy: 0.878\n",
      "Threshold: 0.49, Precision: 0.901, Recall: 0.847, F1 Score: 0.873, Accuracy: 0.878\n",
      "Threshold: 0.50, Precision: 0.904, Recall: 0.843, F1 Score: 0.872, Accuracy: 0.877\n",
      "Threshold: 0.51, Precision: 0.907, Recall: 0.837, F1 Score: 0.871, Accuracy: 0.876\n",
      "Threshold: 0.52, Precision: 0.910, Recall: 0.831, F1 Score: 0.869, Accuracy: 0.875\n",
      "Threshold: 0.53, Precision: 0.913, Recall: 0.825, F1 Score: 0.867, Accuracy: 0.874\n",
      "Threshold: 0.54, Precision: 0.916, Recall: 0.821, F1 Score: 0.866, Accuracy: 0.873\n",
      "Threshold: 0.55, Precision: 0.918, Recall: 0.814, F1 Score: 0.863, Accuracy: 0.871\n",
      "Threshold: 0.56, Precision: 0.921, Recall: 0.809, F1 Score: 0.861, Accuracy: 0.870\n",
      "Threshold: 0.57, Precision: 0.923, Recall: 0.803, F1 Score: 0.859, Accuracy: 0.869\n",
      "Threshold: 0.58, Precision: 0.926, Recall: 0.798, F1 Score: 0.857, Accuracy: 0.868\n",
      "Threshold: 0.59, Precision: 0.929, Recall: 0.793, F1 Score: 0.856, Accuracy: 0.867\n",
      "Threshold: 0.60, Precision: 0.931, Recall: 0.788, F1 Score: 0.853, Accuracy: 0.865\n",
      "Threshold: 0.61, Precision: 0.933, Recall: 0.782, F1 Score: 0.851, Accuracy: 0.864\n",
      "Threshold: 0.62, Precision: 0.935, Recall: 0.776, F1 Score: 0.849, Accuracy: 0.862\n",
      "Threshold: 0.63, Precision: 0.937, Recall: 0.770, F1 Score: 0.846, Accuracy: 0.860\n",
      "Threshold: 0.64, Precision: 0.939, Recall: 0.765, F1 Score: 0.843, Accuracy: 0.858\n",
      "Threshold: 0.65, Precision: 0.940, Recall: 0.759, F1 Score: 0.840, Accuracy: 0.856\n",
      "Threshold: 0.66, Precision: 0.942, Recall: 0.752, F1 Score: 0.836, Accuracy: 0.853\n",
      "Threshold: 0.67, Precision: 0.944, Recall: 0.747, F1 Score: 0.834, Accuracy: 0.852\n",
      "Threshold: 0.68, Precision: 0.945, Recall: 0.740, F1 Score: 0.830, Accuracy: 0.849\n",
      "Threshold: 0.69, Precision: 0.947, Recall: 0.733, F1 Score: 0.827, Accuracy: 0.847\n",
      "Threshold: 0.70, Precision: 0.949, Recall: 0.728, F1 Score: 0.824, Accuracy: 0.845\n",
      "Threshold: 0.71, Precision: 0.951, Recall: 0.721, F1 Score: 0.820, Accuracy: 0.843\n",
      "Threshold: 0.72, Precision: 0.952, Recall: 0.716, F1 Score: 0.818, Accuracy: 0.841\n",
      "Threshold: 0.73, Precision: 0.955, Recall: 0.710, F1 Score: 0.815, Accuracy: 0.839\n",
      "Threshold: 0.74, Precision: 0.956, Recall: 0.704, F1 Score: 0.811, Accuracy: 0.837\n",
      "Threshold: 0.75, Precision: 0.958, Recall: 0.698, F1 Score: 0.808, Accuracy: 0.834\n",
      "Threshold: 0.76, Precision: 0.960, Recall: 0.692, F1 Score: 0.804, Accuracy: 0.832\n",
      "Threshold: 0.77, Precision: 0.962, Recall: 0.686, F1 Score: 0.801, Accuracy: 0.830\n",
      "Threshold: 0.78, Precision: 0.964, Recall: 0.677, F1 Score: 0.795, Accuracy: 0.826\n",
      "Threshold: 0.79, Precision: 0.966, Recall: 0.670, F1 Score: 0.791, Accuracy: 0.824\n",
      "Threshold: 0.80, Precision: 0.967, Recall: 0.664, F1 Score: 0.787, Accuracy: 0.821\n",
      "Threshold: 0.81, Precision: 0.969, Recall: 0.657, F1 Score: 0.783, Accuracy: 0.819\n",
      "Threshold: 0.82, Precision: 0.971, Recall: 0.650, F1 Score: 0.779, Accuracy: 0.816\n",
      "Threshold: 0.83, Precision: 0.972, Recall: 0.645, F1 Score: 0.775, Accuracy: 0.814\n",
      "Threshold: 0.84, Precision: 0.973, Recall: 0.639, F1 Score: 0.772, Accuracy: 0.812\n",
      "Threshold: 0.85, Precision: 0.975, Recall: 0.633, F1 Score: 0.768, Accuracy: 0.809\n",
      "Threshold: 0.86, Precision: 0.976, Recall: 0.628, F1 Score: 0.764, Accuracy: 0.807\n",
      "Threshold: 0.87, Precision: 0.977, Recall: 0.622, F1 Score: 0.760, Accuracy: 0.805\n",
      "Threshold: 0.88, Precision: 0.978, Recall: 0.616, F1 Score: 0.756, Accuracy: 0.802\n",
      "Threshold: 0.89, Precision: 0.980, Recall: 0.609, F1 Score: 0.751, Accuracy: 0.799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
