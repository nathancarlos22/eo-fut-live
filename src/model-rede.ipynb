{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'league',\n",
       "       'corners_home', 'corners_away', 'shotsOffgoal_home',\n",
       "       'shotsOffgoal_away', 'shotsOngoal_home', 'shotsOngoal_away',\n",
       "       'fouls_home', 'fouls_away', 'tackles_home', 'tackles_away', 'result',\n",
       "       'match_id', 'possessiontime_away', 'possessiontime_home',\n",
       "       'defensive_efficiency_home', 'defensive_efficiency_away',\n",
       "       'possession_efficiency_home', 'possession_efficiency_away',\n",
       "       'defensive_stability_home', 'defensive_stability_away',\n",
       "       'attack_intensity_home', 'attack_intensity_away',\n",
       "       'defensive_performance_home', 'defensive_performance_away',\n",
       "       'game_progress_efficiency_home', 'game_progress_efficiency_away',\n",
       "       'game_momentum_home', 'game_momentum_away', 'total_fouls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "691/691 [==============================] - 2s 2ms/step - loss: 0.6903 - accuracy: 0.6494 - recall_3: 0.5365 - precision_3: 0.6918 - val_loss: 0.5928 - val_accuracy: 0.7474 - val_recall_3: 0.7946 - val_precision_3: 0.7287\n",
      "Epoch 2/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5964 - accuracy: 0.7432 - recall_3: 0.7712 - precision_3: 0.7296 - val_loss: 0.5670 - val_accuracy: 0.7538 - val_recall_3: 0.7922 - val_precision_3: 0.7382\n",
      "Epoch 3/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7500 - recall_3: 0.7692 - precision_3: 0.7400 - val_loss: 0.5553 - val_accuracy: 0.7592 - val_recall_3: 0.7827 - val_precision_3: 0.7502\n",
      "Epoch 4/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5670 - accuracy: 0.7564 - recall_3: 0.7650 - precision_3: 0.7514 - val_loss: 0.5461 - val_accuracy: 0.7625 - val_recall_3: 0.7755 - val_precision_3: 0.7585\n",
      "Epoch 5/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5583 - accuracy: 0.7591 - recall_3: 0.7557 - precision_3: 0.7601 - val_loss: 0.5387 - val_accuracy: 0.7639 - val_recall_3: 0.7703 - val_precision_3: 0.7633\n",
      "Epoch 6/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.7624 - recall_3: 0.7515 - precision_3: 0.7674 - val_loss: 0.5316 - val_accuracy: 0.7663 - val_recall_3: 0.7628 - val_precision_3: 0.7709\n",
      "Epoch 7/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7662 - recall_3: 0.7489 - precision_3: 0.7750 - val_loss: 0.5252 - val_accuracy: 0.7678 - val_recall_3: 0.7558 - val_precision_3: 0.7773\n",
      "Epoch 8/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7682 - recall_3: 0.7445 - precision_3: 0.7807 - val_loss: 0.5192 - val_accuracy: 0.7711 - val_recall_3: 0.7489 - val_precision_3: 0.7865\n",
      "Epoch 9/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7694 - recall_3: 0.7380 - precision_3: 0.7868 - val_loss: 0.5140 - val_accuracy: 0.7715 - val_recall_3: 0.7435 - val_precision_3: 0.7906\n",
      "Epoch 10/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7717 - recall_3: 0.7334 - precision_3: 0.7935 - val_loss: 0.5087 - val_accuracy: 0.7726 - val_recall_3: 0.7369 - val_precision_3: 0.7966\n",
      "Epoch 11/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5181 - accuracy: 0.7727 - recall_3: 0.7299 - precision_3: 0.7975 - val_loss: 0.5037 - val_accuracy: 0.7734 - val_recall_3: 0.7293 - val_precision_3: 0.8029\n",
      "Epoch 12/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5119 - accuracy: 0.7744 - recall_3: 0.7236 - precision_3: 0.8047 - val_loss: 0.4995 - val_accuracy: 0.7736 - val_recall_3: 0.7263 - val_precision_3: 0.8053\n",
      "Epoch 13/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7761 - recall_3: 0.7195 - precision_3: 0.8106 - val_loss: 0.4955 - val_accuracy: 0.7747 - val_recall_3: 0.7211 - val_precision_3: 0.8108\n",
      "Epoch 14/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7771 - recall_3: 0.7172 - precision_3: 0.8141 - val_loss: 0.4913 - val_accuracy: 0.7757 - val_recall_3: 0.7146 - val_precision_3: 0.8173\n",
      "Epoch 15/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7782 - recall_3: 0.7119 - precision_3: 0.8199 - val_loss: 0.4881 - val_accuracy: 0.7753 - val_recall_3: 0.7121 - val_precision_3: 0.8184\n",
      "Epoch 16/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4978 - accuracy: 0.7797 - recall_3: 0.7094 - precision_3: 0.8246 - val_loss: 0.4850 - val_accuracy: 0.7776 - val_recall_3: 0.7085 - val_precision_3: 0.8254\n",
      "Epoch 17/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4950 - accuracy: 0.7807 - recall_3: 0.7060 - precision_3: 0.8292 - val_loss: 0.4820 - val_accuracy: 0.7791 - val_recall_3: 0.7058 - val_precision_3: 0.8304\n",
      "Epoch 18/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4910 - accuracy: 0.7809 - recall_3: 0.7034 - precision_3: 0.8316 - val_loss: 0.4790 - val_accuracy: 0.7813 - val_recall_3: 0.7026 - val_precision_3: 0.8372\n",
      "Epoch 19/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7815 - recall_3: 0.6998 - precision_3: 0.8356 - val_loss: 0.4765 - val_accuracy: 0.7817 - val_recall_3: 0.6997 - val_precision_3: 0.8403\n",
      "Epoch 20/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7829 - recall_3: 0.6977 - precision_3: 0.8402 - val_loss: 0.4743 - val_accuracy: 0.7826 - val_recall_3: 0.6972 - val_precision_3: 0.8442\n",
      "Epoch 21/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4837 - accuracy: 0.7829 - recall_3: 0.6955 - precision_3: 0.8420 - val_loss: 0.4717 - val_accuracy: 0.7825 - val_recall_3: 0.6930 - val_precision_3: 0.8475\n",
      "Epoch 22/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.7838 - recall_3: 0.6931 - precision_3: 0.8458 - val_loss: 0.4694 - val_accuracy: 0.7828 - val_recall_3: 0.6903 - val_precision_3: 0.8503\n",
      "Epoch 23/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.7846 - recall_3: 0.6903 - precision_3: 0.8500 - val_loss: 0.4678 - val_accuracy: 0.7832 - val_recall_3: 0.6902 - val_precision_3: 0.8514\n",
      "Epoch 24/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4765 - accuracy: 0.7847 - recall_3: 0.6890 - precision_3: 0.8512 - val_loss: 0.4655 - val_accuracy: 0.7830 - val_recall_3: 0.6846 - val_precision_3: 0.8560\n",
      "Epoch 25/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4744 - accuracy: 0.7846 - recall_3: 0.6865 - precision_3: 0.8531 - val_loss: 0.4638 - val_accuracy: 0.7834 - val_recall_3: 0.6824 - val_precision_3: 0.8587\n",
      "Epoch 26/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4719 - accuracy: 0.7857 - recall_3: 0.6839 - precision_3: 0.8578 - val_loss: 0.4619 - val_accuracy: 0.7840 - val_recall_3: 0.6808 - val_precision_3: 0.8615\n",
      "Epoch 27/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4692 - accuracy: 0.7865 - recall_3: 0.6824 - precision_3: 0.8609 - val_loss: 0.4599 - val_accuracy: 0.7847 - val_recall_3: 0.6786 - val_precision_3: 0.8649\n",
      "Epoch 28/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4676 - accuracy: 0.7881 - recall_3: 0.6809 - precision_3: 0.8657 - val_loss: 0.4583 - val_accuracy: 0.7854 - val_recall_3: 0.6769 - val_precision_3: 0.8681\n",
      "Epoch 29/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.7875 - recall_3: 0.6789 - precision_3: 0.8664 - val_loss: 0.4563 - val_accuracy: 0.7856 - val_recall_3: 0.6731 - val_precision_3: 0.8721\n",
      "Epoch 30/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.7880 - recall_3: 0.6774 - precision_3: 0.8689 - val_loss: 0.4559 - val_accuracy: 0.7851 - val_recall_3: 0.6742 - val_precision_3: 0.8701\n",
      "Epoch 31/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4625 - accuracy: 0.7889 - recall_3: 0.6769 - precision_3: 0.8714 - val_loss: 0.4538 - val_accuracy: 0.7862 - val_recall_3: 0.6720 - val_precision_3: 0.8746\n",
      "Epoch 32/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.7885 - recall_3: 0.6751 - precision_3: 0.8721 - val_loss: 0.4525 - val_accuracy: 0.7858 - val_recall_3: 0.6713 - val_precision_3: 0.8745\n",
      "Epoch 33/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.7893 - recall_3: 0.6737 - precision_3: 0.8754 - val_loss: 0.4512 - val_accuracy: 0.7859 - val_recall_3: 0.6704 - val_precision_3: 0.8756\n",
      "Epoch 34/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.7895 - recall_3: 0.6725 - precision_3: 0.8771 - val_loss: 0.4492 - val_accuracy: 0.7876 - val_recall_3: 0.6680 - val_precision_3: 0.8816\n",
      "Epoch 35/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.7909 - recall_3: 0.6718 - precision_3: 0.8810 - val_loss: 0.4478 - val_accuracy: 0.7880 - val_recall_3: 0.6670 - val_precision_3: 0.8838\n",
      "Epoch 36/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4564 - accuracy: 0.7900 - recall_3: 0.6683 - precision_3: 0.8823 - val_loss: 0.4473 - val_accuracy: 0.7876 - val_recall_3: 0.6653 - val_precision_3: 0.8844\n",
      "Epoch 37/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.7907 - recall_3: 0.6691 - precision_3: 0.8833 - val_loss: 0.4462 - val_accuracy: 0.7883 - val_recall_3: 0.6650 - val_precision_3: 0.8864\n",
      "Epoch 38/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4526 - accuracy: 0.7907 - recall_3: 0.6661 - precision_3: 0.8862 - val_loss: 0.4450 - val_accuracy: 0.7881 - val_recall_3: 0.6636 - val_precision_3: 0.8875\n",
      "Epoch 39/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.7917 - recall_3: 0.6660 - precision_3: 0.8888 - val_loss: 0.4434 - val_accuracy: 0.7877 - val_recall_3: 0.6618 - val_precision_3: 0.8885\n",
      "Epoch 40/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.7923 - recall_3: 0.6649 - precision_3: 0.8913 - val_loss: 0.4427 - val_accuracy: 0.7880 - val_recall_3: 0.6612 - val_precision_3: 0.8897\n",
      "Epoch 41/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4488 - accuracy: 0.7919 - recall_3: 0.6630 - precision_3: 0.8924 - val_loss: 0.4413 - val_accuracy: 0.7880 - val_recall_3: 0.6596 - val_precision_3: 0.8914\n",
      "Epoch 42/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4469 - accuracy: 0.7927 - recall_3: 0.6625 - precision_3: 0.8948 - val_loss: 0.4404 - val_accuracy: 0.7886 - val_recall_3: 0.6592 - val_precision_3: 0.8931\n",
      "Epoch 43/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.7926 - recall_3: 0.6616 - precision_3: 0.8955 - val_loss: 0.4394 - val_accuracy: 0.7890 - val_recall_3: 0.6591 - val_precision_3: 0.8944\n",
      "Epoch 44/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.7927 - recall_3: 0.6593 - precision_3: 0.8983 - val_loss: 0.4386 - val_accuracy: 0.7900 - val_recall_3: 0.6585 - val_precision_3: 0.8974\n",
      "Epoch 45/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4452 - accuracy: 0.7924 - recall_3: 0.6584 - precision_3: 0.8984 - val_loss: 0.4373 - val_accuracy: 0.7902 - val_recall_3: 0.6565 - val_precision_3: 0.9000\n",
      "Epoch 46/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.7930 - recall_3: 0.6570 - precision_3: 0.9014 - val_loss: 0.4370 - val_accuracy: 0.7900 - val_recall_3: 0.6567 - val_precision_3: 0.8993\n",
      "Epoch 47/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.7930 - recall_3: 0.6576 - precision_3: 0.9009 - val_loss: 0.4358 - val_accuracy: 0.7896 - val_recall_3: 0.6553 - val_precision_3: 0.9000\n",
      "Epoch 48/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.7941 - recall_3: 0.6579 - precision_3: 0.9033 - val_loss: 0.4349 - val_accuracy: 0.7902 - val_recall_3: 0.6546 - val_precision_3: 0.9022\n",
      "Epoch 49/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.7934 - recall_3: 0.6567 - precision_3: 0.9028 - val_loss: 0.4339 - val_accuracy: 0.7904 - val_recall_3: 0.6529 - val_precision_3: 0.9044\n",
      "Epoch 50/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4379 - accuracy: 0.7938 - recall_3: 0.6552 - precision_3: 0.9056 - val_loss: 0.4329 - val_accuracy: 0.7903 - val_recall_3: 0.6512 - val_precision_3: 0.9062\n",
      "Epoch 51/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4377 - accuracy: 0.7940 - recall_3: 0.6545 - precision_3: 0.9067 - val_loss: 0.4323 - val_accuracy: 0.7910 - val_recall_3: 0.6510 - val_precision_3: 0.9082\n",
      "Epoch 52/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4364 - accuracy: 0.7947 - recall_3: 0.6536 - precision_3: 0.9096 - val_loss: 0.4313 - val_accuracy: 0.7916 - val_recall_3: 0.6501 - val_precision_3: 0.9109\n",
      "Epoch 53/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.7944 - recall_3: 0.6519 - precision_3: 0.9109 - val_loss: 0.4312 - val_accuracy: 0.7909 - val_recall_3: 0.6510 - val_precision_3: 0.9080\n",
      "Epoch 54/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4354 - accuracy: 0.7952 - recall_3: 0.6531 - precision_3: 0.9113 - val_loss: 0.4307 - val_accuracy: 0.7910 - val_recall_3: 0.6504 - val_precision_3: 0.9088\n",
      "Epoch 55/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4341 - accuracy: 0.7950 - recall_3: 0.6503 - precision_3: 0.9142 - val_loss: 0.4295 - val_accuracy: 0.7919 - val_recall_3: 0.6499 - val_precision_3: 0.9117\n",
      "Epoch 56/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.7957 - recall_3: 0.6515 - precision_3: 0.9145 - val_loss: 0.4295 - val_accuracy: 0.7915 - val_recall_3: 0.6501 - val_precision_3: 0.9104\n",
      "Epoch 57/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4333 - accuracy: 0.7946 - recall_3: 0.6501 - precision_3: 0.9133 - val_loss: 0.4282 - val_accuracy: 0.7931 - val_recall_3: 0.6470 - val_precision_3: 0.9181\n",
      "Epoch 58/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4340 - accuracy: 0.7959 - recall_3: 0.6506 - precision_3: 0.9162 - val_loss: 0.4280 - val_accuracy: 0.7919 - val_recall_3: 0.6479 - val_precision_3: 0.9140\n",
      "Epoch 59/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4320 - accuracy: 0.7959 - recall_3: 0.6500 - precision_3: 0.9169 - val_loss: 0.4274 - val_accuracy: 0.7923 - val_recall_3: 0.6479 - val_precision_3: 0.9150\n",
      "Epoch 60/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4311 - accuracy: 0.7954 - recall_3: 0.6490 - precision_3: 0.9166 - val_loss: 0.4276 - val_accuracy: 0.7918 - val_recall_3: 0.6481 - val_precision_3: 0.9136\n",
      "Epoch 61/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.7963 - recall_3: 0.6491 - precision_3: 0.9188 - val_loss: 0.4267 - val_accuracy: 0.7921 - val_recall_3: 0.6472 - val_precision_3: 0.9154\n",
      "Epoch 62/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.7961 - recall_3: 0.6487 - precision_3: 0.9188 - val_loss: 0.4254 - val_accuracy: 0.7928 - val_recall_3: 0.6436 - val_precision_3: 0.9215\n",
      "Epoch 63/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.7967 - recall_3: 0.6476 - precision_3: 0.9219 - val_loss: 0.4250 - val_accuracy: 0.7933 - val_recall_3: 0.6440 - val_precision_3: 0.9223\n",
      "Epoch 64/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4284 - accuracy: 0.7962 - recall_3: 0.6471 - precision_3: 0.9211 - val_loss: 0.4249 - val_accuracy: 0.7924 - val_recall_3: 0.6447 - val_precision_3: 0.9190\n",
      "Epoch 65/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4274 - accuracy: 0.7970 - recall_3: 0.6469 - precision_3: 0.9233 - val_loss: 0.4244 - val_accuracy: 0.7928 - val_recall_3: 0.6441 - val_precision_3: 0.9209\n",
      "Epoch 66/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4269 - accuracy: 0.7964 - recall_3: 0.6465 - precision_3: 0.9222 - val_loss: 0.4247 - val_accuracy: 0.7924 - val_recall_3: 0.6447 - val_precision_3: 0.9190\n",
      "Epoch 67/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4255 - accuracy: 0.7969 - recall_3: 0.6465 - precision_3: 0.9235 - val_loss: 0.4233 - val_accuracy: 0.7927 - val_recall_3: 0.6425 - val_precision_3: 0.9226\n",
      "Epoch 68/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4261 - accuracy: 0.7973 - recall_3: 0.6456 - precision_3: 0.9256 - val_loss: 0.4237 - val_accuracy: 0.7929 - val_recall_3: 0.6441 - val_precision_3: 0.9211\n",
      "Epoch 69/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4256 - accuracy: 0.7974 - recall_3: 0.6455 - precision_3: 0.9260 - val_loss: 0.4233 - val_accuracy: 0.7930 - val_recall_3: 0.6440 - val_precision_3: 0.9216\n",
      "Epoch 70/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4242 - accuracy: 0.7977 - recall_3: 0.6453 - precision_3: 0.9271 - val_loss: 0.4223 - val_accuracy: 0.7927 - val_recall_3: 0.6425 - val_precision_3: 0.9226\n",
      "Epoch 71/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4232 - accuracy: 0.7979 - recall_3: 0.6451 - precision_3: 0.9280 - val_loss: 0.4226 - val_accuracy: 0.7924 - val_recall_3: 0.6432 - val_precision_3: 0.9210\n",
      "Epoch 72/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4230 - accuracy: 0.7975 - recall_3: 0.6451 - precision_3: 0.9268 - val_loss: 0.4217 - val_accuracy: 0.7934 - val_recall_3: 0.6427 - val_precision_3: 0.9240\n",
      "Epoch 73/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.7979 - recall_3: 0.6451 - precision_3: 0.9281 - val_loss: 0.4214 - val_accuracy: 0.7936 - val_recall_3: 0.6423 - val_precision_3: 0.9252\n",
      "Epoch 74/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4223 - accuracy: 0.7976 - recall_3: 0.6449 - precision_3: 0.9273 - val_loss: 0.4208 - val_accuracy: 0.7937 - val_recall_3: 0.6416 - val_precision_3: 0.9263\n",
      "Epoch 75/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.7969 - recall_3: 0.6428 - precision_3: 0.9280 - val_loss: 0.4209 - val_accuracy: 0.7937 - val_recall_3: 0.6425 - val_precision_3: 0.9252\n",
      "Epoch 76/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4225 - accuracy: 0.7982 - recall_3: 0.6450 - precision_3: 0.9290 - val_loss: 0.4202 - val_accuracy: 0.7938 - val_recall_3: 0.6416 - val_precision_3: 0.9266\n",
      "Epoch 77/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4202 - accuracy: 0.7978 - recall_3: 0.6437 - precision_3: 0.9294 - val_loss: 0.4193 - val_accuracy: 0.7946 - val_recall_3: 0.6404 - val_precision_3: 0.9303\n",
      "Epoch 78/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4214 - accuracy: 0.7981 - recall_3: 0.6430 - precision_3: 0.9311 - val_loss: 0.4192 - val_accuracy: 0.7946 - val_recall_3: 0.6411 - val_precision_3: 0.9294\n",
      "Epoch 79/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.7979 - recall_3: 0.6435 - precision_3: 0.9301 - val_loss: 0.4193 - val_accuracy: 0.7944 - val_recall_3: 0.6414 - val_precision_3: 0.9285\n",
      "Epoch 80/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4201 - accuracy: 0.7986 - recall_3: 0.6432 - precision_3: 0.9323 - val_loss: 0.4184 - val_accuracy: 0.7947 - val_recall_3: 0.6409 - val_precision_3: 0.9299\n",
      "Epoch 81/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4206 - accuracy: 0.7985 - recall_3: 0.6426 - precision_3: 0.9326 - val_loss: 0.4185 - val_accuracy: 0.7943 - val_recall_3: 0.6407 - val_precision_3: 0.9291\n",
      "Epoch 82/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4187 - accuracy: 0.7984 - recall_3: 0.6427 - precision_3: 0.9322 - val_loss: 0.4182 - val_accuracy: 0.7949 - val_recall_3: 0.6409 - val_precision_3: 0.9303\n",
      "Epoch 83/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4192 - accuracy: 0.7985 - recall_3: 0.6422 - precision_3: 0.9330 - val_loss: 0.4177 - val_accuracy: 0.7951 - val_recall_3: 0.6404 - val_precision_3: 0.9315\n",
      "Epoch 84/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4172 - accuracy: 0.7993 - recall_3: 0.6428 - precision_3: 0.9347 - val_loss: 0.4182 - val_accuracy: 0.7947 - val_recall_3: 0.6416 - val_precision_3: 0.9290\n",
      "Epoch 85/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4182 - accuracy: 0.7984 - recall_3: 0.6416 - precision_3: 0.9337 - val_loss: 0.4172 - val_accuracy: 0.7947 - val_recall_3: 0.6395 - val_precision_3: 0.9317\n",
      "Epoch 86/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4167 - accuracy: 0.7986 - recall_3: 0.6417 - precision_3: 0.9339 - val_loss: 0.4173 - val_accuracy: 0.7950 - val_recall_3: 0.6393 - val_precision_3: 0.9326\n",
      "Epoch 87/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4166 - accuracy: 0.7983 - recall_3: 0.6405 - precision_3: 0.9349 - val_loss: 0.4170 - val_accuracy: 0.7946 - val_recall_3: 0.6393 - val_precision_3: 0.9316\n",
      "Epoch 88/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.7990 - recall_3: 0.6417 - precision_3: 0.9351 - val_loss: 0.4160 - val_accuracy: 0.7959 - val_recall_3: 0.6377 - val_precision_3: 0.9371\n",
      "Epoch 89/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4153 - accuracy: 0.7988 - recall_3: 0.6410 - precision_3: 0.9357 - val_loss: 0.4160 - val_accuracy: 0.7951 - val_recall_3: 0.6391 - val_precision_3: 0.9331\n",
      "Epoch 90/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.7988 - recall_3: 0.6411 - precision_3: 0.9353 - val_loss: 0.4157 - val_accuracy: 0.7957 - val_recall_3: 0.6386 - val_precision_3: 0.9355\n",
      "Epoch 91/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4158 - accuracy: 0.7991 - recall_3: 0.6400 - precision_3: 0.9375 - val_loss: 0.4160 - val_accuracy: 0.7952 - val_recall_3: 0.6396 - val_precision_3: 0.9327\n",
      "Epoch 92/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4154 - accuracy: 0.7991 - recall_3: 0.6405 - precision_3: 0.9370 - val_loss: 0.4152 - val_accuracy: 0.7957 - val_recall_3: 0.6380 - val_precision_3: 0.9362\n",
      "Epoch 93/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4137 - accuracy: 0.7992 - recall_3: 0.6411 - precision_3: 0.9366 - val_loss: 0.4148 - val_accuracy: 0.7962 - val_recall_3: 0.6379 - val_precision_3: 0.9376\n",
      "Epoch 94/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4151 - accuracy: 0.7990 - recall_3: 0.6395 - precision_3: 0.9379 - val_loss: 0.4149 - val_accuracy: 0.7958 - val_recall_3: 0.6384 - val_precision_3: 0.9360\n",
      "Epoch 95/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.7989 - recall_3: 0.6394 - precision_3: 0.9378 - val_loss: 0.4144 - val_accuracy: 0.7958 - val_recall_3: 0.6370 - val_precision_3: 0.9378\n",
      "Epoch 96/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.7994 - recall_3: 0.6399 - precision_3: 0.9385 - val_loss: 0.4143 - val_accuracy: 0.7963 - val_recall_3: 0.6373 - val_precision_3: 0.9386\n",
      "Epoch 97/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4126 - accuracy: 0.7993 - recall_3: 0.6395 - precision_3: 0.9387 - val_loss: 0.4144 - val_accuracy: 0.7961 - val_recall_3: 0.6380 - val_precision_3: 0.9372\n",
      "Epoch 98/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4129 - accuracy: 0.7997 - recall_3: 0.6402 - precision_3: 0.9392 - val_loss: 0.4138 - val_accuracy: 0.7963 - val_recall_3: 0.6364 - val_precision_3: 0.9398\n",
      "Epoch 99/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4138 - accuracy: 0.7988 - recall_3: 0.6394 - precision_3: 0.9375 - val_loss: 0.4138 - val_accuracy: 0.7954 - val_recall_3: 0.6379 - val_precision_3: 0.9357\n",
      "Epoch 100/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.7997 - recall_3: 0.6393 - precision_3: 0.9401 - val_loss: 0.4139 - val_accuracy: 0.7957 - val_recall_3: 0.6379 - val_precision_3: 0.9364\n",
      "Epoch 101/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.7996 - recall_3: 0.6404 - precision_3: 0.9384 - val_loss: 0.4134 - val_accuracy: 0.7964 - val_recall_3: 0.6366 - val_precision_3: 0.9400\n",
      "Epoch 102/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.7997 - recall_3: 0.6405 - precision_3: 0.9386 - val_loss: 0.4134 - val_accuracy: 0.7958 - val_recall_3: 0.6368 - val_precision_3: 0.9380\n",
      "Epoch 103/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.7997 - recall_3: 0.6395 - precision_3: 0.9400 - val_loss: 0.4132 - val_accuracy: 0.7959 - val_recall_3: 0.6370 - val_precision_3: 0.9381\n",
      "Epoch 104/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.7994 - recall_3: 0.6401 - precision_3: 0.9383 - val_loss: 0.4126 - val_accuracy: 0.7958 - val_recall_3: 0.6355 - val_precision_3: 0.9397\n",
      "Epoch 105/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.7992 - recall_3: 0.6394 - precision_3: 0.9385 - val_loss: 0.4127 - val_accuracy: 0.7959 - val_recall_3: 0.6362 - val_precision_3: 0.9390\n",
      "Epoch 106/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.7999 - recall_3: 0.6401 - precision_3: 0.9397 - val_loss: 0.4125 - val_accuracy: 0.7957 - val_recall_3: 0.6371 - val_precision_3: 0.9373\n",
      "Epoch 107/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.7995 - recall_3: 0.6398 - precision_3: 0.9390 - val_loss: 0.4125 - val_accuracy: 0.7961 - val_recall_3: 0.6370 - val_precision_3: 0.9386\n",
      "Epoch 108/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8001 - recall_3: 0.6398 - precision_3: 0.9407 - val_loss: 0.4122 - val_accuracy: 0.7962 - val_recall_3: 0.6364 - val_precision_3: 0.9395\n",
      "Epoch 109/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.7999 - recall_3: 0.6393 - precision_3: 0.9408 - val_loss: 0.4130 - val_accuracy: 0.7955 - val_recall_3: 0.6375 - val_precision_3: 0.9364\n",
      "Epoch 110/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8001 - recall_3: 0.6406 - precision_3: 0.9397 - val_loss: 0.4122 - val_accuracy: 0.7961 - val_recall_3: 0.6377 - val_precision_3: 0.9376\n",
      "Epoch 111/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.7996 - recall_3: 0.6386 - precision_3: 0.9409 - val_loss: 0.4120 - val_accuracy: 0.7957 - val_recall_3: 0.6373 - val_precision_3: 0.9371\n",
      "Epoch 112/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.7997 - recall_3: 0.6395 - precision_3: 0.9399 - val_loss: 0.4116 - val_accuracy: 0.7963 - val_recall_3: 0.6359 - val_precision_3: 0.9405\n",
      "Epoch 113/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8002 - recall_3: 0.6402 - precision_3: 0.9404 - val_loss: 0.4111 - val_accuracy: 0.7960 - val_recall_3: 0.6353 - val_precision_3: 0.9404\n",
      "Epoch 114/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4083 - accuracy: 0.8003 - recall_3: 0.6399 - precision_3: 0.9410 - val_loss: 0.4111 - val_accuracy: 0.7963 - val_recall_3: 0.6353 - val_precision_3: 0.9412\n",
      "Epoch 115/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.7999 - recall_3: 0.6401 - precision_3: 0.9397 - val_loss: 0.4109 - val_accuracy: 0.7959 - val_recall_3: 0.6357 - val_precision_3: 0.9397\n",
      "Epoch 116/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - recall_3: 0.6405 - precision_3: 0.9403 - val_loss: 0.4111 - val_accuracy: 0.7960 - val_recall_3: 0.6368 - val_precision_3: 0.9385\n",
      "Epoch 117/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8005 - recall_3: 0.6410 - precision_3: 0.9402 - val_loss: 0.4110 - val_accuracy: 0.7961 - val_recall_3: 0.6364 - val_precision_3: 0.9393\n",
      "Epoch 118/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8001 - recall_3: 0.6404 - precision_3: 0.9398 - val_loss: 0.4104 - val_accuracy: 0.7966 - val_recall_3: 0.6355 - val_precision_3: 0.9419\n",
      "Epoch 119/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4083 - accuracy: 0.8000 - recall_3: 0.6407 - precision_3: 0.9392 - val_loss: 0.4107 - val_accuracy: 0.7959 - val_recall_3: 0.6364 - val_precision_3: 0.9388\n",
      "Epoch 120/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4078 - accuracy: 0.8000 - recall_3: 0.6401 - precision_3: 0.9401 - val_loss: 0.4100 - val_accuracy: 0.7974 - val_recall_3: 0.6341 - val_precision_3: 0.9461\n",
      "Epoch 121/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.8005 - recall_3: 0.6415 - precision_3: 0.9397 - val_loss: 0.4106 - val_accuracy: 0.7963 - val_recall_3: 0.6355 - val_precision_3: 0.9412\n",
      "Epoch 122/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.8001 - recall_3: 0.6402 - precision_3: 0.9402 - val_loss: 0.4098 - val_accuracy: 0.7965 - val_recall_3: 0.6348 - val_precision_3: 0.9426\n",
      "Epoch 123/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8005 - recall_3: 0.6413 - precision_3: 0.9398 - val_loss: 0.4100 - val_accuracy: 0.7960 - val_recall_3: 0.6362 - val_precision_3: 0.9392\n",
      "Epoch 124/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4070 - accuracy: 0.8000 - recall_3: 0.6410 - precision_3: 0.9389 - val_loss: 0.4096 - val_accuracy: 0.7965 - val_recall_3: 0.6359 - val_precision_3: 0.9412\n",
      "Epoch 125/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4061 - accuracy: 0.8006 - recall_3: 0.6424 - precision_3: 0.9387 - val_loss: 0.4096 - val_accuracy: 0.7962 - val_recall_3: 0.6355 - val_precision_3: 0.9407\n",
      "Epoch 126/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8005 - recall_3: 0.6408 - precision_3: 0.9404 - val_loss: 0.4098 - val_accuracy: 0.7960 - val_recall_3: 0.6375 - val_precision_3: 0.9376\n",
      "Epoch 127/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8007 - recall_3: 0.6427 - precision_3: 0.9386 - val_loss: 0.4097 - val_accuracy: 0.7962 - val_recall_3: 0.6362 - val_precision_3: 0.9397\n",
      "Epoch 128/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4050 - accuracy: 0.8005 - recall_3: 0.6425 - precision_3: 0.9384 - val_loss: 0.4091 - val_accuracy: 0.7967 - val_recall_3: 0.6344 - val_precision_3: 0.9436\n",
      "Epoch 129/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8004 - recall_3: 0.6406 - precision_3: 0.9405 - val_loss: 0.4089 - val_accuracy: 0.7966 - val_recall_3: 0.6355 - val_precision_3: 0.9419\n",
      "Epoch 130/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8006 - recall_3: 0.6435 - precision_3: 0.9372 - val_loss: 0.4091 - val_accuracy: 0.7963 - val_recall_3: 0.6382 - val_precision_3: 0.9377\n",
      "Epoch 131/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8007 - recall_3: 0.6439 - precision_3: 0.9371 - val_loss: 0.4087 - val_accuracy: 0.7969 - val_recall_3: 0.6370 - val_precision_3: 0.9408\n",
      "Epoch 132/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8015 - recall_3: 0.6447 - precision_3: 0.9381 - val_loss: 0.4090 - val_accuracy: 0.7963 - val_recall_3: 0.6382 - val_precision_3: 0.9374\n",
      "Epoch 133/500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4051 - accuracy: 0.8005 - recall_3: 0.6439 - precision_3: 0.9364 - val_loss: 0.4088 - val_accuracy: 0.7958 - val_recall_3: 0.6355 - val_precision_3: 0.9397\n",
      "Epoch 134/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8012 - recall_3: 0.6442 - precision_3: 0.9379 - val_loss: 0.4084 - val_accuracy: 0.7968 - val_recall_3: 0.6361 - val_precision_3: 0.9417\n",
      "Epoch 135/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.7999 - recall_3: 0.6435 - precision_3: 0.9354 - val_loss: 0.4086 - val_accuracy: 0.7966 - val_recall_3: 0.6364 - val_precision_3: 0.9408\n",
      "Epoch 136/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8015 - recall_3: 0.6468 - precision_3: 0.9355 - val_loss: 0.4085 - val_accuracy: 0.7960 - val_recall_3: 0.6357 - val_precision_3: 0.9399\n",
      "Epoch 137/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8008 - recall_3: 0.6447 - precision_3: 0.9364 - val_loss: 0.4083 - val_accuracy: 0.7966 - val_recall_3: 0.6391 - val_precision_3: 0.9373\n",
      "Epoch 138/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4049 - accuracy: 0.8015 - recall_3: 0.6489 - precision_3: 0.9330 - val_loss: 0.4081 - val_accuracy: 0.7969 - val_recall_3: 0.6366 - val_precision_3: 0.9413\n",
      "Epoch 139/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8016 - recall_3: 0.6458 - precision_3: 0.9369 - val_loss: 0.4082 - val_accuracy: 0.7965 - val_recall_3: 0.6377 - val_precision_3: 0.9389\n",
      "Epoch 140/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4044 - accuracy: 0.8019 - recall_3: 0.6479 - precision_3: 0.9352 - val_loss: 0.4081 - val_accuracy: 0.7968 - val_recall_3: 0.6350 - val_precision_3: 0.9431\n",
      "Epoch 141/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8006 - recall_3: 0.6456 - precision_3: 0.9348 - val_loss: 0.4077 - val_accuracy: 0.7966 - val_recall_3: 0.6370 - val_precision_3: 0.9401\n",
      "Epoch 142/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4027 - accuracy: 0.8015 - recall_3: 0.6467 - precision_3: 0.9357 - val_loss: 0.4075 - val_accuracy: 0.7963 - val_recall_3: 0.6346 - val_precision_3: 0.9424\n",
      "Epoch 143/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8012 - recall_3: 0.6461 - precision_3: 0.9357 - val_loss: 0.4075 - val_accuracy: 0.7963 - val_recall_3: 0.6370 - val_precision_3: 0.9393\n",
      "Epoch 144/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4018 - accuracy: 0.8017 - recall_3: 0.6485 - precision_3: 0.9339 - val_loss: 0.4075 - val_accuracy: 0.7953 - val_recall_3: 0.6384 - val_precision_3: 0.9347\n",
      "Epoch 145/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8008 - recall_3: 0.6464 - precision_3: 0.9342 - val_loss: 0.4072 - val_accuracy: 0.7957 - val_recall_3: 0.6398 - val_precision_3: 0.9339\n",
      "Epoch 146/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8013 - recall_3: 0.6478 - precision_3: 0.9337 - val_loss: 0.4076 - val_accuracy: 0.7958 - val_recall_3: 0.6418 - val_precision_3: 0.9316\n",
      "Epoch 147/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8010 - recall_3: 0.6480 - precision_3: 0.9327 - val_loss: 0.4072 - val_accuracy: 0.7959 - val_recall_3: 0.6411 - val_precision_3: 0.9328\n",
      "Epoch 148/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4027 - accuracy: 0.8011 - recall_3: 0.6497 - precision_3: 0.9308 - val_loss: 0.4067 - val_accuracy: 0.7958 - val_recall_3: 0.6382 - val_precision_3: 0.9362\n",
      "Epoch 149/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8020 - recall_3: 0.6531 - precision_3: 0.9290 - val_loss: 0.4068 - val_accuracy: 0.7962 - val_recall_3: 0.6386 - val_precision_3: 0.9367\n",
      "Epoch 150/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8023 - recall_3: 0.6525 - precision_3: 0.9306 - val_loss: 0.4068 - val_accuracy: 0.7954 - val_recall_3: 0.6377 - val_precision_3: 0.9359\n",
      "Epoch 151/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4011 - accuracy: 0.8015 - recall_3: 0.6500 - precision_3: 0.9315 - val_loss: 0.4064 - val_accuracy: 0.7962 - val_recall_3: 0.6418 - val_precision_3: 0.9326\n",
      "Epoch 152/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8025 - recall_3: 0.6535 - precision_3: 0.9298 - val_loss: 0.4067 - val_accuracy: 0.7966 - val_recall_3: 0.6436 - val_precision_3: 0.9316\n",
      "Epoch 153/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8015 - recall_3: 0.6535 - precision_3: 0.9272 - val_loss: 0.4059 - val_accuracy: 0.7963 - val_recall_3: 0.6405 - val_precision_3: 0.9345\n",
      "Epoch 154/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.8013 - recall_3: 0.6528 - precision_3: 0.9275 - val_loss: 0.4066 - val_accuracy: 0.7965 - val_recall_3: 0.6427 - val_precision_3: 0.9325\n",
      "Epoch 155/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8024 - recall_3: 0.6554 - precision_3: 0.9274 - val_loss: 0.4061 - val_accuracy: 0.7961 - val_recall_3: 0.6416 - val_precision_3: 0.9326\n",
      "Epoch 156/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8029 - recall_3: 0.6545 - precision_3: 0.9298 - val_loss: 0.4061 - val_accuracy: 0.7962 - val_recall_3: 0.6474 - val_precision_3: 0.9257\n",
      "Epoch 157/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8024 - recall_3: 0.6561 - precision_3: 0.9264 - val_loss: 0.4058 - val_accuracy: 0.7966 - val_recall_3: 0.6450 - val_precision_3: 0.9298\n",
      "Epoch 158/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.4000 - accuracy: 0.8023 - recall_3: 0.6569 - precision_3: 0.9252 - val_loss: 0.4055 - val_accuracy: 0.7963 - val_recall_3: 0.6483 - val_precision_3: 0.9251\n",
      "Epoch 159/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8017 - recall_3: 0.6576 - precision_3: 0.9228 - val_loss: 0.4052 - val_accuracy: 0.7965 - val_recall_3: 0.6434 - val_precision_3: 0.9316\n",
      "Epoch 160/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8027 - recall_3: 0.6591 - precision_3: 0.9237 - val_loss: 0.4052 - val_accuracy: 0.7965 - val_recall_3: 0.6456 - val_precision_3: 0.9289\n",
      "Epoch 161/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8023 - recall_3: 0.6559 - precision_3: 0.9264 - val_loss: 0.4052 - val_accuracy: 0.7963 - val_recall_3: 0.6470 - val_precision_3: 0.9266\n",
      "Epoch 162/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8033 - recall_3: 0.6601 - precision_3: 0.9239 - val_loss: 0.4047 - val_accuracy: 0.7963 - val_recall_3: 0.6431 - val_precision_3: 0.9315\n",
      "Epoch 163/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8022 - recall_3: 0.6569 - precision_3: 0.9248 - val_loss: 0.4053 - val_accuracy: 0.7964 - val_recall_3: 0.6420 - val_precision_3: 0.9331\n",
      "Epoch 164/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3983 - accuracy: 0.8033 - recall_3: 0.6607 - precision_3: 0.9234 - val_loss: 0.4047 - val_accuracy: 0.7966 - val_recall_3: 0.6429 - val_precision_3: 0.9325\n",
      "Epoch 165/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8016 - recall_3: 0.6565 - precision_3: 0.9239 - val_loss: 0.4048 - val_accuracy: 0.7961 - val_recall_3: 0.6468 - val_precision_3: 0.9261\n",
      "Epoch 166/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8028 - recall_3: 0.6618 - precision_3: 0.9207 - val_loss: 0.4047 - val_accuracy: 0.7963 - val_recall_3: 0.6458 - val_precision_3: 0.9282\n",
      "Epoch 167/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8028 - recall_3: 0.6600 - precision_3: 0.9228 - val_loss: 0.4042 - val_accuracy: 0.7964 - val_recall_3: 0.6463 - val_precision_3: 0.9278\n",
      "Epoch 168/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.8032 - recall_3: 0.6599 - precision_3: 0.9240 - val_loss: 0.4046 - val_accuracy: 0.7967 - val_recall_3: 0.6508 - val_precision_3: 0.9230\n",
      "Epoch 169/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3987 - accuracy: 0.8039 - recall_3: 0.6625 - precision_3: 0.9227 - val_loss: 0.4042 - val_accuracy: 0.7965 - val_recall_3: 0.6456 - val_precision_3: 0.9289\n",
      "Epoch 170/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8023 - recall_3: 0.6587 - precision_3: 0.9231 - val_loss: 0.4050 - val_accuracy: 0.7967 - val_recall_3: 0.6569 - val_precision_3: 0.9158\n",
      "Epoch 171/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3980 - accuracy: 0.8031 - recall_3: 0.6625 - precision_3: 0.9208 - val_loss: 0.4037 - val_accuracy: 0.7981 - val_recall_3: 0.6501 - val_precision_3: 0.9274\n",
      "Epoch 172/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3970 - accuracy: 0.8028 - recall_3: 0.6613 - precision_3: 0.9214 - val_loss: 0.4040 - val_accuracy: 0.7963 - val_recall_3: 0.6513 - val_precision_3: 0.9214\n",
      "Epoch 173/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8028 - recall_3: 0.6647 - precision_3: 0.9174 - val_loss: 0.4034 - val_accuracy: 0.7972 - val_recall_3: 0.6477 - val_precision_3: 0.9281\n",
      "Epoch 174/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8022 - recall_3: 0.6637 - precision_3: 0.9170 - val_loss: 0.4034 - val_accuracy: 0.7972 - val_recall_3: 0.6454 - val_precision_3: 0.9310\n",
      "Epoch 175/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8038 - recall_3: 0.6605 - precision_3: 0.9248 - val_loss: 0.4037 - val_accuracy: 0.7967 - val_recall_3: 0.6483 - val_precision_3: 0.9261\n",
      "Epoch 176/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8036 - recall_3: 0.6626 - precision_3: 0.9220 - val_loss: 0.4037 - val_accuracy: 0.7973 - val_recall_3: 0.6547 - val_precision_3: 0.9199\n",
      "Epoch 177/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3962 - accuracy: 0.8038 - recall_3: 0.6675 - precision_3: 0.9166 - val_loss: 0.4035 - val_accuracy: 0.7978 - val_recall_3: 0.6485 - val_precision_3: 0.9287\n",
      "Epoch 178/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3967 - accuracy: 0.8042 - recall_3: 0.6640 - precision_3: 0.9218 - val_loss: 0.4037 - val_accuracy: 0.7978 - val_recall_3: 0.6515 - val_precision_3: 0.9250\n",
      "Epoch 179/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8037 - recall_3: 0.6618 - precision_3: 0.9231 - val_loss: 0.4033 - val_accuracy: 0.7982 - val_recall_3: 0.6551 - val_precision_3: 0.9216\n",
      "Epoch 180/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8029 - recall_3: 0.6631 - precision_3: 0.9195 - val_loss: 0.4032 - val_accuracy: 0.7980 - val_recall_3: 0.6495 - val_precision_3: 0.9279\n",
      "Epoch 181/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8034 - recall_3: 0.6661 - precision_3: 0.9173 - val_loss: 0.4030 - val_accuracy: 0.7970 - val_recall_3: 0.6571 - val_precision_3: 0.9163\n",
      "Epoch 182/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8036 - recall_3: 0.6649 - precision_3: 0.9190 - val_loss: 0.4034 - val_accuracy: 0.7981 - val_recall_3: 0.6558 - val_precision_3: 0.9205\n",
      "Epoch 183/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8032 - recall_3: 0.6693 - precision_3: 0.9132 - val_loss: 0.4030 - val_accuracy: 0.7971 - val_recall_3: 0.6549 - val_precision_3: 0.9190\n",
      "Epoch 184/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8040 - recall_3: 0.6686 - precision_3: 0.9160 - val_loss: 0.4029 - val_accuracy: 0.7977 - val_recall_3: 0.6555 - val_precision_3: 0.9200\n",
      "Epoch 185/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3961 - accuracy: 0.8042 - recall_3: 0.6691 - precision_3: 0.9159 - val_loss: 0.4025 - val_accuracy: 0.7981 - val_recall_3: 0.6580 - val_precision_3: 0.9180\n",
      "Epoch 186/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8048 - recall_3: 0.6729 - precision_3: 0.9132 - val_loss: 0.4028 - val_accuracy: 0.7978 - val_recall_3: 0.6544 - val_precision_3: 0.9215\n",
      "Epoch 187/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8028 - recall_3: 0.6694 - precision_3: 0.9120 - val_loss: 0.4020 - val_accuracy: 0.7981 - val_recall_3: 0.6596 - val_precision_3: 0.9161\n",
      "Epoch 188/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8047 - recall_3: 0.6723 - precision_3: 0.9135 - val_loss: 0.4021 - val_accuracy: 0.7984 - val_recall_3: 0.6537 - val_precision_3: 0.9240\n",
      "Epoch 189/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8052 - recall_3: 0.6699 - precision_3: 0.9175 - val_loss: 0.4022 - val_accuracy: 0.7985 - val_recall_3: 0.6643 - val_precision_3: 0.9119\n",
      "Epoch 190/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8052 - recall_3: 0.6700 - precision_3: 0.9174 - val_loss: 0.4017 - val_accuracy: 0.7991 - val_recall_3: 0.6551 - val_precision_3: 0.9240\n",
      "Epoch 191/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8051 - recall_3: 0.6750 - precision_3: 0.9115 - val_loss: 0.4022 - val_accuracy: 0.7983 - val_recall_3: 0.6564 - val_precision_3: 0.9206\n",
      "Epoch 192/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3940 - accuracy: 0.8036 - recall_3: 0.6691 - precision_3: 0.9143 - val_loss: 0.4020 - val_accuracy: 0.7989 - val_recall_3: 0.6565 - val_precision_3: 0.9218\n",
      "Epoch 193/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8051 - recall_3: 0.6761 - precision_3: 0.9103 - val_loss: 0.4019 - val_accuracy: 0.7982 - val_recall_3: 0.6553 - val_precision_3: 0.9216\n",
      "Epoch 194/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8044 - recall_3: 0.6726 - precision_3: 0.9125 - val_loss: 0.4018 - val_accuracy: 0.7989 - val_recall_3: 0.6621 - val_precision_3: 0.9153\n",
      "Epoch 195/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8053 - recall_3: 0.6736 - precision_3: 0.9137 - val_loss: 0.4015 - val_accuracy: 0.7981 - val_recall_3: 0.6641 - val_precision_3: 0.9110\n",
      "Epoch 196/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8055 - recall_3: 0.6751 - precision_3: 0.9122 - val_loss: 0.4014 - val_accuracy: 0.7995 - val_recall_3: 0.6614 - val_precision_3: 0.9177\n",
      "Epoch 197/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8061 - recall_3: 0.6726 - precision_3: 0.9166 - val_loss: 0.4018 - val_accuracy: 0.7996 - val_recall_3: 0.6648 - val_precision_3: 0.9140\n",
      "Epoch 198/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8062 - recall_3: 0.6779 - precision_3: 0.9108 - val_loss: 0.4015 - val_accuracy: 0.7995 - val_recall_3: 0.6740 - val_precision_3: 0.9036\n",
      "Epoch 199/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3928 - accuracy: 0.8057 - recall_3: 0.6796 - precision_3: 0.9078 - val_loss: 0.4013 - val_accuracy: 0.7996 - val_recall_3: 0.6700 - val_precision_3: 0.9082\n",
      "Epoch 200/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8048 - recall_3: 0.6792 - precision_3: 0.9061 - val_loss: 0.4012 - val_accuracy: 0.7990 - val_recall_3: 0.6623 - val_precision_3: 0.9153\n",
      "Epoch 201/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3926 - accuracy: 0.8058 - recall_3: 0.6795 - precision_3: 0.9081 - val_loss: 0.4010 - val_accuracy: 0.8001 - val_recall_3: 0.6661 - val_precision_3: 0.9137\n",
      "Epoch 202/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8076 - recall_3: 0.6834 - precision_3: 0.9083 - val_loss: 0.4013 - val_accuracy: 0.7991 - val_recall_3: 0.6738 - val_precision_3: 0.9029\n",
      "Epoch 203/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8051 - recall_3: 0.6799 - precision_3: 0.9062 - val_loss: 0.4013 - val_accuracy: 0.7988 - val_recall_3: 0.6627 - val_precision_3: 0.9144\n",
      "Epoch 204/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.8046 - recall_3: 0.6785 - precision_3: 0.9064 - val_loss: 0.4008 - val_accuracy: 0.7980 - val_recall_3: 0.6707 - val_precision_3: 0.9034\n",
      "Epoch 205/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8075 - recall_3: 0.6812 - precision_3: 0.9106 - val_loss: 0.4007 - val_accuracy: 0.7982 - val_recall_3: 0.6709 - val_precision_3: 0.9039\n",
      "Epoch 206/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3910 - accuracy: 0.8066 - recall_3: 0.6832 - precision_3: 0.9062 - val_loss: 0.4006 - val_accuracy: 0.7994 - val_recall_3: 0.6707 - val_precision_3: 0.9069\n",
      "Epoch 207/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8058 - recall_3: 0.6822 - precision_3: 0.9054 - val_loss: 0.4006 - val_accuracy: 0.7990 - val_recall_3: 0.6734 - val_precision_3: 0.9029\n",
      "Epoch 208/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3911 - accuracy: 0.8080 - recall_3: 0.6864 - precision_3: 0.9062 - val_loss: 0.4001 - val_accuracy: 0.7995 - val_recall_3: 0.6691 - val_precision_3: 0.9089\n",
      "Epoch 209/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3912 - accuracy: 0.8082 - recall_3: 0.6859 - precision_3: 0.9070 - val_loss: 0.4002 - val_accuracy: 0.7996 - val_recall_3: 0.6733 - val_precision_3: 0.9046\n",
      "Epoch 210/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8070 - recall_3: 0.6851 - precision_3: 0.9050 - val_loss: 0.4001 - val_accuracy: 0.7998 - val_recall_3: 0.6671 - val_precision_3: 0.9118\n",
      "Epoch 211/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3908 - accuracy: 0.8058 - recall_3: 0.6857 - precision_3: 0.9015 - val_loss: 0.4002 - val_accuracy: 0.7991 - val_recall_3: 0.6763 - val_precision_3: 0.9000\n",
      "Epoch 212/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8062 - recall_3: 0.6887 - precision_3: 0.8995 - val_loss: 0.4007 - val_accuracy: 0.7991 - val_recall_3: 0.6722 - val_precision_3: 0.9047\n",
      "Epoch 213/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8055 - recall_3: 0.6848 - precision_3: 0.9017 - val_loss: 0.3997 - val_accuracy: 0.7998 - val_recall_3: 0.6693 - val_precision_3: 0.9094\n",
      "Epoch 214/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3903 - accuracy: 0.8085 - recall_3: 0.6881 - precision_3: 0.9054 - val_loss: 0.3998 - val_accuracy: 0.7998 - val_recall_3: 0.6720 - val_precision_3: 0.9064\n",
      "Epoch 215/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3902 - accuracy: 0.8070 - recall_3: 0.6889 - precision_3: 0.9011 - val_loss: 0.3995 - val_accuracy: 0.7997 - val_recall_3: 0.6731 - val_precision_3: 0.9050\n",
      "Epoch 216/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3906 - accuracy: 0.8078 - recall_3: 0.6887 - precision_3: 0.9033 - val_loss: 0.3997 - val_accuracy: 0.8014 - val_recall_3: 0.6837 - val_precision_3: 0.8978\n",
      "Epoch 217/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3906 - accuracy: 0.8073 - recall_3: 0.6911 - precision_3: 0.8996 - val_loss: 0.3991 - val_accuracy: 0.8003 - val_recall_3: 0.6754 - val_precision_3: 0.9040\n",
      "Epoch 218/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8069 - recall_3: 0.6879 - precision_3: 0.9020 - val_loss: 0.3995 - val_accuracy: 0.7997 - val_recall_3: 0.6812 - val_precision_3: 0.8964\n",
      "Epoch 219/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8076 - recall_3: 0.6945 - precision_3: 0.8967 - val_loss: 0.3993 - val_accuracy: 0.8008 - val_recall_3: 0.6797 - val_precision_3: 0.9005\n",
      "Epoch 220/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3908 - accuracy: 0.8079 - recall_3: 0.6904 - precision_3: 0.9017 - val_loss: 0.3991 - val_accuracy: 0.8005 - val_recall_3: 0.6777 - val_precision_3: 0.9019\n",
      "Epoch 221/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8081 - recall_3: 0.6907 - precision_3: 0.9016 - val_loss: 0.3996 - val_accuracy: 0.8005 - val_recall_3: 0.6772 - val_precision_3: 0.9025\n",
      "Epoch 222/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3894 - accuracy: 0.8090 - recall_3: 0.6934 - precision_3: 0.9011 - val_loss: 0.3994 - val_accuracy: 0.8012 - val_recall_3: 0.6761 - val_precision_3: 0.9054\n",
      "Epoch 223/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8066 - recall_3: 0.6892 - precision_3: 0.8998 - val_loss: 0.3992 - val_accuracy: 0.8011 - val_recall_3: 0.6840 - val_precision_3: 0.8966\n",
      "Epoch 224/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8080 - recall_3: 0.6916 - precision_3: 0.9006 - val_loss: 0.3989 - val_accuracy: 0.8013 - val_recall_3: 0.6840 - val_precision_3: 0.8972\n",
      "Epoch 225/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3892 - accuracy: 0.8096 - recall_3: 0.6950 - precision_3: 0.9007 - val_loss: 0.3988 - val_accuracy: 0.8009 - val_recall_3: 0.6864 - val_precision_3: 0.8938\n",
      "Epoch 226/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3882 - accuracy: 0.8093 - recall_3: 0.6970 - precision_3: 0.8981 - val_loss: 0.3989 - val_accuracy: 0.8006 - val_recall_3: 0.6713 - val_precision_3: 0.9092\n",
      "Epoch 227/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.8075 - recall_3: 0.6947 - precision_3: 0.8963 - val_loss: 0.3989 - val_accuracy: 0.8012 - val_recall_3: 0.6812 - val_precision_3: 0.9000\n",
      "Epoch 228/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3889 - accuracy: 0.8102 - recall_3: 0.6938 - precision_3: 0.9035 - val_loss: 0.3986 - val_accuracy: 0.8003 - val_recall_3: 0.6846 - val_precision_3: 0.8943\n",
      "Epoch 229/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8089 - recall_3: 0.6963 - precision_3: 0.8979 - val_loss: 0.3984 - val_accuracy: 0.8012 - val_recall_3: 0.6806 - val_precision_3: 0.9006\n",
      "Epoch 230/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3878 - accuracy: 0.8098 - recall_3: 0.6995 - precision_3: 0.8966 - val_loss: 0.3983 - val_accuracy: 0.8015 - val_recall_3: 0.6873 - val_precision_3: 0.8943\n",
      "Epoch 231/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8106 - recall_3: 0.6995 - precision_3: 0.8984 - val_loss: 0.3984 - val_accuracy: 0.8016 - val_recall_3: 0.6903 - val_precision_3: 0.8914\n",
      "Epoch 232/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3882 - accuracy: 0.8096 - recall_3: 0.7014 - precision_3: 0.8943 - val_loss: 0.3981 - val_accuracy: 0.8020 - val_recall_3: 0.6743 - val_precision_3: 0.9091\n",
      "Epoch 233/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8108 - recall_3: 0.7025 - precision_3: 0.8959 - val_loss: 0.3981 - val_accuracy: 0.8029 - val_recall_3: 0.6772 - val_precision_3: 0.9082\n",
      "Epoch 234/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8100 - recall_3: 0.7004 - precision_3: 0.8963 - val_loss: 0.3980 - val_accuracy: 0.8017 - val_recall_3: 0.6970 - val_precision_3: 0.8850\n",
      "Epoch 235/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3870 - accuracy: 0.8122 - recall_3: 0.7063 - precision_3: 0.8953 - val_loss: 0.3975 - val_accuracy: 0.8030 - val_recall_3: 0.6945 - val_precision_3: 0.8905\n",
      "Epoch 236/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8106 - recall_3: 0.7064 - precision_3: 0.8916 - val_loss: 0.3973 - val_accuracy: 0.8030 - val_recall_3: 0.6848 - val_precision_3: 0.9003\n",
      "Epoch 237/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3872 - accuracy: 0.8116 - recall_3: 0.7053 - precision_3: 0.8948 - val_loss: 0.3981 - val_accuracy: 0.8027 - val_recall_3: 0.6973 - val_precision_3: 0.8869\n",
      "Epoch 238/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3879 - accuracy: 0.8111 - recall_3: 0.7073 - precision_3: 0.8916 - val_loss: 0.3979 - val_accuracy: 0.8017 - val_recall_3: 0.6955 - val_precision_3: 0.8864\n",
      "Epoch 239/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3872 - accuracy: 0.8099 - recall_3: 0.7045 - precision_3: 0.8920 - val_loss: 0.3972 - val_accuracy: 0.8039 - val_recall_3: 0.6839 - val_precision_3: 0.9034\n",
      "Epoch 240/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8096 - recall_3: 0.7044 - precision_3: 0.8912 - val_loss: 0.3977 - val_accuracy: 0.8030 - val_recall_3: 0.6887 - val_precision_3: 0.8964\n",
      "Epoch 241/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8112 - recall_3: 0.7076 - precision_3: 0.8917 - val_loss: 0.3973 - val_accuracy: 0.8028 - val_recall_3: 0.6876 - val_precision_3: 0.8969\n",
      "Epoch 242/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8119 - recall_3: 0.7070 - precision_3: 0.8938 - val_loss: 0.3973 - val_accuracy: 0.8024 - val_recall_3: 0.7008 - val_precision_3: 0.8829\n",
      "Epoch 243/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3874 - accuracy: 0.8097 - recall_3: 0.7044 - precision_3: 0.8915 - val_loss: 0.3972 - val_accuracy: 0.8026 - val_recall_3: 0.6959 - val_precision_3: 0.8881\n",
      "Epoch 244/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8116 - recall_3: 0.7065 - precision_3: 0.8937 - val_loss: 0.3970 - val_accuracy: 0.8033 - val_recall_3: 0.6964 - val_precision_3: 0.8892\n",
      "Epoch 245/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3863 - accuracy: 0.8108 - recall_3: 0.7097 - precision_3: 0.8889 - val_loss: 0.3971 - val_accuracy: 0.8032 - val_recall_3: 0.6943 - val_precision_3: 0.8911\n",
      "Epoch 246/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8124 - recall_3: 0.7090 - precision_3: 0.8930 - val_loss: 0.3974 - val_accuracy: 0.8030 - val_recall_3: 0.7133 - val_precision_3: 0.8725\n",
      "Epoch 247/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8127 - recall_3: 0.7123 - precision_3: 0.8904 - val_loss: 0.3970 - val_accuracy: 0.8034 - val_recall_3: 0.6898 - val_precision_3: 0.8961\n",
      "Epoch 248/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8112 - recall_3: 0.7060 - precision_3: 0.8933 - val_loss: 0.3971 - val_accuracy: 0.8040 - val_recall_3: 0.7000 - val_precision_3: 0.8872\n",
      "Epoch 249/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3864 - accuracy: 0.8143 - recall_3: 0.7162 - precision_3: 0.8903 - val_loss: 0.3969 - val_accuracy: 0.8056 - val_recall_3: 0.6833 - val_precision_3: 0.9080\n",
      "Epoch 250/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3863 - accuracy: 0.8120 - recall_3: 0.7082 - precision_3: 0.8929 - val_loss: 0.3964 - val_accuracy: 0.8051 - val_recall_3: 0.7000 - val_precision_3: 0.8897\n",
      "Epoch 251/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3849 - accuracy: 0.8120 - recall_3: 0.7106 - precision_3: 0.8905 - val_loss: 0.3968 - val_accuracy: 0.8029 - val_recall_3: 0.7011 - val_precision_3: 0.8836\n",
      "Epoch 252/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8116 - recall_3: 0.7108 - precision_3: 0.8894 - val_loss: 0.3969 - val_accuracy: 0.8049 - val_recall_3: 0.6905 - val_precision_3: 0.8987\n",
      "Epoch 253/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8120 - recall_3: 0.7086 - precision_3: 0.8926 - val_loss: 0.3963 - val_accuracy: 0.8063 - val_recall_3: 0.7051 - val_precision_3: 0.8874\n",
      "Epoch 254/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8126 - recall_3: 0.7104 - precision_3: 0.8921 - val_loss: 0.3969 - val_accuracy: 0.8051 - val_recall_3: 0.6943 - val_precision_3: 0.8955\n",
      "Epoch 255/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8123 - recall_3: 0.7125 - precision_3: 0.8893 - val_loss: 0.3963 - val_accuracy: 0.8049 - val_recall_3: 0.6912 - val_precision_3: 0.8982\n",
      "Epoch 256/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8140 - recall_3: 0.7151 - precision_3: 0.8905 - val_loss: 0.3966 - val_accuracy: 0.8039 - val_recall_3: 0.6882 - val_precision_3: 0.8990\n",
      "Epoch 257/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3854 - accuracy: 0.8133 - recall_3: 0.7133 - precision_3: 0.8907 - val_loss: 0.3963 - val_accuracy: 0.8045 - val_recall_3: 0.6919 - val_precision_3: 0.8964\n",
      "Epoch 258/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8135 - recall_3: 0.7142 - precision_3: 0.8903 - val_loss: 0.3961 - val_accuracy: 0.8047 - val_recall_3: 0.6934 - val_precision_3: 0.8953\n",
      "Epoch 259/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3840 - accuracy: 0.8142 - recall_3: 0.7135 - precision_3: 0.8926 - val_loss: 0.3960 - val_accuracy: 0.8063 - val_recall_3: 0.7105 - val_precision_3: 0.8822\n",
      "Epoch 260/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3851 - accuracy: 0.8120 - recall_3: 0.7163 - precision_3: 0.8849 - val_loss: 0.3960 - val_accuracy: 0.8048 - val_recall_3: 0.6925 - val_precision_3: 0.8965\n",
      "Epoch 261/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8135 - recall_3: 0.7164 - precision_3: 0.8882 - val_loss: 0.3956 - val_accuracy: 0.8057 - val_recall_3: 0.6970 - val_precision_3: 0.8940\n",
      "Epoch 262/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8128 - recall_3: 0.7167 - precision_3: 0.8865 - val_loss: 0.3957 - val_accuracy: 0.8057 - val_recall_3: 0.6936 - val_precision_3: 0.8974\n",
      "Epoch 263/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3836 - accuracy: 0.8125 - recall_3: 0.7156 - precision_3: 0.8867 - val_loss: 0.3961 - val_accuracy: 0.8053 - val_recall_3: 0.7097 - val_precision_3: 0.8807\n",
      "Epoch 264/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8131 - recall_3: 0.7187 - precision_3: 0.8852 - val_loss: 0.3954 - val_accuracy: 0.8052 - val_recall_3: 0.6954 - val_precision_3: 0.8946\n",
      "Epoch 265/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8152 - recall_3: 0.7196 - precision_3: 0.8889 - val_loss: 0.3952 - val_accuracy: 0.8068 - val_recall_3: 0.6977 - val_precision_3: 0.8957\n",
      "Epoch 266/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8135 - recall_3: 0.7190 - precision_3: 0.8858 - val_loss: 0.3954 - val_accuracy: 0.8061 - val_recall_3: 0.7008 - val_precision_3: 0.8912\n",
      "Epoch 267/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3831 - accuracy: 0.8141 - recall_3: 0.7194 - precision_3: 0.8867 - val_loss: 0.3951 - val_accuracy: 0.8069 - val_recall_3: 0.7092 - val_precision_3: 0.8848\n",
      "Epoch 268/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3829 - accuracy: 0.8142 - recall_3: 0.7234 - precision_3: 0.8833 - val_loss: 0.3958 - val_accuracy: 0.8064 - val_recall_3: 0.7088 - val_precision_3: 0.8839\n",
      "Epoch 269/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8159 - recall_3: 0.7240 - precision_3: 0.8863 - val_loss: 0.3955 - val_accuracy: 0.8068 - val_recall_3: 0.7203 - val_precision_3: 0.8740\n",
      "Epoch 270/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3839 - accuracy: 0.8140 - recall_3: 0.7219 - precision_3: 0.8841 - val_loss: 0.3953 - val_accuracy: 0.8072 - val_recall_3: 0.7203 - val_precision_3: 0.8749\n",
      "Epoch 271/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 0.8155 - recall_3: 0.7282 - precision_3: 0.8815 - val_loss: 0.3950 - val_accuracy: 0.8071 - val_recall_3: 0.7051 - val_precision_3: 0.8892\n",
      "Epoch 272/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 0.8152 - recall_3: 0.7250 - precision_3: 0.8838 - val_loss: 0.3949 - val_accuracy: 0.8068 - val_recall_3: 0.7130 - val_precision_3: 0.8810\n",
      "Epoch 273/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8140 - recall_3: 0.7210 - precision_3: 0.8851 - val_loss: 0.3948 - val_accuracy: 0.8068 - val_recall_3: 0.7126 - val_precision_3: 0.8811\n",
      "Epoch 274/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8168 - recall_3: 0.7262 - precision_3: 0.8861 - val_loss: 0.3950 - val_accuracy: 0.8072 - val_recall_3: 0.7112 - val_precision_3: 0.8835\n",
      "Epoch 275/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3825 - accuracy: 0.8154 - recall_3: 0.7250 - precision_3: 0.8843 - val_loss: 0.3948 - val_accuracy: 0.8065 - val_recall_3: 0.7009 - val_precision_3: 0.8918\n",
      "Epoch 276/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3819 - accuracy: 0.8140 - recall_3: 0.7221 - precision_3: 0.8840 - val_loss: 0.3948 - val_accuracy: 0.8079 - val_recall_3: 0.7103 - val_precision_3: 0.8859\n",
      "Epoch 277/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3824 - accuracy: 0.8149 - recall_3: 0.7216 - precision_3: 0.8863 - val_loss: 0.3950 - val_accuracy: 0.8082 - val_recall_3: 0.7153 - val_precision_3: 0.8817\n",
      "Epoch 278/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.8163 - recall_3: 0.7284 - precision_3: 0.8829 - val_loss: 0.3945 - val_accuracy: 0.8076 - val_recall_3: 0.7124 - val_precision_3: 0.8830\n",
      "Epoch 279/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8173 - recall_3: 0.7284 - precision_3: 0.8852 - val_loss: 0.3943 - val_accuracy: 0.8082 - val_recall_3: 0.7211 - val_precision_3: 0.8764\n",
      "Epoch 280/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8162 - recall_3: 0.7279 - precision_3: 0.8834 - val_loss: 0.3941 - val_accuracy: 0.8091 - val_recall_3: 0.7058 - val_precision_3: 0.8929\n",
      "Epoch 281/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8155 - recall_3: 0.7259 - precision_3: 0.8836 - val_loss: 0.3943 - val_accuracy: 0.8076 - val_recall_3: 0.7112 - val_precision_3: 0.8842\n",
      "Epoch 282/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8173 - recall_3: 0.7284 - precision_3: 0.8851 - val_loss: 0.3944 - val_accuracy: 0.8069 - val_recall_3: 0.7106 - val_precision_3: 0.8834\n",
      "Epoch 283/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8185 - recall_3: 0.7318 - precision_3: 0.8844 - val_loss: 0.3947 - val_accuracy: 0.8093 - val_recall_3: 0.7281 - val_precision_3: 0.8723\n",
      "Epoch 284/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8160 - recall_3: 0.7313 - precision_3: 0.8797 - val_loss: 0.3944 - val_accuracy: 0.8089 - val_recall_3: 0.7168 - val_precision_3: 0.8819\n",
      "Epoch 285/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.8157 - recall_3: 0.7274 - precision_3: 0.8826 - val_loss: 0.3944 - val_accuracy: 0.8094 - val_recall_3: 0.7238 - val_precision_3: 0.8764\n",
      "Epoch 286/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8166 - recall_3: 0.7331 - precision_3: 0.8794 - val_loss: 0.3946 - val_accuracy: 0.8074 - val_recall_3: 0.7135 - val_precision_3: 0.8816\n",
      "Epoch 287/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3821 - accuracy: 0.8178 - recall_3: 0.7286 - precision_3: 0.8860 - val_loss: 0.3947 - val_accuracy: 0.8089 - val_recall_3: 0.7230 - val_precision_3: 0.8761\n",
      "Epoch 288/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3818 - accuracy: 0.8166 - recall_3: 0.7300 - precision_3: 0.8823 - val_loss: 0.3937 - val_accuracy: 0.8088 - val_recall_3: 0.7121 - val_precision_3: 0.8862\n",
      "Epoch 289/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8164 - recall_3: 0.7285 - precision_3: 0.8831 - val_loss: 0.3938 - val_accuracy: 0.8083 - val_recall_3: 0.7142 - val_precision_3: 0.8829\n",
      "Epoch 290/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8153 - recall_3: 0.7285 - precision_3: 0.8808 - val_loss: 0.3935 - val_accuracy: 0.8097 - val_recall_3: 0.7245 - val_precision_3: 0.8763\n",
      "Epoch 291/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8162 - recall_3: 0.7288 - precision_3: 0.8825 - val_loss: 0.3941 - val_accuracy: 0.8089 - val_recall_3: 0.7187 - val_precision_3: 0.8801\n",
      "Epoch 292/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3800 - accuracy: 0.8166 - recall_3: 0.7283 - precision_3: 0.8838 - val_loss: 0.3939 - val_accuracy: 0.8081 - val_recall_3: 0.7070 - val_precision_3: 0.8894\n",
      "Epoch 293/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8178 - recall_3: 0.7327 - precision_3: 0.8822 - val_loss: 0.3932 - val_accuracy: 0.8094 - val_recall_3: 0.7157 - val_precision_3: 0.8839\n",
      "Epoch 294/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8182 - recall_3: 0.7340 - precision_3: 0.8819 - val_loss: 0.3933 - val_accuracy: 0.8095 - val_recall_3: 0.7196 - val_precision_3: 0.8804\n",
      "Epoch 295/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3805 - accuracy: 0.8172 - recall_3: 0.7330 - precision_3: 0.8807 - val_loss: 0.3933 - val_accuracy: 0.8083 - val_recall_3: 0.7099 - val_precision_3: 0.8870\n",
      "Epoch 296/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8162 - recall_3: 0.7298 - precision_3: 0.8815 - val_loss: 0.3931 - val_accuracy: 0.8087 - val_recall_3: 0.7184 - val_precision_3: 0.8800\n",
      "Epoch 297/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3804 - accuracy: 0.8155 - recall_3: 0.7305 - precision_3: 0.8794 - val_loss: 0.3929 - val_accuracy: 0.8093 - val_recall_3: 0.7218 - val_precision_3: 0.8780\n",
      "Epoch 298/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3794 - accuracy: 0.8190 - recall_3: 0.7374 - precision_3: 0.8804 - val_loss: 0.3931 - val_accuracy: 0.8096 - val_recall_3: 0.7263 - val_precision_3: 0.8745\n",
      "Epoch 299/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8187 - recall_3: 0.7359 - precision_3: 0.8811 - val_loss: 0.3931 - val_accuracy: 0.8091 - val_recall_3: 0.7227 - val_precision_3: 0.8768\n",
      "Epoch 300/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3791 - accuracy: 0.8190 - recall_3: 0.7373 - precision_3: 0.8806 - val_loss: 0.3930 - val_accuracy: 0.8101 - val_recall_3: 0.7223 - val_precision_3: 0.8792\n",
      "Epoch 301/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.8171 - recall_3: 0.7325 - precision_3: 0.8810 - val_loss: 0.3933 - val_accuracy: 0.8097 - val_recall_3: 0.7311 - val_precision_3: 0.8705\n",
      "Epoch 302/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8192 - recall_3: 0.7341 - precision_3: 0.8839 - val_loss: 0.3927 - val_accuracy: 0.8095 - val_recall_3: 0.7315 - val_precision_3: 0.8697\n",
      "Epoch 303/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8173 - recall_3: 0.7365 - precision_3: 0.8777 - val_loss: 0.3928 - val_accuracy: 0.8078 - val_recall_3: 0.7142 - val_precision_3: 0.8819\n",
      "Epoch 304/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8188 - recall_3: 0.7349 - precision_3: 0.8824 - val_loss: 0.3929 - val_accuracy: 0.8084 - val_recall_3: 0.7227 - val_precision_3: 0.8753\n",
      "Epoch 305/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8185 - recall_3: 0.7361 - precision_3: 0.8806 - val_loss: 0.3928 - val_accuracy: 0.8091 - val_recall_3: 0.7191 - val_precision_3: 0.8801\n",
      "Epoch 306/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8170 - recall_3: 0.7350 - precision_3: 0.8784 - val_loss: 0.3929 - val_accuracy: 0.8099 - val_recall_3: 0.7362 - val_precision_3: 0.8665\n",
      "Epoch 307/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3782 - accuracy: 0.8183 - recall_3: 0.7383 - precision_3: 0.8782 - val_loss: 0.3929 - val_accuracy: 0.8086 - val_recall_3: 0.7207 - val_precision_3: 0.8775\n",
      "Epoch 308/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8184 - recall_3: 0.7347 - precision_3: 0.8816 - val_loss: 0.3925 - val_accuracy: 0.8088 - val_recall_3: 0.7290 - val_precision_3: 0.8706\n",
      "Epoch 309/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3800 - accuracy: 0.8180 - recall_3: 0.7360 - precision_3: 0.8797 - val_loss: 0.3927 - val_accuracy: 0.8094 - val_recall_3: 0.7277 - val_precision_3: 0.8728\n",
      "Epoch 310/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3790 - accuracy: 0.8186 - recall_3: 0.7375 - precision_3: 0.8795 - val_loss: 0.3923 - val_accuracy: 0.8097 - val_recall_3: 0.7185 - val_precision_3: 0.8818\n",
      "Epoch 311/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8195 - recall_3: 0.7387 - precision_3: 0.8804 - val_loss: 0.3927 - val_accuracy: 0.8093 - val_recall_3: 0.7336 - val_precision_3: 0.8674\n",
      "Epoch 312/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3790 - accuracy: 0.8197 - recall_3: 0.7372 - precision_3: 0.8823 - val_loss: 0.3925 - val_accuracy: 0.8097 - val_recall_3: 0.7254 - val_precision_3: 0.8757\n",
      "Epoch 313/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8187 - recall_3: 0.7398 - precision_3: 0.8777 - val_loss: 0.3923 - val_accuracy: 0.8092 - val_recall_3: 0.7239 - val_precision_3: 0.8758\n",
      "Epoch 314/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8209 - recall_3: 0.7421 - precision_3: 0.8801 - val_loss: 0.3919 - val_accuracy: 0.8097 - val_recall_3: 0.7257 - val_precision_3: 0.8754\n",
      "Epoch 315/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3801 - accuracy: 0.8184 - recall_3: 0.7390 - precision_3: 0.8778 - val_loss: 0.3923 - val_accuracy: 0.8087 - val_recall_3: 0.7290 - val_precision_3: 0.8702\n",
      "Epoch 316/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3790 - accuracy: 0.8197 - recall_3: 0.7413 - precision_3: 0.8785 - val_loss: 0.3919 - val_accuracy: 0.8114 - val_recall_3: 0.7252 - val_precision_3: 0.8793\n",
      "Epoch 317/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8214 - recall_3: 0.7439 - precision_3: 0.8798 - val_loss: 0.3920 - val_accuracy: 0.8108 - val_recall_3: 0.7279 - val_precision_3: 0.8757\n",
      "Epoch 318/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8195 - recall_3: 0.7420 - precision_3: 0.8774 - val_loss: 0.3921 - val_accuracy: 0.8099 - val_recall_3: 0.7207 - val_precision_3: 0.8804\n",
      "Epoch 319/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3786 - accuracy: 0.8183 - recall_3: 0.7387 - precision_3: 0.8777 - val_loss: 0.3916 - val_accuracy: 0.8112 - val_recall_3: 0.7333 - val_precision_3: 0.8716\n",
      "Epoch 320/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3777 - accuracy: 0.8208 - recall_3: 0.7430 - precision_3: 0.8792 - val_loss: 0.3916 - val_accuracy: 0.8103 - val_recall_3: 0.7284 - val_precision_3: 0.8741\n",
      "Epoch 321/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3791 - accuracy: 0.8185 - recall_3: 0.7383 - precision_3: 0.8786 - val_loss: 0.3917 - val_accuracy: 0.8109 - val_recall_3: 0.7347 - val_precision_3: 0.8698\n",
      "Epoch 322/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3768 - accuracy: 0.8213 - recall_3: 0.7447 - precision_3: 0.8788 - val_loss: 0.3918 - val_accuracy: 0.8105 - val_recall_3: 0.7270 - val_precision_3: 0.8757\n",
      "Epoch 323/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8192 - recall_3: 0.7413 - precision_3: 0.8774 - val_loss: 0.3913 - val_accuracy: 0.8108 - val_recall_3: 0.7295 - val_precision_3: 0.8742\n",
      "Epoch 324/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3786 - accuracy: 0.8200 - recall_3: 0.7430 - precision_3: 0.8775 - val_loss: 0.3919 - val_accuracy: 0.8087 - val_recall_3: 0.7173 - val_precision_3: 0.8808\n",
      "Epoch 325/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8203 - recall_3: 0.7418 - precision_3: 0.8793 - val_loss: 0.3919 - val_accuracy: 0.8095 - val_recall_3: 0.7338 - val_precision_3: 0.8676\n",
      "Epoch 326/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3792 - accuracy: 0.8211 - recall_3: 0.7471 - precision_3: 0.8762 - val_loss: 0.3909 - val_accuracy: 0.8102 - val_recall_3: 0.7185 - val_precision_3: 0.8830\n",
      "Epoch 327/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8196 - recall_3: 0.7425 - precision_3: 0.8771 - val_loss: 0.3918 - val_accuracy: 0.8094 - val_recall_3: 0.7256 - val_precision_3: 0.8748\n",
      "Epoch 328/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8200 - recall_3: 0.7420 - precision_3: 0.8784 - val_loss: 0.3908 - val_accuracy: 0.8120 - val_recall_3: 0.7349 - val_precision_3: 0.8719\n",
      "Epoch 329/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8191 - recall_3: 0.7409 - precision_3: 0.8776 - val_loss: 0.3914 - val_accuracy: 0.8104 - val_recall_3: 0.7469 - val_precision_3: 0.8583\n",
      "Epoch 330/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8221 - recall_3: 0.7462 - precision_3: 0.8791 - val_loss: 0.3912 - val_accuracy: 0.8112 - val_recall_3: 0.7403 - val_precision_3: 0.8655\n",
      "Epoch 331/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8215 - recall_3: 0.7472 - precision_3: 0.8769 - val_loss: 0.3910 - val_accuracy: 0.8107 - val_recall_3: 0.7299 - val_precision_3: 0.8737\n",
      "Epoch 332/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3759 - accuracy: 0.8221 - recall_3: 0.7464 - precision_3: 0.8788 - val_loss: 0.3909 - val_accuracy: 0.8105 - val_recall_3: 0.7202 - val_precision_3: 0.8820\n",
      "Epoch 333/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3783 - accuracy: 0.8209 - recall_3: 0.7471 - precision_3: 0.8758 - val_loss: 0.3911 - val_accuracy: 0.8097 - val_recall_3: 0.7189 - val_precision_3: 0.8814\n",
      "Epoch 334/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.8220 - recall_3: 0.7470 - precision_3: 0.8780 - val_loss: 0.3910 - val_accuracy: 0.8115 - val_recall_3: 0.7304 - val_precision_3: 0.8747\n",
      "Epoch 335/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8206 - recall_3: 0.7479 - precision_3: 0.8744 - val_loss: 0.3917 - val_accuracy: 0.8103 - val_recall_3: 0.7236 - val_precision_3: 0.8785\n",
      "Epoch 336/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3765 - accuracy: 0.8215 - recall_3: 0.7440 - precision_3: 0.8798 - val_loss: 0.3906 - val_accuracy: 0.8122 - val_recall_3: 0.7484 - val_precision_3: 0.8607\n",
      "Epoch 337/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3774 - accuracy: 0.8216 - recall_3: 0.7459 - precision_3: 0.8783 - val_loss: 0.3905 - val_accuracy: 0.8117 - val_recall_3: 0.7423 - val_precision_3: 0.8649\n",
      "Epoch 338/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8208 - recall_3: 0.7481 - precision_3: 0.8746 - val_loss: 0.3909 - val_accuracy: 0.8106 - val_recall_3: 0.7335 - val_precision_3: 0.8701\n",
      "Epoch 339/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3770 - accuracy: 0.8241 - recall_3: 0.7513 - precision_3: 0.8786 - val_loss: 0.3909 - val_accuracy: 0.8101 - val_recall_3: 0.7304 - val_precision_3: 0.8719\n",
      "Epoch 340/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8215 - recall_3: 0.7499 - precision_3: 0.8746 - val_loss: 0.3907 - val_accuracy: 0.8108 - val_recall_3: 0.7383 - val_precision_3: 0.8665\n",
      "Epoch 341/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3759 - accuracy: 0.8212 - recall_3: 0.7482 - precision_3: 0.8753 - val_loss: 0.3907 - val_accuracy: 0.8109 - val_recall_3: 0.7274 - val_precision_3: 0.8764\n",
      "Epoch 342/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8221 - recall_3: 0.7479 - precision_3: 0.8774 - val_loss: 0.3904 - val_accuracy: 0.8102 - val_recall_3: 0.7333 - val_precision_3: 0.8696\n",
      "Epoch 343/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8219 - recall_3: 0.7499 - precision_3: 0.8754 - val_loss: 0.3909 - val_accuracy: 0.8113 - val_recall_3: 0.7486 - val_precision_3: 0.8588\n",
      "Epoch 344/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3778 - accuracy: 0.8214 - recall_3: 0.7488 - precision_3: 0.8752 - val_loss: 0.3908 - val_accuracy: 0.8104 - val_recall_3: 0.7354 - val_precision_3: 0.8681\n",
      "Epoch 345/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3765 - accuracy: 0.8228 - recall_3: 0.7521 - precision_3: 0.8754 - val_loss: 0.3901 - val_accuracy: 0.8107 - val_recall_3: 0.7336 - val_precision_3: 0.8704\n",
      "Epoch 346/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3756 - accuracy: 0.8202 - recall_3: 0.7464 - precision_3: 0.8750 - val_loss: 0.3902 - val_accuracy: 0.8113 - val_recall_3: 0.7286 - val_precision_3: 0.8760\n",
      "Epoch 347/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8225 - recall_3: 0.7477 - precision_3: 0.8786 - val_loss: 0.3901 - val_accuracy: 0.8120 - val_recall_3: 0.7372 - val_precision_3: 0.8698\n",
      "Epoch 348/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3760 - accuracy: 0.8230 - recall_3: 0.7504 - precision_3: 0.8771 - val_loss: 0.3902 - val_accuracy: 0.8105 - val_recall_3: 0.7256 - val_precision_3: 0.8770\n",
      "Epoch 349/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8223 - recall_3: 0.7494 - precision_3: 0.8768 - val_loss: 0.3901 - val_accuracy: 0.8115 - val_recall_3: 0.7324 - val_precision_3: 0.8730\n",
      "Epoch 350/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8223 - recall_3: 0.7497 - precision_3: 0.8764 - val_loss: 0.3898 - val_accuracy: 0.8118 - val_recall_3: 0.7363 - val_precision_3: 0.8702\n",
      "Epoch 351/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3753 - accuracy: 0.8224 - recall_3: 0.7495 - precision_3: 0.8767 - val_loss: 0.3902 - val_accuracy: 0.8129 - val_recall_3: 0.7403 - val_precision_3: 0.8690\n",
      "Epoch 352/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3766 - accuracy: 0.8226 - recall_3: 0.7520 - precision_3: 0.8749 - val_loss: 0.3901 - val_accuracy: 0.8127 - val_recall_3: 0.7362 - val_precision_3: 0.8722\n",
      "Epoch 353/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8217 - recall_3: 0.7476 - precision_3: 0.8770 - val_loss: 0.3899 - val_accuracy: 0.8124 - val_recall_3: 0.7412 - val_precision_3: 0.8671\n",
      "Epoch 354/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8211 - recall_3: 0.7457 - precision_3: 0.8773 - val_loss: 0.3898 - val_accuracy: 0.8111 - val_recall_3: 0.7414 - val_precision_3: 0.8644\n",
      "Epoch 355/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3752 - accuracy: 0.8232 - recall_3: 0.7519 - precision_3: 0.8763 - val_loss: 0.3899 - val_accuracy: 0.8132 - val_recall_3: 0.7419 - val_precision_3: 0.8681\n",
      "Epoch 356/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3762 - accuracy: 0.8221 - recall_3: 0.7516 - precision_3: 0.8743 - val_loss: 0.3903 - val_accuracy: 0.8129 - val_recall_3: 0.7477 - val_precision_3: 0.8627\n",
      "Epoch 357/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3753 - accuracy: 0.8244 - recall_3: 0.7529 - precision_3: 0.8778 - val_loss: 0.3898 - val_accuracy: 0.8126 - val_recall_3: 0.7451 - val_precision_3: 0.8643\n",
      "Epoch 358/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3767 - accuracy: 0.8220 - recall_3: 0.7491 - precision_3: 0.8763 - val_loss: 0.3900 - val_accuracy: 0.8118 - val_recall_3: 0.7489 - val_precision_3: 0.8595\n",
      "Epoch 359/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3749 - accuracy: 0.8225 - recall_3: 0.7527 - precision_3: 0.8740 - val_loss: 0.3897 - val_accuracy: 0.8129 - val_recall_3: 0.7340 - val_precision_3: 0.8745\n",
      "Epoch 360/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8236 - recall_3: 0.7503 - precision_3: 0.8785 - val_loss: 0.3899 - val_accuracy: 0.8126 - val_recall_3: 0.7550 - val_precision_3: 0.8561\n",
      "Epoch 361/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3753 - accuracy: 0.8240 - recall_3: 0.7539 - precision_3: 0.8760 - val_loss: 0.3904 - val_accuracy: 0.8129 - val_recall_3: 0.7568 - val_precision_3: 0.8552\n",
      "Epoch 362/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8225 - recall_3: 0.7519 - precision_3: 0.8748 - val_loss: 0.3898 - val_accuracy: 0.8133 - val_recall_3: 0.7356 - val_precision_3: 0.8738\n",
      "Epoch 363/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3743 - accuracy: 0.8233 - recall_3: 0.7514 - precision_3: 0.8768 - val_loss: 0.3900 - val_accuracy: 0.8140 - val_recall_3: 0.7487 - val_precision_3: 0.8640\n",
      "Epoch 364/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8227 - recall_3: 0.7509 - precision_3: 0.8761 - val_loss: 0.3895 - val_accuracy: 0.8138 - val_recall_3: 0.7441 - val_precision_3: 0.8676\n",
      "Epoch 365/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3759 - accuracy: 0.8221 - recall_3: 0.7477 - precision_3: 0.8778 - val_loss: 0.3898 - val_accuracy: 0.8124 - val_recall_3: 0.7432 - val_precision_3: 0.8654\n",
      "Epoch 366/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8235 - recall_3: 0.7556 - precision_3: 0.8736 - val_loss: 0.3897 - val_accuracy: 0.8119 - val_recall_3: 0.7320 - val_precision_3: 0.8742\n",
      "Epoch 367/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3736 - accuracy: 0.8246 - recall_3: 0.7570 - precision_3: 0.8748 - val_loss: 0.3892 - val_accuracy: 0.8135 - val_recall_3: 0.7417 - val_precision_3: 0.8688\n",
      "Epoch 368/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8249 - recall_3: 0.7578 - precision_3: 0.8745 - val_loss: 0.3894 - val_accuracy: 0.8138 - val_recall_3: 0.7392 - val_precision_3: 0.8718\n",
      "Epoch 369/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3744 - accuracy: 0.8230 - recall_3: 0.7539 - precision_3: 0.8741 - val_loss: 0.3895 - val_accuracy: 0.8138 - val_recall_3: 0.7453 - val_precision_3: 0.8665\n",
      "Epoch 370/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3734 - accuracy: 0.8255 - recall_3: 0.7556 - precision_3: 0.8777 - val_loss: 0.3895 - val_accuracy: 0.8114 - val_recall_3: 0.7322 - val_precision_3: 0.8729\n",
      "Epoch 371/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8230 - recall_3: 0.7562 - precision_3: 0.8722 - val_loss: 0.3892 - val_accuracy: 0.8124 - val_recall_3: 0.7344 - val_precision_3: 0.8731\n",
      "Epoch 372/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3747 - accuracy: 0.8245 - recall_3: 0.7552 - precision_3: 0.8761 - val_loss: 0.3892 - val_accuracy: 0.8126 - val_recall_3: 0.7380 - val_precision_3: 0.8703\n",
      "Epoch 373/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3753 - accuracy: 0.8225 - recall_3: 0.7532 - precision_3: 0.8736 - val_loss: 0.3899 - val_accuracy: 0.8121 - val_recall_3: 0.7304 - val_precision_3: 0.8761\n",
      "Epoch 374/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8225 - recall_3: 0.7492 - precision_3: 0.8772 - val_loss: 0.3888 - val_accuracy: 0.8146 - val_recall_3: 0.7430 - val_precision_3: 0.8701\n",
      "Epoch 375/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8216 - recall_3: 0.7498 - precision_3: 0.8747 - val_loss: 0.3898 - val_accuracy: 0.8145 - val_recall_3: 0.7451 - val_precision_3: 0.8679\n",
      "Epoch 376/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3750 - accuracy: 0.8231 - recall_3: 0.7534 - precision_3: 0.8748 - val_loss: 0.3883 - val_accuracy: 0.8162 - val_recall_3: 0.7475 - val_precision_3: 0.8694\n",
      "Epoch 377/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8235 - recall_3: 0.7555 - precision_3: 0.8738 - val_loss: 0.3884 - val_accuracy: 0.8152 - val_recall_3: 0.7437 - val_precision_3: 0.8706\n",
      "Epoch 378/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8238 - recall_3: 0.7563 - precision_3: 0.8736 - val_loss: 0.3892 - val_accuracy: 0.8125 - val_recall_3: 0.7270 - val_precision_3: 0.8799\n",
      "Epoch 379/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8234 - recall_3: 0.7540 - precision_3: 0.8749 - val_loss: 0.3888 - val_accuracy: 0.8137 - val_recall_3: 0.7392 - val_precision_3: 0.8716\n",
      "Epoch 380/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3741 - accuracy: 0.8239 - recall_3: 0.7560 - precision_3: 0.8742 - val_loss: 0.3894 - val_accuracy: 0.8145 - val_recall_3: 0.7495 - val_precision_3: 0.8642\n",
      "Epoch 381/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8244 - recall_3: 0.7573 - precision_3: 0.8740 - val_loss: 0.3887 - val_accuracy: 0.8146 - val_recall_3: 0.7416 - val_precision_3: 0.8714\n",
      "Epoch 382/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3728 - accuracy: 0.8246 - recall_3: 0.7555 - precision_3: 0.8760 - val_loss: 0.3884 - val_accuracy: 0.8147 - val_recall_3: 0.7477 - val_precision_3: 0.8663\n",
      "Epoch 383/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8233 - recall_3: 0.7551 - precision_3: 0.8736 - val_loss: 0.3885 - val_accuracy: 0.8145 - val_recall_3: 0.7408 - val_precision_3: 0.8718\n",
      "Epoch 384/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8236 - recall_3: 0.7560 - precision_3: 0.8736 - val_loss: 0.3879 - val_accuracy: 0.8150 - val_recall_3: 0.7398 - val_precision_3: 0.8737\n",
      "Epoch 385/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8250 - recall_3: 0.7564 - precision_3: 0.8759 - val_loss: 0.3885 - val_accuracy: 0.8133 - val_recall_3: 0.7315 - val_precision_3: 0.8775\n",
      "Epoch 386/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8242 - recall_3: 0.7529 - precision_3: 0.8775 - val_loss: 0.3885 - val_accuracy: 0.8145 - val_recall_3: 0.7401 - val_precision_3: 0.8723\n",
      "Epoch 387/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8238 - recall_3: 0.7561 - precision_3: 0.8739 - val_loss: 0.3882 - val_accuracy: 0.8150 - val_recall_3: 0.7437 - val_precision_3: 0.8702\n",
      "Epoch 388/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3728 - accuracy: 0.8244 - recall_3: 0.7574 - precision_3: 0.8740 - val_loss: 0.3886 - val_accuracy: 0.8140 - val_recall_3: 0.7385 - val_precision_3: 0.8728\n",
      "Epoch 389/500\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.3744 - accuracy: 0.8245 - recall_3: 0.7590 - precision_3: 0.8728 - val_loss: 0.3886 - val_accuracy: 0.8148 - val_recall_3: 0.7527 - val_precision_3: 0.8623\n",
      "Epoch 390/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8250 - recall_3: 0.7545 - precision_3: 0.8777 - val_loss: 0.3884 - val_accuracy: 0.8152 - val_recall_3: 0.7425 - val_precision_3: 0.8717\n",
      "Epoch 391/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8237 - recall_3: 0.7553 - precision_3: 0.8742 - val_loss: 0.3890 - val_accuracy: 0.8140 - val_recall_3: 0.7457 - val_precision_3: 0.8665\n",
      "Epoch 392/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8243 - recall_3: 0.7573 - precision_3: 0.8739 - val_loss: 0.3885 - val_accuracy: 0.8152 - val_recall_3: 0.7486 - val_precision_3: 0.8664\n",
      "Epoch 393/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8245 - recall_3: 0.7567 - precision_3: 0.8748 - val_loss: 0.3883 - val_accuracy: 0.8142 - val_recall_3: 0.7444 - val_precision_3: 0.8680\n",
      "Epoch 394/500\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 0.3720 - accuracy: 0.8243 - recall_3: 0.7567 - precision_3: 0.8743 - val_loss: 0.3881 - val_accuracy: 0.8162 - val_recall_3: 0.7448 - val_precision_3: 0.8717\n",
      "1381/1381 [==============================] - 1s 725us/step\n",
      "346/346 [==============================] - 0s 768us/step\n",
      "Acurácia no conjunto de treinamento: 0.8380385041236877\n",
      "Acurácia no conjunto de teste: 0.8149959444999695\n",
      "AUC no conjunto de treinamento: 0.927853044306125\n",
      "AUC no conjunto de teste: 0.9061876540831871\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.0005)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.0005)))\n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.0005)))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Mantendo a taxa de aprendizado e o tamanho do batch do último ajuste\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Aumentando a paciência no EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Paciência aumentada para permitir mais treinamento\n",
    "\n",
    "# Treinando o modelo com mais épocas\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64,  # Aumento do número de épocas\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 705us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.77      0.89      0.83      5479\n",
      "    Classe 1       0.87      0.74      0.80      5564\n",
      "\n",
      "    accuracy                           0.81     11043\n",
      "   macro avg       0.82      0.82      0.81     11043\n",
      "weighted avg       0.82      0.81      0.81     11043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 727us/step\n",
      "Threshold: 0.10, Precision: 0.605, Recall: 0.992, F1 Score: 0.752, Accuracy: 0.669\n",
      "Threshold: 0.11, Precision: 0.608, Recall: 0.992, F1 Score: 0.754, Accuracy: 0.673\n",
      "Threshold: 0.12, Precision: 0.612, Recall: 0.991, F1 Score: 0.756, Accuracy: 0.678\n",
      "Threshold: 0.13, Precision: 0.614, Recall: 0.991, F1 Score: 0.759, Accuracy: 0.682\n",
      "Threshold: 0.14, Precision: 0.618, Recall: 0.989, F1 Score: 0.761, Accuracy: 0.686\n",
      "Threshold: 0.15, Precision: 0.621, Recall: 0.988, F1 Score: 0.763, Accuracy: 0.691\n",
      "Threshold: 0.16, Precision: 0.625, Recall: 0.986, F1 Score: 0.765, Accuracy: 0.695\n",
      "Threshold: 0.17, Precision: 0.629, Recall: 0.984, F1 Score: 0.767, Accuracy: 0.699\n",
      "Threshold: 0.18, Precision: 0.634, Recall: 0.982, F1 Score: 0.770, Accuracy: 0.705\n",
      "Threshold: 0.19, Precision: 0.638, Recall: 0.978, F1 Score: 0.773, Accuracy: 0.710\n",
      "Threshold: 0.20, Precision: 0.643, Recall: 0.976, F1 Score: 0.775, Accuracy: 0.715\n",
      "Threshold: 0.21, Precision: 0.649, Recall: 0.974, F1 Score: 0.779, Accuracy: 0.721\n",
      "Threshold: 0.22, Precision: 0.655, Recall: 0.970, F1 Score: 0.782, Accuracy: 0.727\n",
      "Threshold: 0.23, Precision: 0.660, Recall: 0.967, F1 Score: 0.784, Accuracy: 0.732\n",
      "Threshold: 0.24, Precision: 0.665, Recall: 0.961, F1 Score: 0.786, Accuracy: 0.736\n",
      "Threshold: 0.25, Precision: 0.670, Recall: 0.957, F1 Score: 0.788, Accuracy: 0.741\n",
      "Threshold: 0.26, Precision: 0.675, Recall: 0.951, F1 Score: 0.789, Accuracy: 0.744\n",
      "Threshold: 0.27, Precision: 0.680, Recall: 0.946, F1 Score: 0.792, Accuracy: 0.749\n",
      "Threshold: 0.28, Precision: 0.686, Recall: 0.941, F1 Score: 0.794, Accuracy: 0.753\n",
      "Threshold: 0.29, Precision: 0.692, Recall: 0.935, F1 Score: 0.796, Accuracy: 0.758\n",
      "Threshold: 0.30, Precision: 0.698, Recall: 0.930, F1 Score: 0.798, Accuracy: 0.762\n",
      "Threshold: 0.31, Precision: 0.706, Recall: 0.924, F1 Score: 0.800, Accuracy: 0.767\n",
      "Threshold: 0.32, Precision: 0.711, Recall: 0.917, F1 Score: 0.801, Accuracy: 0.771\n",
      "Threshold: 0.33, Precision: 0.718, Recall: 0.911, F1 Score: 0.803, Accuracy: 0.775\n",
      "Threshold: 0.34, Precision: 0.725, Recall: 0.902, F1 Score: 0.804, Accuracy: 0.778\n",
      "Threshold: 0.35, Precision: 0.732, Recall: 0.895, F1 Score: 0.805, Accuracy: 0.782\n",
      "Threshold: 0.36, Precision: 0.740, Recall: 0.888, F1 Score: 0.807, Accuracy: 0.786\n",
      "Threshold: 0.37, Precision: 0.748, Recall: 0.880, F1 Score: 0.809, Accuracy: 0.790\n",
      "Threshold: 0.38, Precision: 0.757, Recall: 0.870, F1 Score: 0.810, Accuracy: 0.794\n",
      "Threshold: 0.39, Precision: 0.765, Recall: 0.860, F1 Score: 0.809, Accuracy: 0.796\n",
      "Threshold: 0.40, Precision: 0.772, Recall: 0.850, F1 Score: 0.809, Accuracy: 0.798\n",
      "Threshold: 0.41, Precision: 0.783, Recall: 0.841, F1 Score: 0.811, Accuracy: 0.802\n",
      "Threshold: 0.42, Precision: 0.793, Recall: 0.829, F1 Score: 0.810, Accuracy: 0.805\n",
      "Threshold: 0.43, Precision: 0.804, Recall: 0.820, F1 Score: 0.812, Accuracy: 0.808\n",
      "Threshold: 0.44, Precision: 0.816, Recall: 0.811, F1 Score: 0.813, Accuracy: 0.812\n",
      "Threshold: 0.45, Precision: 0.824, Recall: 0.799, F1 Score: 0.811, Accuracy: 0.813\n",
      "Threshold: 0.46, Precision: 0.834, Recall: 0.787, F1 Score: 0.810, Accuracy: 0.814\n",
      "Threshold: 0.47, Precision: 0.844, Recall: 0.777, F1 Score: 0.809, Accuracy: 0.815\n",
      "Threshold: 0.48, Precision: 0.853, Recall: 0.766, F1 Score: 0.807, Accuracy: 0.816\n",
      "Threshold: 0.49, Precision: 0.865, Recall: 0.753, F1 Score: 0.805, Accuracy: 0.816\n",
      "Threshold: 0.50, Precision: 0.874, Recall: 0.740, F1 Score: 0.801, Accuracy: 0.815\n",
      "Threshold: 0.51, Precision: 0.880, Recall: 0.729, F1 Score: 0.798, Accuracy: 0.814\n",
      "Threshold: 0.52, Precision: 0.890, Recall: 0.719, F1 Score: 0.795, Accuracy: 0.814\n",
      "Threshold: 0.53, Precision: 0.898, Recall: 0.707, F1 Score: 0.791, Accuracy: 0.812\n",
      "Threshold: 0.54, Precision: 0.907, Recall: 0.699, F1 Score: 0.789, Accuracy: 0.812\n",
      "Threshold: 0.55, Precision: 0.915, Recall: 0.689, F1 Score: 0.786, Accuracy: 0.811\n",
      "Threshold: 0.56, Precision: 0.920, Recall: 0.678, F1 Score: 0.781, Accuracy: 0.808\n",
      "Threshold: 0.57, Precision: 0.927, Recall: 0.670, F1 Score: 0.778, Accuracy: 0.807\n",
      "Threshold: 0.58, Precision: 0.934, Recall: 0.664, F1 Score: 0.776, Accuracy: 0.807\n",
      "Threshold: 0.59, Precision: 0.942, Recall: 0.657, F1 Score: 0.774, Accuracy: 0.807\n",
      "Threshold: 0.60, Precision: 0.946, Recall: 0.648, F1 Score: 0.769, Accuracy: 0.804\n",
      "Threshold: 0.61, Precision: 0.949, Recall: 0.643, F1 Score: 0.766, Accuracy: 0.803\n",
      "Threshold: 0.62, Precision: 0.952, Recall: 0.639, F1 Score: 0.764, Accuracy: 0.802\n",
      "Threshold: 0.63, Precision: 0.955, Recall: 0.634, F1 Score: 0.762, Accuracy: 0.801\n",
      "Threshold: 0.64, Precision: 0.956, Recall: 0.632, F1 Score: 0.761, Accuracy: 0.800\n",
      "Threshold: 0.65, Precision: 0.957, Recall: 0.630, F1 Score: 0.760, Accuracy: 0.799\n",
      "Threshold: 0.66, Precision: 0.958, Recall: 0.630, F1 Score: 0.760, Accuracy: 0.799\n",
      "Threshold: 0.67, Precision: 0.958, Recall: 0.629, F1 Score: 0.759, Accuracy: 0.799\n",
      "Threshold: 0.68, Precision: 0.959, Recall: 0.628, F1 Score: 0.759, Accuracy: 0.799\n",
      "Threshold: 0.69, Precision: 0.960, Recall: 0.628, F1 Score: 0.759, Accuracy: 0.799\n",
      "Threshold: 0.70, Precision: 0.960, Recall: 0.627, F1 Score: 0.759, Accuracy: 0.799\n",
      "Threshold: 0.71, Precision: 0.961, Recall: 0.626, F1 Score: 0.758, Accuracy: 0.799\n",
      "Threshold: 0.72, Precision: 0.961, Recall: 0.625, F1 Score: 0.757, Accuracy: 0.798\n",
      "Threshold: 0.73, Precision: 0.961, Recall: 0.625, F1 Score: 0.757, Accuracy: 0.798\n",
      "Threshold: 0.74, Precision: 0.962, Recall: 0.624, F1 Score: 0.757, Accuracy: 0.798\n",
      "Threshold: 0.75, Precision: 0.964, Recall: 0.623, F1 Score: 0.757, Accuracy: 0.798\n",
      "Threshold: 0.76, Precision: 0.964, Recall: 0.622, F1 Score: 0.756, Accuracy: 0.798\n",
      "Threshold: 0.77, Precision: 0.964, Recall: 0.621, F1 Score: 0.756, Accuracy: 0.798\n",
      "Threshold: 0.78, Precision: 0.964, Recall: 0.620, F1 Score: 0.755, Accuracy: 0.797\n",
      "Threshold: 0.79, Precision: 0.965, Recall: 0.619, F1 Score: 0.754, Accuracy: 0.797\n",
      "Threshold: 0.80, Precision: 0.965, Recall: 0.617, F1 Score: 0.753, Accuracy: 0.796\n",
      "Threshold: 0.81, Precision: 0.965, Recall: 0.615, F1 Score: 0.752, Accuracy: 0.795\n",
      "Threshold: 0.82, Precision: 0.966, Recall: 0.613, F1 Score: 0.750, Accuracy: 0.794\n",
      "Threshold: 0.83, Precision: 0.966, Recall: 0.613, F1 Score: 0.750, Accuracy: 0.794\n",
      "Threshold: 0.84, Precision: 0.966, Recall: 0.610, F1 Score: 0.748, Accuracy: 0.793\n",
      "Threshold: 0.85, Precision: 0.967, Recall: 0.609, F1 Score: 0.747, Accuracy: 0.792\n",
      "Threshold: 0.86, Precision: 0.967, Recall: 0.607, F1 Score: 0.745, Accuracy: 0.791\n",
      "Threshold: 0.87, Precision: 0.968, Recall: 0.603, F1 Score: 0.743, Accuracy: 0.790\n",
      "Threshold: 0.88, Precision: 0.969, Recall: 0.600, F1 Score: 0.741, Accuracy: 0.789\n",
      "Threshold: 0.89, Precision: 0.970, Recall: 0.597, F1 Score: 0.739, Accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
