{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'blockedShotsHome',\n",
       "       'blockedShotsAway', 'league', 'corners_home', 'corners_away',\n",
       "       'shotsOffgoal_home', 'shotsOffgoal_away', 'shotsOngoal_home',\n",
       "       'shotsOngoal_away', 'yellowcards_home', 'yellowcards_away',\n",
       "       'fouls_home', 'fouls_away', 'offsides_home', 'offsides_away',\n",
       "       'tackles_home', 'tackles_away', 'result', 'match_id',\n",
       "       'possessiontime_away', 'possessiontime_home', 'shotsOnGoalEfficiency',\n",
       "       'attackPressure', 'shotAccuracy_home', 'shotAccuracy_away',\n",
       "       'possessionControl', 'passRisk', 'defensiveDiscipline',\n",
       "       'defensiveEfficacy', 'defensiveAggression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural no Keras: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrução do modelo, salvamento, visualização treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "726/726 [==============================] - 3s 3ms/step - loss: 0.6292 - accuracy: 0.6302 - recall_6: 0.4306 - precision_6: 0.7170 - auc_3: 0.6610 - val_loss: 0.6083 - val_accuracy: 0.6458 - val_recall_6: 0.3919 - val_precision_6: 0.7941 - val_auc_3: 0.6819\n",
      "Epoch 2/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.6066 - accuracy: 0.6446 - recall_6: 0.3867 - precision_6: 0.7992 - auc_3: 0.6813 - val_loss: 0.5947 - val_accuracy: 0.6527 - val_recall_6: 0.4146 - val_precision_6: 0.7898 - val_auc_3: 0.6966\n",
      "Epoch 3/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5962 - accuracy: 0.6498 - recall_6: 0.3874 - precision_6: 0.8159 - auc_3: 0.6954 - val_loss: 0.5877 - val_accuracy: 0.6549 - val_recall_6: 0.3734 - val_precision_6: 0.8522 - val_auc_3: 0.7043\n",
      "Epoch 4/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5874 - accuracy: 0.6580 - recall_6: 0.4134 - precision_6: 0.8097 - auc_3: 0.7105 - val_loss: 0.5797 - val_accuracy: 0.6624 - val_recall_6: 0.3959 - val_precision_6: 0.8458 - val_auc_3: 0.7269\n",
      "Epoch 5/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5795 - accuracy: 0.6649 - recall_6: 0.4426 - precision_6: 0.7973 - auc_3: 0.7249 - val_loss: 0.5729 - val_accuracy: 0.6729 - val_recall_6: 0.4630 - val_precision_6: 0.7964 - val_auc_3: 0.7363\n",
      "Epoch 6/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5700 - accuracy: 0.6744 - recall_6: 0.4828 - precision_6: 0.7830 - auc_3: 0.7401 - val_loss: 0.5660 - val_accuracy: 0.6826 - val_recall_6: 0.4961 - val_precision_6: 0.7898 - val_auc_3: 0.7539\n",
      "Epoch 7/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5599 - accuracy: 0.6846 - recall_6: 0.5120 - precision_6: 0.7821 - auc_3: 0.7546 - val_loss: 0.5505 - val_accuracy: 0.6949 - val_recall_6: 0.5168 - val_precision_6: 0.8014 - val_auc_3: 0.7704\n",
      "Epoch 8/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.6929 - recall_6: 0.5379 - precision_6: 0.7799 - auc_3: 0.7673 - val_loss: 0.5386 - val_accuracy: 0.7031 - val_recall_6: 0.5208 - val_precision_6: 0.8183 - val_auc_3: 0.7832\n",
      "Epoch 9/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.6995 - recall_6: 0.5543 - precision_6: 0.7814 - auc_3: 0.7783 - val_loss: 0.5274 - val_accuracy: 0.7140 - val_recall_6: 0.5643 - val_precision_6: 0.8043 - val_auc_3: 0.8004\n",
      "Epoch 10/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.5303 - accuracy: 0.7091 - recall_6: 0.5735 - precision_6: 0.7872 - auc_3: 0.7893 - val_loss: 0.5166 - val_accuracy: 0.7210 - val_recall_6: 0.5848 - val_precision_6: 0.8027 - val_auc_3: 0.8100\n",
      "Epoch 11/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.5229 - accuracy: 0.7140 - recall_6: 0.5852 - precision_6: 0.7884 - auc_3: 0.7976 - val_loss: 0.5087 - val_accuracy: 0.7263 - val_recall_6: 0.5941 - val_precision_6: 0.8066 - val_auc_3: 0.8172\n",
      "Epoch 12/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.5161 - accuracy: 0.7202 - recall_6: 0.5983 - precision_6: 0.7913 - auc_3: 0.8047 - val_loss: 0.5070 - val_accuracy: 0.7322 - val_recall_6: 0.6496 - val_precision_6: 0.7773 - val_auc_3: 0.8225\n",
      "Epoch 13/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.5090 - accuracy: 0.7247 - recall_6: 0.6041 - precision_6: 0.7963 - auc_3: 0.8106 - val_loss: 0.4920 - val_accuracy: 0.7402 - val_recall_6: 0.6092 - val_precision_6: 0.8245 - val_auc_3: 0.8349\n",
      "Epoch 14/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.5035 - accuracy: 0.7303 - recall_6: 0.6183 - precision_6: 0.7970 - auc_3: 0.8168 - val_loss: 0.4865 - val_accuracy: 0.7444 - val_recall_6: 0.6413 - val_precision_6: 0.8070 - val_auc_3: 0.8371\n",
      "Epoch 15/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4964 - accuracy: 0.7350 - recall_6: 0.6258 - precision_6: 0.8009 - auc_3: 0.8229 - val_loss: 0.4786 - val_accuracy: 0.7471 - val_recall_6: 0.6141 - val_precision_6: 0.8358 - val_auc_3: 0.8438\n",
      "Epoch 16/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4920 - accuracy: 0.7383 - recall_6: 0.6302 - precision_6: 0.8042 - auc_3: 0.8272 - val_loss: 0.4705 - val_accuracy: 0.7552 - val_recall_6: 0.6527 - val_precision_6: 0.8201 - val_auc_3: 0.8518\n",
      "Epoch 17/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4858 - accuracy: 0.7407 - recall_6: 0.6383 - precision_6: 0.8029 - auc_3: 0.8315 - val_loss: 0.4690 - val_accuracy: 0.7574 - val_recall_6: 0.6572 - val_precision_6: 0.8210 - val_auc_3: 0.8531\n",
      "Epoch 18/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4826 - accuracy: 0.7436 - recall_6: 0.6439 - precision_6: 0.8045 - auc_3: 0.8343 - val_loss: 0.4632 - val_accuracy: 0.7605 - val_recall_6: 0.6618 - val_precision_6: 0.8236 - val_auc_3: 0.8570\n",
      "Epoch 19/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4770 - accuracy: 0.7472 - recall_6: 0.6521 - precision_6: 0.8054 - auc_3: 0.8396 - val_loss: 0.4595 - val_accuracy: 0.7667 - val_recall_6: 0.7265 - val_precision_6: 0.7894 - val_auc_3: 0.8627\n",
      "Epoch 20/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.4747 - accuracy: 0.7494 - recall_6: 0.6595 - precision_6: 0.8043 - auc_3: 0.8417 - val_loss: 0.4555 - val_accuracy: 0.7635 - val_recall_6: 0.6882 - val_precision_6: 0.8095 - val_auc_3: 0.8617\n",
      "Epoch 21/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4714 - accuracy: 0.7517 - recall_6: 0.6591 - precision_6: 0.8091 - auc_3: 0.8446 - val_loss: 0.4509 - val_accuracy: 0.7676 - val_recall_6: 0.6709 - val_precision_6: 0.8310 - val_auc_3: 0.8652\n",
      "Epoch 22/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4706 - accuracy: 0.7517 - recall_6: 0.6622 - precision_6: 0.8068 - auc_3: 0.8447 - val_loss: 0.4497 - val_accuracy: 0.7708 - val_recall_6: 0.6978 - val_precision_6: 0.8164 - val_auc_3: 0.8679\n",
      "Epoch 23/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4644 - accuracy: 0.7552 - recall_6: 0.6685 - precision_6: 0.8089 - auc_3: 0.8497 - val_loss: 0.4426 - val_accuracy: 0.7767 - val_recall_6: 0.6840 - val_precision_6: 0.8389 - val_auc_3: 0.8723\n",
      "Epoch 24/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.7573 - recall_6: 0.6739 - precision_6: 0.8091 - auc_3: 0.8516 - val_loss: 0.4402 - val_accuracy: 0.7787 - val_recall_6: 0.7173 - val_precision_6: 0.8170 - val_auc_3: 0.8762\n",
      "Epoch 25/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4594 - accuracy: 0.7585 - recall_6: 0.6784 - precision_6: 0.8081 - auc_3: 0.8529 - val_loss: 0.4331 - val_accuracy: 0.7818 - val_recall_6: 0.7205 - val_precision_6: 0.8204 - val_auc_3: 0.8788\n",
      "Epoch 26/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4546 - accuracy: 0.7617 - recall_6: 0.6850 - precision_6: 0.8093 - auc_3: 0.8570 - val_loss: 0.4302 - val_accuracy: 0.7833 - val_recall_6: 0.7163 - val_precision_6: 0.8265 - val_auc_3: 0.8805\n",
      "Epoch 27/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.7628 - recall_6: 0.6796 - precision_6: 0.8155 - auc_3: 0.8574 - val_loss: 0.4308 - val_accuracy: 0.7837 - val_recall_6: 0.7002 - val_precision_6: 0.8399 - val_auc_3: 0.8812\n",
      "Epoch 28/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7651 - recall_6: 0.6889 - precision_6: 0.8128 - auc_3: 0.8594 - val_loss: 0.4295 - val_accuracy: 0.7839 - val_recall_6: 0.7375 - val_precision_6: 0.8123 - val_auc_3: 0.8820\n",
      "Epoch 29/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.7664 - recall_6: 0.6894 - precision_6: 0.8151 - auc_3: 0.8610 - val_loss: 0.4268 - val_accuracy: 0.7866 - val_recall_6: 0.6943 - val_precision_6: 0.8508 - val_auc_3: 0.8840\n",
      "Epoch 30/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4474 - accuracy: 0.7673 - recall_6: 0.6912 - precision_6: 0.8155 - auc_3: 0.8624 - val_loss: 0.4225 - val_accuracy: 0.7865 - val_recall_6: 0.7187 - val_precision_6: 0.8306 - val_auc_3: 0.8849\n",
      "Epoch 31/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4454 - accuracy: 0.7676 - recall_6: 0.6945 - precision_6: 0.8136 - auc_3: 0.8636 - val_loss: 0.4215 - val_accuracy: 0.7883 - val_recall_6: 0.7186 - val_precision_6: 0.8343 - val_auc_3: 0.8869\n",
      "Epoch 32/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.7682 - recall_6: 0.6909 - precision_6: 0.8174 - auc_3: 0.8640 - val_loss: 0.4175 - val_accuracy: 0.7913 - val_recall_6: 0.7242 - val_precision_6: 0.8358 - val_auc_3: 0.8891\n",
      "Epoch 33/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.7724 - recall_6: 0.7051 - precision_6: 0.8150 - auc_3: 0.8676 - val_loss: 0.4198 - val_accuracy: 0.7899 - val_recall_6: 0.7374 - val_precision_6: 0.8233 - val_auc_3: 0.8883\n",
      "Epoch 34/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4381 - accuracy: 0.7731 - recall_6: 0.6994 - precision_6: 0.8205 - auc_3: 0.8691 - val_loss: 0.4221 - val_accuracy: 0.7894 - val_recall_6: 0.7590 - val_precision_6: 0.8075 - val_auc_3: 0.8889\n",
      "Epoch 35/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4384 - accuracy: 0.7715 - recall_6: 0.6976 - precision_6: 0.8188 - auc_3: 0.8680 - val_loss: 0.4167 - val_accuracy: 0.7922 - val_recall_6: 0.7282 - val_precision_6: 0.8345 - val_auc_3: 0.8900\n",
      "Epoch 36/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7750 - recall_6: 0.7050 - precision_6: 0.8201 - auc_3: 0.8712 - val_loss: 0.4083 - val_accuracy: 0.7963 - val_recall_6: 0.7205 - val_precision_6: 0.8486 - val_auc_3: 0.8958\n",
      "Epoch 37/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4358 - accuracy: 0.7745 - recall_6: 0.7042 - precision_6: 0.8196 - auc_3: 0.8708 - val_loss: 0.4077 - val_accuracy: 0.7977 - val_recall_6: 0.7139 - val_precision_6: 0.8570 - val_auc_3: 0.8970\n",
      "Epoch 38/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4314 - accuracy: 0.7778 - recall_6: 0.7105 - precision_6: 0.8212 - auc_3: 0.8736 - val_loss: 0.4091 - val_accuracy: 0.7937 - val_recall_6: 0.7322 - val_precision_6: 0.8342 - val_auc_3: 0.8938\n",
      "Epoch 39/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4313 - accuracy: 0.7785 - recall_6: 0.7106 - precision_6: 0.8225 - auc_3: 0.8738 - val_loss: 0.4035 - val_accuracy: 0.8010 - val_recall_6: 0.7385 - val_precision_6: 0.8433 - val_auc_3: 0.8971\n",
      "Epoch 40/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4285 - accuracy: 0.7793 - recall_6: 0.7163 - precision_6: 0.8197 - auc_3: 0.8759 - val_loss: 0.4021 - val_accuracy: 0.8033 - val_recall_6: 0.7413 - val_precision_6: 0.8456 - val_auc_3: 0.8993\n",
      "Epoch 41/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4286 - accuracy: 0.7792 - recall_6: 0.7130 - precision_6: 0.8219 - auc_3: 0.8755 - val_loss: 0.4012 - val_accuracy: 0.8023 - val_recall_6: 0.7517 - val_precision_6: 0.8357 - val_auc_3: 0.8993\n",
      "Epoch 42/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4264 - accuracy: 0.7808 - recall_6: 0.7148 - precision_6: 0.8237 - auc_3: 0.8770 - val_loss: 0.4029 - val_accuracy: 0.8004 - val_recall_6: 0.7701 - val_precision_6: 0.8191 - val_auc_3: 0.8974\n",
      "Epoch 43/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4256 - accuracy: 0.7799 - recall_6: 0.7176 - precision_6: 0.8200 - auc_3: 0.8770 - val_loss: 0.4031 - val_accuracy: 0.8025 - val_recall_6: 0.7541 - val_precision_6: 0.8343 - val_auc_3: 0.9001\n",
      "Epoch 44/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.7825 - recall_6: 0.7202 - precision_6: 0.8228 - auc_3: 0.8793 - val_loss: 0.4008 - val_accuracy: 0.8019 - val_recall_6: 0.7800 - val_precision_6: 0.8151 - val_auc_3: 0.8994\n",
      "Epoch 45/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4240 - accuracy: 0.7833 - recall_6: 0.7197 - precision_6: 0.8247 - auc_3: 0.8790 - val_loss: 0.3974 - val_accuracy: 0.8047 - val_recall_6: 0.7431 - val_precision_6: 0.8469 - val_auc_3: 0.9020\n",
      "Epoch 46/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4214 - accuracy: 0.7842 - recall_6: 0.7206 - precision_6: 0.8258 - auc_3: 0.8803 - val_loss: 0.3970 - val_accuracy: 0.8049 - val_recall_6: 0.7597 - val_precision_6: 0.8346 - val_auc_3: 0.9019\n",
      "Epoch 47/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.7844 - recall_6: 0.7248 - precision_6: 0.8230 - auc_3: 0.8813 - val_loss: 0.3976 - val_accuracy: 0.8069 - val_recall_6: 0.7803 - val_precision_6: 0.8235 - val_auc_3: 0.9029\n",
      "Epoch 48/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4198 - accuracy: 0.7844 - recall_6: 0.7232 - precision_6: 0.8243 - auc_3: 0.8813 - val_loss: 0.3948 - val_accuracy: 0.8062 - val_recall_6: 0.8033 - val_precision_6: 0.8075 - val_auc_3: 0.9034\n",
      "Epoch 49/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4194 - accuracy: 0.7850 - recall_6: 0.7300 - precision_6: 0.8204 - auc_3: 0.8819 - val_loss: 0.3926 - val_accuracy: 0.8088 - val_recall_6: 0.7577 - val_precision_6: 0.8433 - val_auc_3: 0.9044\n",
      "Epoch 50/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4168 - accuracy: 0.7884 - recall_6: 0.7320 - precision_6: 0.8252 - auc_3: 0.8839 - val_loss: 0.3936 - val_accuracy: 0.8082 - val_recall_6: 0.7803 - val_precision_6: 0.8258 - val_auc_3: 0.9045\n",
      "Epoch 51/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.7880 - recall_6: 0.7347 - precision_6: 0.8224 - auc_3: 0.8841 - val_loss: 0.3904 - val_accuracy: 0.8088 - val_recall_6: 0.7773 - val_precision_6: 0.8291 - val_auc_3: 0.9064\n",
      "Epoch 52/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4146 - accuracy: 0.7893 - recall_6: 0.7335 - precision_6: 0.8259 - auc_3: 0.8852 - val_loss: 0.3868 - val_accuracy: 0.8131 - val_recall_6: 0.7535 - val_precision_6: 0.8548 - val_auc_3: 0.9084\n",
      "Epoch 53/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4113 - accuracy: 0.7886 - recall_6: 0.7327 - precision_6: 0.8250 - auc_3: 0.8868 - val_loss: 0.3874 - val_accuracy: 0.8102 - val_recall_6: 0.7861 - val_precision_6: 0.8253 - val_auc_3: 0.9082\n",
      "Epoch 54/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4113 - accuracy: 0.7904 - recall_6: 0.7377 - precision_6: 0.8248 - auc_3: 0.8870 - val_loss: 0.3887 - val_accuracy: 0.8130 - val_recall_6: 0.7971 - val_precision_6: 0.8227 - val_auc_3: 0.9079\n",
      "Epoch 55/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4119 - accuracy: 0.7908 - recall_6: 0.7358 - precision_6: 0.8269 - auc_3: 0.8868 - val_loss: 0.3843 - val_accuracy: 0.8112 - val_recall_6: 0.7649 - val_precision_6: 0.8424 - val_auc_3: 0.9085\n",
      "Epoch 56/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4112 - accuracy: 0.7910 - recall_6: 0.7398 - precision_6: 0.8244 - auc_3: 0.8871 - val_loss: 0.3860 - val_accuracy: 0.8134 - val_recall_6: 0.7739 - val_precision_6: 0.8396 - val_auc_3: 0.9079\n",
      "Epoch 57/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4103 - accuracy: 0.7920 - recall_6: 0.7406 - precision_6: 0.8257 - auc_3: 0.8875 - val_loss: 0.3884 - val_accuracy: 0.8097 - val_recall_6: 0.8232 - val_precision_6: 0.8010 - val_auc_3: 0.9080\n",
      "Epoch 58/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4087 - accuracy: 0.7927 - recall_6: 0.7363 - precision_6: 0.8301 - auc_3: 0.8886 - val_loss: 0.3894 - val_accuracy: 0.8138 - val_recall_6: 0.7904 - val_precision_6: 0.8286 - val_auc_3: 0.9095\n",
      "Epoch 59/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4095 - accuracy: 0.7925 - recall_6: 0.7378 - precision_6: 0.8286 - auc_3: 0.8880 - val_loss: 0.3884 - val_accuracy: 0.8116 - val_recall_6: 0.7940 - val_precision_6: 0.8225 - val_auc_3: 0.9085\n",
      "Epoch 60/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4057 - accuracy: 0.7950 - recall_6: 0.7437 - precision_6: 0.8288 - auc_3: 0.8906 - val_loss: 0.3796 - val_accuracy: 0.8162 - val_recall_6: 0.8032 - val_precision_6: 0.8242 - val_auc_3: 0.9116\n",
      "Epoch 61/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4083 - accuracy: 0.7929 - recall_6: 0.7447 - precision_6: 0.8242 - auc_3: 0.8889 - val_loss: 0.3773 - val_accuracy: 0.8187 - val_recall_6: 0.7907 - val_precision_6: 0.8370 - val_auc_3: 0.9130\n",
      "Epoch 62/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4047 - accuracy: 0.7960 - recall_6: 0.7422 - precision_6: 0.8318 - auc_3: 0.8916 - val_loss: 0.3837 - val_accuracy: 0.8152 - val_recall_6: 0.8121 - val_precision_6: 0.8166 - val_auc_3: 0.9106\n",
      "Epoch 63/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4043 - accuracy: 0.7947 - recall_6: 0.7452 - precision_6: 0.8272 - auc_3: 0.8915 - val_loss: 0.3773 - val_accuracy: 0.8183 - val_recall_6: 0.7975 - val_precision_6: 0.8316 - val_auc_3: 0.9131\n",
      "Epoch 64/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.7937 - recall_6: 0.7473 - precision_6: 0.8240 - auc_3: 0.8908 - val_loss: 0.3796 - val_accuracy: 0.8167 - val_recall_6: 0.7952 - val_precision_6: 0.8304 - val_auc_3: 0.9119\n",
      "Epoch 65/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4040 - accuracy: 0.7949 - recall_6: 0.7438 - precision_6: 0.8287 - auc_3: 0.8913 - val_loss: 0.3803 - val_accuracy: 0.8160 - val_recall_6: 0.7865 - val_precision_6: 0.8353 - val_auc_3: 0.9116\n",
      "Epoch 66/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.7961 - recall_6: 0.7471 - precision_6: 0.8285 - auc_3: 0.8920 - val_loss: 0.3773 - val_accuracy: 0.8192 - val_recall_6: 0.7884 - val_precision_6: 0.8396 - val_auc_3: 0.9132\n",
      "Epoch 67/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4007 - accuracy: 0.7974 - recall_6: 0.7472 - precision_6: 0.8307 - auc_3: 0.8934 - val_loss: 0.3809 - val_accuracy: 0.8140 - val_recall_6: 0.7718 - val_precision_6: 0.8423 - val_auc_3: 0.9110\n",
      "Epoch 68/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.7975 - recall_6: 0.7482 - precision_6: 0.8303 - auc_3: 0.8927 - val_loss: 0.3795 - val_accuracy: 0.8164 - val_recall_6: 0.7894 - val_precision_6: 0.8339 - val_auc_3: 0.9127\n",
      "Epoch 69/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.7971 - recall_6: 0.7499 - precision_6: 0.8282 - auc_3: 0.8928 - val_loss: 0.3783 - val_accuracy: 0.8183 - val_recall_6: 0.8092 - val_precision_6: 0.8237 - val_auc_3: 0.9136\n",
      "Epoch 70/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.7973 - recall_6: 0.7497 - precision_6: 0.8287 - auc_3: 0.8938 - val_loss: 0.3744 - val_accuracy: 0.8190 - val_recall_6: 0.7721 - val_precision_6: 0.8514 - val_auc_3: 0.9144\n",
      "Epoch 71/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3973 - accuracy: 0.7988 - recall_6: 0.7543 - precision_6: 0.8280 - auc_3: 0.8954 - val_loss: 0.3735 - val_accuracy: 0.8174 - val_recall_6: 0.8100 - val_precision_6: 0.8216 - val_auc_3: 0.9139\n",
      "Epoch 72/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3996 - accuracy: 0.7986 - recall_6: 0.7520 - precision_6: 0.8295 - auc_3: 0.8944 - val_loss: 0.3774 - val_accuracy: 0.8187 - val_recall_6: 0.7939 - val_precision_6: 0.8348 - val_auc_3: 0.9131\n",
      "Epoch 73/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3964 - accuracy: 0.8000 - recall_6: 0.7535 - precision_6: 0.8310 - auc_3: 0.8962 - val_loss: 0.3729 - val_accuracy: 0.8203 - val_recall_6: 0.7860 - val_precision_6: 0.8434 - val_auc_3: 0.9150\n",
      "Epoch 74/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3964 - accuracy: 0.8003 - recall_6: 0.7551 - precision_6: 0.8304 - auc_3: 0.8961 - val_loss: 0.3749 - val_accuracy: 0.8185 - val_recall_6: 0.8436 - val_precision_6: 0.8028 - val_auc_3: 0.9147\n",
      "Epoch 75/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.7998 - recall_6: 0.7537 - precision_6: 0.8305 - auc_3: 0.8968 - val_loss: 0.3727 - val_accuracy: 0.8188 - val_recall_6: 0.8310 - val_precision_6: 0.8108 - val_auc_3: 0.9154\n",
      "Epoch 76/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3962 - accuracy: 0.8006 - recall_6: 0.7538 - precision_6: 0.8318 - auc_3: 0.8963 - val_loss: 0.3679 - val_accuracy: 0.8232 - val_recall_6: 0.8148 - val_precision_6: 0.8282 - val_auc_3: 0.9178\n",
      "Epoch 77/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8023 - recall_6: 0.7575 - precision_6: 0.8322 - auc_3: 0.8980 - val_loss: 0.3709 - val_accuracy: 0.8217 - val_recall_6: 0.8156 - val_precision_6: 0.8252 - val_auc_3: 0.9156\n",
      "Epoch 78/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3954 - accuracy: 0.8009 - recall_6: 0.7551 - precision_6: 0.8314 - auc_3: 0.8969 - val_loss: 0.3670 - val_accuracy: 0.8240 - val_recall_6: 0.8196 - val_precision_6: 0.8265 - val_auc_3: 0.9181\n",
      "Epoch 79/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8018 - recall_6: 0.7533 - precision_6: 0.8344 - auc_3: 0.8974 - val_loss: 0.3682 - val_accuracy: 0.8239 - val_recall_6: 0.8020 - val_precision_6: 0.8383 - val_auc_3: 0.9176\n",
      "Epoch 80/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8044 - recall_6: 0.7594 - precision_6: 0.8347 - auc_3: 0.8994 - val_loss: 0.3643 - val_accuracy: 0.8239 - val_recall_6: 0.7845 - val_precision_6: 0.8510 - val_auc_3: 0.9180\n",
      "Epoch 81/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3914 - accuracy: 0.8045 - recall_6: 0.7597 - precision_6: 0.8347 - auc_3: 0.8992 - val_loss: 0.3675 - val_accuracy: 0.8243 - val_recall_6: 0.8157 - val_precision_6: 0.8296 - val_auc_3: 0.9185\n",
      "Epoch 82/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8031 - recall_6: 0.7596 - precision_6: 0.8321 - auc_3: 0.8986 - val_loss: 0.3697 - val_accuracy: 0.8230 - val_recall_6: 0.8472 - val_precision_6: 0.8075 - val_auc_3: 0.9188\n",
      "Epoch 83/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8045 - recall_6: 0.7603 - precision_6: 0.8341 - auc_3: 0.8996 - val_loss: 0.3670 - val_accuracy: 0.8249 - val_recall_6: 0.8249 - val_precision_6: 0.8245 - val_auc_3: 0.9194\n",
      "Epoch 84/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3898 - accuracy: 0.8045 - recall_6: 0.7634 - precision_6: 0.8318 - auc_3: 0.8998 - val_loss: 0.3688 - val_accuracy: 0.8270 - val_recall_6: 0.7922 - val_precision_6: 0.8509 - val_auc_3: 0.9182\n",
      "Epoch 85/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3895 - accuracy: 0.8044 - recall_6: 0.7558 - precision_6: 0.8372 - auc_3: 0.9000 - val_loss: 0.3653 - val_accuracy: 0.8250 - val_recall_6: 0.8459 - val_precision_6: 0.8115 - val_auc_3: 0.9197\n",
      "Epoch 86/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3895 - accuracy: 0.8040 - recall_6: 0.7625 - precision_6: 0.8317 - auc_3: 0.8999 - val_loss: 0.3657 - val_accuracy: 0.8263 - val_recall_6: 0.8274 - val_precision_6: 0.8251 - val_auc_3: 0.9190\n",
      "Epoch 87/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3885 - accuracy: 0.8050 - recall_6: 0.7634 - precision_6: 0.8328 - auc_3: 0.9006 - val_loss: 0.3633 - val_accuracy: 0.8278 - val_recall_6: 0.8224 - val_precision_6: 0.8309 - val_auc_3: 0.9200\n",
      "Epoch 88/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3870 - accuracy: 0.8070 - recall_6: 0.7671 - precision_6: 0.8338 - auc_3: 0.9018 - val_loss: 0.3666 - val_accuracy: 0.8264 - val_recall_6: 0.8203 - val_precision_6: 0.8299 - val_auc_3: 0.9193\n",
      "Epoch 89/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3877 - accuracy: 0.8061 - recall_6: 0.7649 - precision_6: 0.8338 - auc_3: 0.9011 - val_loss: 0.3639 - val_accuracy: 0.8304 - val_recall_6: 0.8196 - val_precision_6: 0.8372 - val_auc_3: 0.9215\n",
      "Epoch 90/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3870 - accuracy: 0.8067 - recall_6: 0.7645 - precision_6: 0.8351 - auc_3: 0.9016 - val_loss: 0.3644 - val_accuracy: 0.8294 - val_recall_6: 0.8015 - val_precision_6: 0.8483 - val_auc_3: 0.9207\n",
      "Epoch 91/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3862 - accuracy: 0.8067 - recall_6: 0.7621 - precision_6: 0.8369 - auc_3: 0.9020 - val_loss: 0.3610 - val_accuracy: 0.8300 - val_recall_6: 0.8037 - val_precision_6: 0.8478 - val_auc_3: 0.9217\n",
      "Epoch 92/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8060 - recall_6: 0.7593 - precision_6: 0.8377 - auc_3: 0.9019 - val_loss: 0.3615 - val_accuracy: 0.8291 - val_recall_6: 0.7908 - val_precision_6: 0.8558 - val_auc_3: 0.9209\n",
      "Epoch 93/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8073 - recall_6: 0.7637 - precision_6: 0.8368 - auc_3: 0.9023 - val_loss: 0.3606 - val_accuracy: 0.8299 - val_recall_6: 0.7960 - val_precision_6: 0.8533 - val_auc_3: 0.9215\n",
      "Epoch 94/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8077 - recall_6: 0.7662 - precision_6: 0.8358 - auc_3: 0.9024 - val_loss: 0.3595 - val_accuracy: 0.8305 - val_recall_6: 0.8121 - val_precision_6: 0.8426 - val_auc_3: 0.9227\n",
      "Epoch 95/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8085 - recall_6: 0.7646 - precision_6: 0.8383 - auc_3: 0.9028 - val_loss: 0.3603 - val_accuracy: 0.8282 - val_recall_6: 0.8152 - val_precision_6: 0.8365 - val_auc_3: 0.9207\n",
      "Epoch 96/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8066 - recall_6: 0.7697 - precision_6: 0.8311 - auc_3: 0.9034 - val_loss: 0.3578 - val_accuracy: 0.8302 - val_recall_6: 0.8225 - val_precision_6: 0.8349 - val_auc_3: 0.9220\n",
      "Epoch 97/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3819 - accuracy: 0.8105 - recall_6: 0.7726 - precision_6: 0.8361 - auc_3: 0.9046 - val_loss: 0.3578 - val_accuracy: 0.8307 - val_recall_6: 0.8144 - val_precision_6: 0.8413 - val_auc_3: 0.9226\n",
      "Epoch 98/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8101 - recall_6: 0.7707 - precision_6: 0.8368 - auc_3: 0.9043 - val_loss: 0.3610 - val_accuracy: 0.8319 - val_recall_6: 0.8142 - val_precision_6: 0.8436 - val_auc_3: 0.9216\n",
      "Epoch 99/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3814 - accuracy: 0.8099 - recall_6: 0.7709 - precision_6: 0.8362 - auc_3: 0.9048 - val_loss: 0.3599 - val_accuracy: 0.8274 - val_recall_6: 0.8582 - val_precision_6: 0.8080 - val_auc_3: 0.9235\n",
      "Epoch 100/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8101 - recall_6: 0.7730 - precision_6: 0.8351 - auc_3: 0.9044 - val_loss: 0.3602 - val_accuracy: 0.8315 - val_recall_6: 0.8255 - val_precision_6: 0.8350 - val_auc_3: 0.9226\n",
      "Epoch 101/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8090 - recall_6: 0.7686 - precision_6: 0.8363 - auc_3: 0.9039 - val_loss: 0.3554 - val_accuracy: 0.8308 - val_recall_6: 0.8251 - val_precision_6: 0.8342 - val_auc_3: 0.9235\n",
      "Epoch 102/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8096 - recall_6: 0.7711 - precision_6: 0.8356 - auc_3: 0.9041 - val_loss: 0.3551 - val_accuracy: 0.8324 - val_recall_6: 0.8347 - val_precision_6: 0.8305 - val_auc_3: 0.9243\n",
      "Epoch 103/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8101 - recall_6: 0.7760 - precision_6: 0.8329 - auc_3: 0.9054 - val_loss: 0.3598 - val_accuracy: 0.8314 - val_recall_6: 0.8359 - val_precision_6: 0.8279 - val_auc_3: 0.9240\n",
      "Epoch 104/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8116 - recall_6: 0.7751 - precision_6: 0.8363 - auc_3: 0.9054 - val_loss: 0.3591 - val_accuracy: 0.8303 - val_recall_6: 0.8115 - val_precision_6: 0.8426 - val_auc_3: 0.9219\n",
      "Epoch 105/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3801 - accuracy: 0.8112 - recall_6: 0.7718 - precision_6: 0.8379 - auc_3: 0.9056 - val_loss: 0.3606 - val_accuracy: 0.8273 - val_recall_6: 0.8613 - val_precision_6: 0.8060 - val_auc_3: 0.9234\n",
      "Epoch 106/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3817 - accuracy: 0.8108 - recall_6: 0.7737 - precision_6: 0.8359 - auc_3: 0.9048 - val_loss: 0.3554 - val_accuracy: 0.8296 - val_recall_6: 0.8179 - val_precision_6: 0.8369 - val_auc_3: 0.9225\n",
      "Epoch 107/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8119 - recall_6: 0.7723 - precision_6: 0.8389 - auc_3: 0.9066 - val_loss: 0.3599 - val_accuracy: 0.8286 - val_recall_6: 0.8247 - val_precision_6: 0.8308 - val_auc_3: 0.9220\n",
      "Epoch 108/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8118 - recall_6: 0.7733 - precision_6: 0.8380 - auc_3: 0.9069 - val_loss: 0.3547 - val_accuracy: 0.8328 - val_recall_6: 0.7964 - val_precision_6: 0.8583 - val_auc_3: 0.9242\n",
      "Epoch 109/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3765 - accuracy: 0.8123 - recall_6: 0.7719 - precision_6: 0.8398 - auc_3: 0.9072 - val_loss: 0.3586 - val_accuracy: 0.8307 - val_recall_6: 0.8384 - val_precision_6: 0.8253 - val_auc_3: 0.9235\n",
      "Epoch 110/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3773 - accuracy: 0.8123 - recall_6: 0.7727 - precision_6: 0.8393 - auc_3: 0.9069 - val_loss: 0.3576 - val_accuracy: 0.8315 - val_recall_6: 0.8292 - val_precision_6: 0.8325 - val_auc_3: 0.9233\n",
      "Epoch 111/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3766 - accuracy: 0.8138 - recall_6: 0.7788 - precision_6: 0.8375 - auc_3: 0.9076 - val_loss: 0.3564 - val_accuracy: 0.8336 - val_recall_6: 0.8105 - val_precision_6: 0.8492 - val_auc_3: 0.9244\n",
      "Epoch 112/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8125 - recall_6: 0.7742 - precision_6: 0.8386 - auc_3: 0.9070 - val_loss: 0.3580 - val_accuracy: 0.8302 - val_recall_6: 0.8440 - val_precision_6: 0.8208 - val_auc_3: 0.9239\n",
      "Epoch 113/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3756 - accuracy: 0.8119 - recall_6: 0.7726 - precision_6: 0.8386 - auc_3: 0.9077 - val_loss: 0.3527 - val_accuracy: 0.8339 - val_recall_6: 0.8207 - val_precision_6: 0.8424 - val_auc_3: 0.9253\n",
      "Epoch 114/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8131 - recall_6: 0.7730 - precision_6: 0.8405 - auc_3: 0.9080 - val_loss: 0.3577 - val_accuracy: 0.8318 - val_recall_6: 0.8193 - val_precision_6: 0.8398 - val_auc_3: 0.9243\n",
      "Epoch 115/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3770 - accuracy: 0.8127 - recall_6: 0.7765 - precision_6: 0.8373 - auc_3: 0.9071 - val_loss: 0.3493 - val_accuracy: 0.8358 - val_recall_6: 0.8083 - val_precision_6: 0.8548 - val_auc_3: 0.9263\n",
      "Epoch 116/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8149 - recall_6: 0.7749 - precision_6: 0.8423 - auc_3: 0.9093 - val_loss: 0.3503 - val_accuracy: 0.8351 - val_recall_6: 0.8121 - val_precision_6: 0.8507 - val_auc_3: 0.9260\n",
      "Epoch 117/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8148 - recall_6: 0.7797 - precision_6: 0.8388 - auc_3: 0.9095 - val_loss: 0.3531 - val_accuracy: 0.8357 - val_recall_6: 0.8161 - val_precision_6: 0.8489 - val_auc_3: 0.9259\n",
      "Epoch 118/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3752 - accuracy: 0.8143 - recall_6: 0.7748 - precision_6: 0.8414 - auc_3: 0.9087 - val_loss: 0.3504 - val_accuracy: 0.8355 - val_recall_6: 0.8213 - val_precision_6: 0.8449 - val_auc_3: 0.9259\n",
      "Epoch 119/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8150 - recall_6: 0.7776 - precision_6: 0.8406 - auc_3: 0.9084 - val_loss: 0.3513 - val_accuracy: 0.8365 - val_recall_6: 0.8154 - val_precision_6: 0.8508 - val_auc_3: 0.9264\n",
      "Epoch 120/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8155 - recall_6: 0.7769 - precision_6: 0.8421 - auc_3: 0.9095 - val_loss: 0.3522 - val_accuracy: 0.8352 - val_recall_6: 0.8349 - val_precision_6: 0.8350 - val_auc_3: 0.9266\n",
      "Epoch 121/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3746 - accuracy: 0.8147 - recall_6: 0.7791 - precision_6: 0.8389 - auc_3: 0.9086 - val_loss: 0.3507 - val_accuracy: 0.8370 - val_recall_6: 0.8240 - val_precision_6: 0.8454 - val_auc_3: 0.9259\n",
      "Epoch 122/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8164 - recall_6: 0.7818 - precision_6: 0.8401 - auc_3: 0.9104 - val_loss: 0.3484 - val_accuracy: 0.8395 - val_recall_6: 0.8342 - val_precision_6: 0.8427 - val_auc_3: 0.9276\n",
      "Epoch 123/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3731 - accuracy: 0.8149 - recall_6: 0.7743 - precision_6: 0.8428 - auc_3: 0.9091 - val_loss: 0.3494 - val_accuracy: 0.8359 - val_recall_6: 0.8332 - val_precision_6: 0.8372 - val_auc_3: 0.9267\n",
      "Epoch 124/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8138 - recall_6: 0.7776 - precision_6: 0.8384 - auc_3: 0.9089 - val_loss: 0.3503 - val_accuracy: 0.8367 - val_recall_6: 0.8385 - val_precision_6: 0.8351 - val_auc_3: 0.9279\n",
      "Epoch 125/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8156 - recall_6: 0.7798 - precision_6: 0.8400 - auc_3: 0.9095 - val_loss: 0.3538 - val_accuracy: 0.8355 - val_recall_6: 0.8286 - val_precision_6: 0.8396 - val_auc_3: 0.9257\n",
      "Epoch 126/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8155 - recall_6: 0.7787 - precision_6: 0.8406 - auc_3: 0.9099 - val_loss: 0.3485 - val_accuracy: 0.8369 - val_recall_6: 0.8376 - val_precision_6: 0.8359 - val_auc_3: 0.9280\n",
      "Epoch 127/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3706 - accuracy: 0.8160 - recall_6: 0.7828 - precision_6: 0.8387 - auc_3: 0.9108 - val_loss: 0.3521 - val_accuracy: 0.8351 - val_recall_6: 0.8178 - val_precision_6: 0.8466 - val_auc_3: 0.9268\n",
      "Epoch 128/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3735 - accuracy: 0.8144 - recall_6: 0.7760 - precision_6: 0.8408 - auc_3: 0.9090 - val_loss: 0.3479 - val_accuracy: 0.8379 - val_recall_6: 0.8138 - val_precision_6: 0.8545 - val_auc_3: 0.9276\n",
      "Epoch 129/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3702 - accuracy: 0.8184 - recall_6: 0.7819 - precision_6: 0.8436 - auc_3: 0.9111 - val_loss: 0.3489 - val_accuracy: 0.8377 - val_recall_6: 0.8276 - val_precision_6: 0.8442 - val_auc_3: 0.9274\n",
      "Epoch 130/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3724 - accuracy: 0.8178 - recall_6: 0.7827 - precision_6: 0.8419 - auc_3: 0.9100 - val_loss: 0.3473 - val_accuracy: 0.8388 - val_recall_6: 0.8417 - val_precision_6: 0.8363 - val_auc_3: 0.9279\n",
      "Epoch 131/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3708 - accuracy: 0.8167 - recall_6: 0.7817 - precision_6: 0.8406 - auc_3: 0.9106 - val_loss: 0.3447 - val_accuracy: 0.8391 - val_recall_6: 0.8294 - val_precision_6: 0.8453 - val_auc_3: 0.9289\n",
      "Epoch 132/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3703 - accuracy: 0.8163 - recall_6: 0.7806 - precision_6: 0.8408 - auc_3: 0.9107 - val_loss: 0.3414 - val_accuracy: 0.8409 - val_recall_6: 0.8341 - val_precision_6: 0.8451 - val_auc_3: 0.9300\n",
      "Epoch 133/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8175 - recall_6: 0.7800 - precision_6: 0.8434 - auc_3: 0.9109 - val_loss: 0.3448 - val_accuracy: 0.8388 - val_recall_6: 0.8414 - val_precision_6: 0.8366 - val_auc_3: 0.9291\n",
      "Epoch 134/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3691 - accuracy: 0.8190 - recall_6: 0.7862 - precision_6: 0.8414 - auc_3: 0.9118 - val_loss: 0.3465 - val_accuracy: 0.8385 - val_recall_6: 0.8387 - val_precision_6: 0.8378 - val_auc_3: 0.9291\n",
      "Epoch 135/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8183 - recall_6: 0.7862 - precision_6: 0.8402 - auc_3: 0.9118 - val_loss: 0.3446 - val_accuracy: 0.8399 - val_recall_6: 0.8278 - val_precision_6: 0.8479 - val_auc_3: 0.9288\n",
      "Epoch 136/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3684 - accuracy: 0.8184 - recall_6: 0.7877 - precision_6: 0.8393 - auc_3: 0.9120 - val_loss: 0.3418 - val_accuracy: 0.8403 - val_recall_6: 0.8295 - val_precision_6: 0.8474 - val_auc_3: 0.9296\n",
      "Epoch 137/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8178 - recall_6: 0.7808 - precision_6: 0.8434 - auc_3: 0.9116 - val_loss: 0.3443 - val_accuracy: 0.8404 - val_recall_6: 0.8302 - val_precision_6: 0.8471 - val_auc_3: 0.9299\n",
      "Epoch 138/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8172 - recall_6: 0.7828 - precision_6: 0.8408 - auc_3: 0.9114 - val_loss: 0.3468 - val_accuracy: 0.8380 - val_recall_6: 0.8560 - val_precision_6: 0.8258 - val_auc_3: 0.9296\n",
      "Epoch 139/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3678 - accuracy: 0.8171 - recall_6: 0.7818 - precision_6: 0.8414 - auc_3: 0.9117 - val_loss: 0.3444 - val_accuracy: 0.8374 - val_recall_6: 0.8492 - val_precision_6: 0.8291 - val_auc_3: 0.9303\n",
      "Epoch 140/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8188 - recall_6: 0.7857 - precision_6: 0.8416 - auc_3: 0.9126 - val_loss: 0.3459 - val_accuracy: 0.8395 - val_recall_6: 0.8331 - val_precision_6: 0.8434 - val_auc_3: 0.9288\n",
      "Epoch 141/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3669 - accuracy: 0.8203 - recall_6: 0.7881 - precision_6: 0.8425 - auc_3: 0.9130 - val_loss: 0.3426 - val_accuracy: 0.8407 - val_recall_6: 0.8437 - val_precision_6: 0.8381 - val_auc_3: 0.9308\n",
      "Epoch 142/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8196 - recall_6: 0.7829 - precision_6: 0.8449 - auc_3: 0.9131 - val_loss: 0.3429 - val_accuracy: 0.8403 - val_recall_6: 0.8426 - val_precision_6: 0.8383 - val_auc_3: 0.9307\n",
      "Epoch 143/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3663 - accuracy: 0.8197 - recall_6: 0.7885 - precision_6: 0.8412 - auc_3: 0.9131 - val_loss: 0.3433 - val_accuracy: 0.8397 - val_recall_6: 0.8438 - val_precision_6: 0.8364 - val_auc_3: 0.9307\n",
      "Epoch 144/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8184 - recall_6: 0.7823 - precision_6: 0.8434 - auc_3: 0.9133 - val_loss: 0.3424 - val_accuracy: 0.8415 - val_recall_6: 0.8507 - val_precision_6: 0.8349 - val_auc_3: 0.9308\n",
      "Epoch 145/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8223 - recall_6: 0.7877 - precision_6: 0.8465 - auc_3: 0.9142 - val_loss: 0.3421 - val_accuracy: 0.8408 - val_recall_6: 0.8366 - val_precision_6: 0.8433 - val_auc_3: 0.9299\n",
      "Epoch 146/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3670 - accuracy: 0.8184 - recall_6: 0.7835 - precision_6: 0.8424 - auc_3: 0.9125 - val_loss: 0.3434 - val_accuracy: 0.8387 - val_recall_6: 0.8294 - val_precision_6: 0.8447 - val_auc_3: 0.9298\n",
      "Epoch 147/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3653 - accuracy: 0.8189 - recall_6: 0.7840 - precision_6: 0.8430 - auc_3: 0.9132 - val_loss: 0.3428 - val_accuracy: 0.8398 - val_recall_6: 0.8341 - val_precision_6: 0.8434 - val_auc_3: 0.9308\n",
      "Epoch 148/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3663 - accuracy: 0.8193 - recall_6: 0.7854 - precision_6: 0.8426 - auc_3: 0.9129 - val_loss: 0.3430 - val_accuracy: 0.8392 - val_recall_6: 0.8432 - val_precision_6: 0.8361 - val_auc_3: 0.9304\n",
      "Epoch 149/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8196 - recall_6: 0.7870 - precision_6: 0.8421 - auc_3: 0.9132 - val_loss: 0.3463 - val_accuracy: 0.8384 - val_recall_6: 0.8545 - val_precision_6: 0.8274 - val_auc_3: 0.9306\n",
      "Epoch 150/500\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 0.3643 - accuracy: 0.8212 - recall_6: 0.7878 - precision_6: 0.8443 - auc_3: 0.9141 - val_loss: 0.3443 - val_accuracy: 0.8420 - val_recall_6: 0.8334 - val_precision_6: 0.8476 - val_auc_3: 0.9304\n",
      "Epoch 151/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3612 - accuracy: 0.8221 - recall_6: 0.7897 - precision_6: 0.8445 - auc_3: 0.9155 - val_loss: 0.3418 - val_accuracy: 0.8427 - val_recall_6: 0.8372 - val_precision_6: 0.8460 - val_auc_3: 0.9307\n",
      "Epoch 152/500\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3657 - accuracy: 0.8206 - recall_6: 0.7863 - precision_6: 0.8443 - auc_3: 0.9135 - val_loss: 0.3426 - val_accuracy: 0.8444 - val_recall_6: 0.8380 - val_precision_6: 0.8483 - val_auc_3: 0.9316\n",
      "2904/2904 [==============================] - 2s 748us/step\n",
      "726/726 [==============================] - 1s 800us/step\n",
      "Acurácia no conjunto de treinamento: 0.885861873626709\n",
      "Acurácia no conjunto de teste: 0.8408748507499695\n",
      "AUC no conjunto de treinamento: 0.9644279181693785\n",
      "AUC no conjunto de teste: 0.9300713978324587\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 766us/step\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.84      0.85      0.84     11633\n",
      "    Classe 1       0.85      0.83      0.84     11594\n",
      "\n",
      "    accuracy                           0.84     23227\n",
      "   macro avg       0.84      0.84      0.84     23227\n",
      "weighted avg       0.84      0.84      0.84     23227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2, l1_l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# , kernel_regularizer=l2(0.00005))) \n",
    "\n",
    "# classes = np.unique(y_train)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "# class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Criação do modelo com possivelmente mais capacidade\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))  # Aumento na capacidade da primeira camada\n",
    "model.add(Dropout(0.3))  # Diminuição do dropout\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Diminuição do dropout\n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Otimizador com escalonamento de taxa de aprendizado\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', tf.metrics.Recall(), tf.metrics.Precision(), tf.metrics.AUC()])\n",
    "\n",
    "# Ajuste no callback de EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=128,  # Experimentar com um batch size diferente\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    # class_weight=class_weights,\n",
    "                    callbacks=[early_stop], verbose=1)\n",
    "\n",
    "\n",
    "# Avaliando a acurácia e AUC do modelo\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "train_auc = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print('Acurácia no conjunto de treinamento:', train_acc)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "print('AUC no conjunto de treinamento:', train_auc)\n",
    "print('AUC no conjunto de teste:', test_auc)\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# Obtendo os rótulos verdadeiros\n",
    "y_true = y_test  # Substitua com o array correto de rótulos verdadeiros do conjunto de teste\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_true, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva de Aprendizado: A curva de aprendizado mostra que a acurácia de validação e treinamento estão se aproximando uma da outra conforme o número de épocas aumenta, o que é um bom sinal de que o modelo não está sofrendo de overfitting significativo.\n",
    "\n",
    "Acurácia e AUC: A acurácia e a Área Sob a Curva ROC (AUC) no conjunto de teste são bastante altas, o que sugere que o modelo tem um bom desempenho geral.\n",
    "\n",
    "Recall e Precision: Os valores de recall e precisão são bastante equilibrados para as previsões no conjunto de validação, indicando que o modelo tem um desempenho bom e equilibrado em relação a ambas as classes.\n",
    "\n",
    "Relatório de Classificação: O relatório de classificação mostra resultados quase simétricos para as classes 0 e 1, com uma precisão, recall e pontuação F1 bastante semelhantes para ambas, o que sugere que o modelo está tratando ambas as classes de forma equitativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/726 [==============================] - 1s 712us/step\n",
      "Threshold: 0.10, Precision: 0.524, Recall: 0.998, F1 Score: 0.687, Accuracy: 0.546\n",
      "Threshold: 0.11, Precision: 0.528, Recall: 0.998, F1 Score: 0.691, Accuracy: 0.554\n",
      "Threshold: 0.12, Precision: 0.533, Recall: 0.997, F1 Score: 0.695, Accuracy: 0.563\n",
      "Threshold: 0.13, Precision: 0.538, Recall: 0.996, F1 Score: 0.698, Accuracy: 0.570\n",
      "Threshold: 0.14, Precision: 0.542, Recall: 0.995, F1 Score: 0.702, Accuracy: 0.578\n",
      "Threshold: 0.15, Precision: 0.547, Recall: 0.993, F1 Score: 0.705, Accuracy: 0.586\n",
      "Threshold: 0.16, Precision: 0.551, Recall: 0.992, F1 Score: 0.709, Accuracy: 0.593\n",
      "Threshold: 0.17, Precision: 0.556, Recall: 0.991, F1 Score: 0.712, Accuracy: 0.600\n",
      "Threshold: 0.18, Precision: 0.561, Recall: 0.989, F1 Score: 0.716, Accuracy: 0.608\n",
      "Threshold: 0.19, Precision: 0.566, Recall: 0.987, F1 Score: 0.719, Accuracy: 0.615\n",
      "Threshold: 0.20, Precision: 0.570, Recall: 0.985, F1 Score: 0.722, Accuracy: 0.622\n",
      "Threshold: 0.21, Precision: 0.575, Recall: 0.983, F1 Score: 0.725, Accuracy: 0.629\n",
      "Threshold: 0.22, Precision: 0.580, Recall: 0.981, F1 Score: 0.728, Accuracy: 0.635\n",
      "Threshold: 0.23, Precision: 0.584, Recall: 0.979, F1 Score: 0.732, Accuracy: 0.642\n",
      "Threshold: 0.24, Precision: 0.589, Recall: 0.976, F1 Score: 0.735, Accuracy: 0.648\n",
      "Threshold: 0.25, Precision: 0.594, Recall: 0.972, F1 Score: 0.737, Accuracy: 0.654\n",
      "Threshold: 0.26, Precision: 0.599, Recall: 0.969, F1 Score: 0.740, Accuracy: 0.661\n",
      "Threshold: 0.27, Precision: 0.605, Recall: 0.966, F1 Score: 0.744, Accuracy: 0.668\n",
      "Threshold: 0.28, Precision: 0.610, Recall: 0.961, F1 Score: 0.747, Accuracy: 0.674\n",
      "Threshold: 0.29, Precision: 0.616, Recall: 0.956, F1 Score: 0.749, Accuracy: 0.680\n",
      "Threshold: 0.30, Precision: 0.621, Recall: 0.951, F1 Score: 0.751, Accuracy: 0.685\n",
      "Threshold: 0.31, Precision: 0.626, Recall: 0.944, F1 Score: 0.753, Accuracy: 0.690\n",
      "Threshold: 0.32, Precision: 0.632, Recall: 0.936, F1 Score: 0.755, Accuracy: 0.696\n",
      "Threshold: 0.33, Precision: 0.637, Recall: 0.927, F1 Score: 0.755, Accuracy: 0.700\n",
      "Threshold: 0.34, Precision: 0.645, Recall: 0.917, F1 Score: 0.757, Accuracy: 0.706\n",
      "Threshold: 0.35, Precision: 0.651, Recall: 0.907, F1 Score: 0.758, Accuracy: 0.711\n",
      "Threshold: 0.36, Precision: 0.666, Recall: 0.887, F1 Score: 0.760, Accuracy: 0.721\n",
      "Threshold: 0.37, Precision: 0.679, Recall: 0.866, F1 Score: 0.761, Accuracy: 0.728\n",
      "Threshold: 0.38, Precision: 0.693, Recall: 0.848, F1 Score: 0.762, Accuracy: 0.736\n",
      "Threshold: 0.39, Precision: 0.706, Recall: 0.830, F1 Score: 0.763, Accuracy: 0.743\n",
      "Threshold: 0.40, Precision: 0.721, Recall: 0.812, F1 Score: 0.763, Accuracy: 0.749\n",
      "Threshold: 0.41, Precision: 0.733, Recall: 0.788, F1 Score: 0.760, Accuracy: 0.751\n",
      "Threshold: 0.42, Precision: 0.747, Recall: 0.769, F1 Score: 0.758, Accuracy: 0.755\n",
      "Threshold: 0.43, Precision: 0.758, Recall: 0.750, F1 Score: 0.754, Accuracy: 0.756\n",
      "Threshold: 0.44, Precision: 0.770, Recall: 0.730, F1 Score: 0.749, Accuracy: 0.756\n",
      "Threshold: 0.45, Precision: 0.782, Recall: 0.712, F1 Score: 0.746, Accuracy: 0.757\n",
      "Threshold: 0.46, Precision: 0.794, Recall: 0.696, F1 Score: 0.742, Accuracy: 0.758\n",
      "Threshold: 0.47, Precision: 0.803, Recall: 0.681, F1 Score: 0.737, Accuracy: 0.757\n",
      "Threshold: 0.48, Precision: 0.810, Recall: 0.663, F1 Score: 0.730, Accuracy: 0.755\n",
      "Threshold: 0.49, Precision: 0.820, Recall: 0.648, F1 Score: 0.724, Accuracy: 0.753\n",
      "Threshold: 0.50, Precision: 0.830, Recall: 0.634, F1 Score: 0.719, Accuracy: 0.753\n",
      "Threshold: 0.51, Precision: 0.839, Recall: 0.621, F1 Score: 0.713, Accuracy: 0.751\n",
      "Threshold: 0.52, Precision: 0.848, Recall: 0.607, F1 Score: 0.708, Accuracy: 0.750\n",
      "Threshold: 0.53, Precision: 0.854, Recall: 0.595, F1 Score: 0.701, Accuracy: 0.747\n",
      "Threshold: 0.54, Precision: 0.860, Recall: 0.582, F1 Score: 0.694, Accuracy: 0.744\n",
      "Threshold: 0.55, Precision: 0.865, Recall: 0.569, F1 Score: 0.687, Accuracy: 0.741\n",
      "Threshold: 0.56, Precision: 0.870, Recall: 0.558, F1 Score: 0.680, Accuracy: 0.738\n",
      "Threshold: 0.57, Precision: 0.874, Recall: 0.549, F1 Score: 0.675, Accuracy: 0.736\n",
      "Threshold: 0.58, Precision: 0.880, Recall: 0.540, F1 Score: 0.669, Accuracy: 0.733\n",
      "Threshold: 0.59, Precision: 0.884, Recall: 0.529, F1 Score: 0.662, Accuracy: 0.730\n",
      "Threshold: 0.60, Precision: 0.889, Recall: 0.521, F1 Score: 0.657, Accuracy: 0.728\n",
      "Threshold: 0.61, Precision: 0.893, Recall: 0.512, F1 Score: 0.651, Accuracy: 0.726\n",
      "Threshold: 0.62, Precision: 0.897, Recall: 0.503, F1 Score: 0.644, Accuracy: 0.723\n",
      "Threshold: 0.63, Precision: 0.903, Recall: 0.496, F1 Score: 0.640, Accuracy: 0.722\n",
      "Threshold: 0.64, Precision: 0.906, Recall: 0.489, F1 Score: 0.635, Accuracy: 0.719\n",
      "Threshold: 0.65, Precision: 0.907, Recall: 0.481, F1 Score: 0.629, Accuracy: 0.716\n",
      "Threshold: 0.66, Precision: 0.910, Recall: 0.475, F1 Score: 0.624, Accuracy: 0.715\n",
      "Threshold: 0.67, Precision: 0.912, Recall: 0.467, F1 Score: 0.618, Accuracy: 0.712\n",
      "Threshold: 0.68, Precision: 0.916, Recall: 0.461, F1 Score: 0.613, Accuracy: 0.710\n",
      "Threshold: 0.69, Precision: 0.919, Recall: 0.454, F1 Score: 0.608, Accuracy: 0.708\n",
      "Threshold: 0.70, Precision: 0.922, Recall: 0.447, F1 Score: 0.602, Accuracy: 0.705\n",
      "Threshold: 0.71, Precision: 0.926, Recall: 0.439, F1 Score: 0.596, Accuracy: 0.703\n",
      "Threshold: 0.72, Precision: 0.929, Recall: 0.430, F1 Score: 0.588, Accuracy: 0.699\n",
      "Threshold: 0.73, Precision: 0.932, Recall: 0.422, F1 Score: 0.581, Accuracy: 0.696\n",
      "Threshold: 0.74, Precision: 0.936, Recall: 0.412, F1 Score: 0.572, Accuracy: 0.693\n",
      "Threshold: 0.75, Precision: 0.940, Recall: 0.405, F1 Score: 0.566, Accuracy: 0.690\n",
      "Threshold: 0.76, Precision: 0.943, Recall: 0.396, F1 Score: 0.558, Accuracy: 0.687\n",
      "Threshold: 0.77, Precision: 0.944, Recall: 0.387, F1 Score: 0.549, Accuracy: 0.682\n",
      "Threshold: 0.78, Precision: 0.947, Recall: 0.377, F1 Score: 0.539, Accuracy: 0.679\n",
      "Threshold: 0.79, Precision: 0.950, Recall: 0.367, F1 Score: 0.529, Accuracy: 0.674\n",
      "Threshold: 0.80, Precision: 0.952, Recall: 0.359, F1 Score: 0.521, Accuracy: 0.671\n",
      "Threshold: 0.81, Precision: 0.955, Recall: 0.351, F1 Score: 0.514, Accuracy: 0.668\n",
      "Threshold: 0.82, Precision: 0.959, Recall: 0.342, F1 Score: 0.504, Accuracy: 0.664\n",
      "Threshold: 0.83, Precision: 0.961, Recall: 0.335, F1 Score: 0.497, Accuracy: 0.661\n",
      "Threshold: 0.84, Precision: 0.964, Recall: 0.327, F1 Score: 0.489, Accuracy: 0.658\n",
      "Threshold: 0.85, Precision: 0.967, Recall: 0.321, F1 Score: 0.482, Accuracy: 0.656\n",
      "Threshold: 0.86, Precision: 0.969, Recall: 0.314, F1 Score: 0.474, Accuracy: 0.652\n",
      "Threshold: 0.87, Precision: 0.970, Recall: 0.308, F1 Score: 0.467, Accuracy: 0.650\n",
      "Threshold: 0.88, Precision: 0.974, Recall: 0.303, F1 Score: 0.463, Accuracy: 0.648\n",
      "Threshold: 0.89, Precision: 0.975, Recall: 0.297, F1 Score: 0.455, Accuracy: 0.645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo\n",
    "model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# Prever as probabilidades para o conjunto de teste\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Inicialize o valor do threshold que você quer testar\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Para cada threshold, calcule e imprima as métricas\n",
    "for thresh in thresholds:\n",
    "    # Converta probabilidades em previsões binárias com base no threshold\n",
    "    y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "    # Calcule as métricas para a classe 1\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprima as métricas\n",
    "    print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
