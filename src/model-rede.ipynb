{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pendências\n",
    "- [x] Procurar sobre importância de atributos\n",
    "- [x] Calcular acurácia dos modelos\n",
    "- [x] Fazer previsão por liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['minute', 'homeTeam', 'awayTeam', 'shotsHome', 'shotsAway', 'league',\n",
       "       'shotsOffgoal_home', 'shotsOffgoal_away', 'fouls_home', 'fouls_away',\n",
       "       'tackles_home', 'tackles_away', 'result', 'match_id',\n",
       "       'possessiontime_away', 'possessiontime_home', 'shotsOnGoalEfficiency',\n",
       "       'attackPressure', 'shotAccuracy_home', 'shotAccuracy_away',\n",
       "       'possessionControl', 'passRiskHome', 'passRiskAway',\n",
       "       'defensiveDiscipline', 'defensiveEfficacy', 'defensiveAggression',\n",
       "       'timeSinceLastEventShots_Home', 'timeSinceLastEventShots_Away',\n",
       "       'timeSinceLastEventCorners_Home', 'timeSinceLastEventCorners_Away',\n",
       "       'timeSinceLastEventPasses_Home', 'timeSinceLastEventPasses_Away',\n",
       "       'timeSinceLastEvent_Home', 'timeSinceLastEvent_Away',\n",
       "       'timeSinceLastEventFouls_Home', 'timeSinceLastEventFouls_Away',\n",
       "       'timeSinceLastEventTotalCards_Home',\n",
       "       'timeSinceLastEventTotalCards_Away', 'total_change_possessiontime_home',\n",
       "       'total_change_possessiontime_away', '05ht_home', '05ft_home',\n",
       "       '15ft_home', '25ft_home', '05_home', '15_home', '25_home', '05ht_away',\n",
       "       '05ft_away', '15ft_away', '05_away', '15_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42, stratify=y)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural: Treinamento e Avaliação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, neurons, dropout_rate, activation_type, normalization_type):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         layers = []\n",
    "\n",
    "\n",
    "#         # Primeira camada\n",
    "#         layers.append(nn.Linear(input_size, neurons[0]))\n",
    "#         if normalization_type == 'batch':\n",
    "#             layers.append(nn.BatchNorm1d(neurons[0]))\n",
    "#         layers.append(self._get_activation(activation_type))\n",
    "#         if dropout_rate > 0:\n",
    "#             layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "#         # Camadas ocultas\n",
    "#         for i in range(1, len(neurons)):\n",
    "#             layers.append(nn.Linear(neurons[i-1], neurons[i]))\n",
    "#             if normalization_type == 'batch':\n",
    "#                 layers.append(nn.BatchNorm1d(neurons[i]))\n",
    "#             layers.append(self._get_activation(activation_type))\n",
    "#             if dropout_rate > 0:\n",
    "#                 layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "\n",
    "#         # Camada de saída\n",
    "#         self.layers = nn.Sequential(*layers)\n",
    "#         self.output = nn.Linear(neurons[-1], 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def _get_activation(self, activation_type):\n",
    "#         if activation_type == 'relu':\n",
    "#             return nn.ReLU()\n",
    "#         elif activation_type == 'tanh':\n",
    "#             return nn.Tanh()\n",
    "#         elif activation_type == 'leaky_relu':\n",
    "#             return nn.LeakyReLU()\n",
    "#         elif activation_type == 'elu':\n",
    "#             return nn.ELU()\n",
    "#         # Adicione outras funções de ativação conforme necessário\n",
    "#         else:\n",
    "#             raise ValueError(f\"Tipo de ativação desconhecido: {activation_type}\")\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         x = self.output(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# patience = 10\n",
    "# def train(model, criterion, optimizer, train_loader, val_loader, epochs=400):\n",
    "#     model.train()\n",
    "#     best_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#           for i, (inputs, labels) in enumerate(train_loader):\n",
    "#               inputs, labels = inputs.to(device), labels.to(device)\n",
    "#               optimizer.zero_grad()\n",
    "#               outputs = model(inputs)\n",
    "#               loss = criterion(outputs, labels.unsqueeze(1))\n",
    "#               loss.backward()\n",
    "#               optimizer.step()\n",
    "\n",
    "#           # Avaliação no conjunto de validação\n",
    "#           model.eval()\n",
    "#           with torch.no_grad():\n",
    "#               val_losses = []\n",
    "#               for inputs, labels in val_loader:\n",
    "#                   inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                   outputs = model(inputs)\n",
    "#                   val_loss = criterion(outputs, labels.unsqueeze(1))\n",
    "#                   val_losses.append(val_loss.item())\n",
    "\n",
    "#               avg_val_loss = np.mean(val_losses)\n",
    "#               print(f'Época {epoch+1}/{epochs}, Perda de Treinamento: {loss.item()}, Perda de Validação: {avg_val_loss}, Melhor perda: {best_loss}')\n",
    "\n",
    "#               # Salvar os melhores pesos do modelo\n",
    "#               if avg_val_loss < best_loss:\n",
    "#                   print('Melhor perda de validação alcançada, salvando o modelo...')\n",
    "#                   best_loss = avg_val_loss\n",
    "#                   torch.save(model.state_dict(), f'../models/model_redeht.pth')\n",
    "#                   epochs_no_improve = 0\n",
    "#               else:\n",
    "#                   epochs_no_improve += 1\n",
    "#                   if epochs_no_improve == patience:\n",
    "#                       print('Early stopping!')\n",
    "#                       break\n",
    "\n",
    "#     # Carrega os melhores pesos antes de retornar (opcional)\n",
    "#     model.load_state_dict(torch.load(f'../models/model_redeht.pth'))\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, X, y):\n",
    "#         self.X = torch.tensor(X, dtype=torch.float32)\n",
    "#         self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.X[idx], self.y[idx]\n",
    "\n",
    "# def evaluate(model, data_loader, criterion):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     total_accuracy = 0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in data_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels.unsqueeze(1))\n",
    "#             total_loss += loss.item()\n",
    "#             preds = (outputs > 0.5).float()\n",
    "#             total_accuracy += (preds.squeeze() == labels).float().sum().item()\n",
    "#             total_samples += labels.size(0)\n",
    "\n",
    "#     avg_loss = total_loss / len(data_loader)\n",
    "#     avg_accuracy = total_accuracy / total_samples\n",
    "#     return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, epochs=400):\n",
    "#   # Seu código de treinamento e avaliação aqui\n",
    "#   train(model, criterion, optimizer, train_loader, val_loader, epochs=epochs)\n",
    "#   loss, accuracy = evaluate(model, val_loader, criterion)\n",
    "#   # Retorna a perda média no conjunto de validação\n",
    "#   return loss\n",
    "\n",
    "# # Espaço de Hiperparâmetros\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.00001, 0.00001, 0.000001],\n",
    "#     'batch_size': [64, 128, 256, 1024],\n",
    "#     'num_layers': [2, 3, 4],  # Por exemplo, entre 2 e 4 camadas\n",
    "#     'max_neurons': 1024,  # Número máximo de neurônios em uma camada\n",
    "#     # 'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
    "#     'dropout_rate': [0], # sem dropout para ajustas após a escolha dos melhores parâmetros\n",
    "#     'activation_type': ['relu', 'leaky_relu'],\n",
    "#     # 'activation_type': ['relu'],\n",
    "#     'normalization_type': ['none']  # 'none' indica sem normalização\n",
    "#     # 'normalization_type': ['none'] # deixar o ajuste de normalização para diminuir overfitting após a escolha dos melhores parâmetros\n",
    "\n",
    "# }\n",
    "\n",
    "# # Random Search\n",
    "# n_iterations = 50\n",
    "# best_loss = float('inf')\n",
    "# best_params = None\n",
    "# input_size = X_train.shape[1]\n",
    "# criterion = nn.BCELoss().to(device)\n",
    "\n",
    "# # Divisão dos dados de treinamento e validação\n",
    "# X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Gera uma lista de números de neurônios aleatórios e depois ordena em ordem decrescente\n",
    "# # Em geral, redes com uma ordem decrescente de neurônios (mais neurônios nas primeiras camadas e menos nas últimas) são comuns, pois isso pode ajudar a rede a capturar progressivamente características mais abstratas dos dados\n",
    "# def generate_neuron_configuration(num_layers, max_neurons):\n",
    "#     neuron_counts = np.random.randint(100, max_neurons, size=num_layers)\n",
    "#     neuron_counts.sort()  # Ordena em ordem crescente\n",
    "#     return tuple(neuron_counts[::-1])  # Inverte para ordem decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_iterations):\n",
    "#     # Escolha aleatória dos hiperparâmetros\n",
    "#     lr = np.random.choice(param_grid['learning_rate'])\n",
    "#     batch_size = np.random.choice(param_grid['batch_size'])\n",
    "#     num_layers = np.random.choice(param_grid['num_layers'])\n",
    "#     neurons = generate_neuron_configuration(num_layers, param_grid['max_neurons'])\n",
    "#     dropout_rate = np.random.choice(param_grid['dropout_rate'])\n",
    "#     activation_type = np.random.choice(param_grid['activation_type'])\n",
    "#     normalization_type = np.random.choice(param_grid['normalization_type'])\n",
    "\n",
    "\n",
    "#     print(f\"Iteração {i} LR={lr}, batch_size={batch_size}, num_layers={num_layers}, neurons: {neurons}  dropout_rate: {dropout_rate}  activation_type: {activation_type} normalization_type: {normalization_type}\")\n",
    "\n",
    "#     train_dataset = CustomDataset(X_train_new.tolist(), y_train_new.tolist())\n",
    "#     val_dataset = CustomDataset(X_val.tolist(), y_val.tolist())\n",
    "\n",
    "#     train_loader = DataLoader(dataset=train_dataset, batch_size=int(batch_size), shuffle=True)\n",
    "#     val_loader = DataLoader(dataset=val_dataset, batch_size=int(batch_size))\n",
    "\n",
    "#     # Criar modelo, otimizador e dataloaders\n",
    "#     model = NeuralNetwork(input_size, neurons, dropout_rate, activation_type, normalization_type).to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     train_loader = DataLoader(dataset=train_dataset, batch_size=int(batch_size), shuffle=True)\n",
    "#     val_loader = DataLoader(dataset=val_dataset, batch_size=int(batch_size))\n",
    "\n",
    "#     # Treinar e avaliar\n",
    "#     val_loss = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader)\n",
    "\n",
    "#     # Checar se é o melhor modelo\n",
    "#     if val_loss < best_loss:\n",
    "#         best_loss = val_loss\n",
    "#         best_params = (lr, batch_size, num_layers, neurons, dropout_rate, activation_type, normalization_type)\n",
    "\n",
    "#     print(f'Melhor Perda de Validação: {best_loss}')\n",
    "#     print(f'Melhores Hiperparâmetros: LR={best_params[0]}, batch_size={best_params[1]}, num_layers={best_params[2]}, neurons: {best_params[3]}  dropout_rate: {best_params[4]}  activation_type: {best_params[5]} normalization_type: {best_params[6]}')\n",
    "\n",
    "# print(f'Melhor Perda de Validação: {best_loss}')\n",
    "# print(f'Melhores Hiperparâmetros: LR={best_params[0]}, batch_size={best_params[1]}, num_layers={best_params[2]}, neurons: {best_params[3]}  dropout_rate: {best_params[4]}  activation_type: {best_params[5]} normalization_type: {best_params[6]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xht = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id']).head(1699).tail(1)\n",
    "# Xht = preprocessor.transform(Xht)\n",
    "# yht = df['result'].head(1699).tail(1)\n",
    "# yht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jogos = []\n",
    "# Xht = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id']).head(1699).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jogos.append(Xht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(df_jogos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Preparar dados de entrada\n",
    "# # Suponha que 'novo_dado' seja o seu novo dado de entrada que você quer prever\n",
    "# # Deve ser processado da mesma forma que os dados de treinamento foram processados\n",
    "# # novo_dado = torch.tensor(novo_dado, dtype=torch.float32)\n",
    "# novo_dado = torch.tensor(Xht, dtype=torch.float32)\n",
    "\n",
    "# # 4. Fazer previsões\n",
    "# with torch.no_grad():\n",
    "#     previsao = model(novo_dado)\n",
    "# previsao[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsao[0][0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# # carregar o modelo\n",
    "# model = joblib.load('../models/modelo_mlp.pkl')\n",
    "# # Fazendo as predições no conjunto de teste\n",
    "# predictions = model.predict(Xht)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1953/1953 [==============================] - 41s 20ms/step - loss: 0.8608 - accuracy: 0.5231 - recall: 0.5232 - precision: 0.5230 - auc: 0.5320 - val_loss: 0.6772 - val_accuracy: 0.5664 - val_recall: 0.5026 - val_precision: 0.5763 - val_auc: 0.6012 - lr: 1.0000e-04\n",
      "Epoch 2/400\n",
      "1953/1953 [==============================] - 39s 20ms/step - loss: 0.7403 - accuracy: 0.5393 - recall: 0.5424 - precision: 0.5390 - auc: 0.5549 - val_loss: 0.6688 - val_accuracy: 0.5838 - val_recall: 0.6309 - val_precision: 0.5768 - val_auc: 0.6185 - lr: 1.0000e-04\n",
      "Epoch 3/400\n",
      "1953/1953 [==============================] - 36s 19ms/step - loss: 0.6986 - accuracy: 0.5517 - recall: 0.5653 - precision: 0.5503 - auc: 0.5742 - val_loss: 0.6670 - val_accuracy: 0.5905 - val_recall: 0.6273 - val_precision: 0.5845 - val_auc: 0.6255 - lr: 1.0000e-04\n",
      "Epoch 4/400\n",
      "1953/1953 [==============================] - 37s 19ms/step - loss: 0.6813 - accuracy: 0.5665 - recall: 0.5907 - precision: 0.5634 - auc: 0.5934 - val_loss: 0.6652 - val_accuracy: 0.5885 - val_recall: 0.6348 - val_precision: 0.5812 - val_auc: 0.6276 - lr: 1.0000e-04\n",
      "Epoch 5/400\n",
      "1953/1953 [==============================] - 45s 23ms/step - loss: 0.6740 - accuracy: 0.5749 - recall: 0.6047 - precision: 0.5707 - auc: 0.6070 - val_loss: 0.6634 - val_accuracy: 0.5933 - val_recall: 0.6387 - val_precision: 0.5857 - val_auc: 0.6318 - lr: 1.0000e-04\n",
      "Epoch 6/400\n",
      "1953/1953 [==============================] - 47s 24ms/step - loss: 0.6701 - accuracy: 0.5820 - recall: 0.6241 - precision: 0.5756 - auc: 0.6161 - val_loss: 0.6610 - val_accuracy: 0.5955 - val_recall: 0.6914 - val_precision: 0.5803 - val_auc: 0.6359 - lr: 1.0000e-04\n",
      "Epoch 7/400\n",
      "1953/1953 [==============================] - 49s 25ms/step - loss: 0.6671 - accuracy: 0.5852 - recall: 0.6316 - precision: 0.5779 - auc: 0.6233 - val_loss: 0.6603 - val_accuracy: 0.5981 - val_recall: 0.6758 - val_precision: 0.5850 - val_auc: 0.6386 - lr: 1.0000e-04\n",
      "Epoch 8/400\n",
      "1953/1953 [==============================] - 48s 24ms/step - loss: 0.6643 - accuracy: 0.5898 - recall: 0.6384 - precision: 0.5818 - auc: 0.6288 - val_loss: 0.6574 - val_accuracy: 0.5996 - val_recall: 0.6965 - val_precision: 0.5836 - val_auc: 0.6436 - lr: 1.0000e-04\n",
      "Epoch 9/400\n",
      "1953/1953 [==============================] - 47s 24ms/step - loss: 0.6615 - accuracy: 0.5949 - recall: 0.6443 - precision: 0.5863 - auc: 0.6349 - val_loss: 0.6561 - val_accuracy: 0.6013 - val_recall: 0.6983 - val_precision: 0.5850 - val_auc: 0.6465 - lr: 1.0000e-04\n",
      "Epoch 10/400\n",
      "1953/1953 [==============================] - 44s 22ms/step - loss: 0.6597 - accuracy: 0.5988 - recall: 0.6514 - precision: 0.5893 - auc: 0.6393 - val_loss: 0.6546 - val_accuracy: 0.6051 - val_recall: 0.6836 - val_precision: 0.5910 - val_auc: 0.6499 - lr: 1.0000e-04\n",
      "Epoch 11/400\n",
      "1543/1953 [======================>.......] - ETA: 8s - loss: 0.6577 - accuracy: 0.6010 - recall: 0.6550 - precision: 0.5913 - auc: 0.6432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Iniciando o treinamento\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fazendo as predições no conjunto de teste\u001b[39;00m\n\u001b[0;32m     45\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, LayerNormalization, Activation, BatchNormalization, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2, l1_l2\n",
    "import tensorflow as tf  # Import the l2 regularizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1280, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(640, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(320, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Ajustando o otimizador\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', tf.metrics.Recall(), tf.metrics.Precision(), tf.metrics.AUC()])\n",
    "\n",
    "# Ajustando os callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "# Iniciando o treinamento\n",
    "history = model.fit(X_train, y_train, epochs=400, batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stop, reduce_lr], verbose=1)\n",
    "\n",
    "\n",
    "# Fazendo as predições no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# avaliando o modelo com os dados de treino\n",
    "loss, accuracy, recall, precision, auc = model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "# Imprimindo as métricas de treino\n",
    "print(f'Treino de perda: {loss}')\n",
    "print(f'Treino de acurácia: {accuracy}')\n",
    "print(f'Treino de recall: {recall}')\n",
    "print(f'Treino de precisão: {precision}')\n",
    "print(f'Treino de AUC: {auc}')\n",
    "\n",
    "# avaliando o modelo com os dados de teste\n",
    "loss, accuracy, recall, precision, auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimindo as métricas de teste\n",
    "print(f'Teste de perda: {loss}')\n",
    "print(f'Teste de acurácia: {accuracy}')\n",
    "print(f'Teste de recall: {recall}')\n",
    "print(f'Teste de precisão: {precision}')\n",
    "print(f'Teste de AUC: {auc}')\n",
    "\n",
    "\n",
    "\n",
    "# Gerando predições com o conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)  # Converter para 0s e 1s\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.show()\n",
    "\n",
    "# Gerando o relatório de classificação\n",
    "report = classification_report(y_test, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n",
    "\n",
    "# Plotando a curva de aprendizado\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Curva de Aprendizado do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Validação'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Salvando o modelo\n",
    "model.save('../models/model_redeht.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 05m 28s]\n",
      "val_accuracy: 0.6181989312171936\n",
      "\n",
      "Best val_accuracy So Far: 0.7631000876426697\n",
      "Total elapsed time: 00h 51m 23s\n"
     ]
    }
   ],
   "source": [
    "# from keras import regularizers\n",
    "\n",
    "# from kerastuner import HyperModel, RandomSearch\n",
    "\n",
    "# class MyHyperModel(HyperModel):\n",
    "#     def __init__(self, input_shape):\n",
    "#         self.input_shape = input_shape\n",
    "\n",
    "#     def build(self, hp):\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(units=hp.Int('units', min_value=512, max_value=2048, step=512),\n",
    "#                         activation='relu', input_shape=self.input_shape,\n",
    "#                         kernel_regularizer=regularizers.l2(hp.Float('l2', 1e-5, 1e-2, sampling='log'))))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(hp.Float('dropout', 0.3, 0.5, step=0.1)))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "#         model.compile(optimizer=Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy', tf.metrics.Recall(), tf.metrics.Precision(), tf.metrics.AUC()])\n",
    "#         return model\n",
    "\n",
    "# hypermodel = MyHyperModel(input_shape=(X_train.shape[1],))\n",
    "\n",
    "# tuner = RandomSearch(\n",
    "#     hypermodel,\n",
    "#     objective='val_accuracy',  # ou 'val_loss', 'val_accuracy', etc.\n",
    "#     max_trials=10,\n",
    "#     executions_per_trial=1,\n",
    "#     directory='my_dir',\n",
    "#     project_name='hparam_tuning'\n",
    "# )\n",
    "\n",
    "# tuner.search(X_train, y_train,\n",
    "#              epochs=50,\n",
    "#              validation_split=0.2,\n",
    "#              callbacks=[reduce_lr, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 1024 and the optimal learning rate for the optimizer\n",
      "is 0.0002472161416221352. The optimal dropout rate is 0.3 and the optimal l2 regularization is 3.1323535509142155e-05.\n",
      "\n",
      "\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.5319 - accuracy: 0.7612 - recall: 0.8155 - precision: 0.7356 - auc: 0.8344\n",
      "Loss: 0.5318855047225952, Accuracy: 0.7612209916114807, Recall: 0.8155437111854553, Precision: 0.7356217503547668, AUC: 0.8344180583953857\n"
     ]
    }
   ],
   "source": [
    "# # Obter o melhor conjunto de hiperparâmetros\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# # Você pode acessar os hiperparâmetros diretamente pelo nome\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}. The optimal dropout rate is {best_hps.get('dropout')} and the optimal l2 regularization is {best_hps.get('l2')}.\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# # Obter o melhor modelo\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# # Avaliar o melhor modelo\n",
    "# loss, accuracy, recall, precision, auc = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# print(f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 1s 852us/step\n",
      "Teste de perda: 0.5318855047225952\n",
      "Teste de acurácia: 0.7612209916114807\n",
      "Teste de recall: 0.8155437111854553\n",
      "Teste de precisão: 0.7356217503547668\n",
      "Teste de AUC: 0.8344180583953857\n",
      "623/623 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.93      0.89      0.91      9959\n",
      "    Classe 1       0.90      0.93      0.92      9959\n",
      "\n",
      "    accuracy                           0.91     19918\n",
      "   macro avg       0.92      0.91      0.91     19918\n",
      "weighted avg       0.92      0.91      0.91     19918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = best_model.predict(X_test)\n",
    "# predictions = np.where(predictions > 0.5, 1, 0).flatten()  # Converter para 0s e 1s e achatar o array\n",
    "\n",
    "# # Imprimindo as métricas de teste\n",
    "# print(f'Teste de perda: {loss}')\n",
    "# print(f'Teste de acurácia: {accuracy}')\n",
    "# print(f'Teste de recall: {recall}')\n",
    "# print(f'Teste de precisão: {precision}')\n",
    "# print(f'Teste de AUC: {auc}')\n",
    "\n",
    "# # Gerando predições com o conjunto de teste\n",
    "# predictions = model.predict(X_test)\n",
    "# predictions = (predictions > 0.5).astype(int)  # Converter para 0s e 1s\n",
    "\n",
    "# # Matriz de confusão\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "# plt.title('Matriz de Confusão')\n",
    "# plt.ylabel('Verdadeiros')\n",
    "# plt.xlabel('Predições')\n",
    "# plt.show()\n",
    "\n",
    "# # Gerando o relatório de classificação\n",
    "# report = classification_report(y_test, predictions, target_names=['Classe 0', 'Classe 1'])\n",
    "\n",
    "# # Imprimindo o relatório de classificação\n",
    "# print(\"Relatório de Classificação:\")\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva de Aprendizado: A curva de aprendizado mostra que a acurácia de validação e treinamento estão se aproximando uma da outra conforme o número de épocas aumenta, o que é um bom sinal de que o modelo não está sofrendo de overfitting significativo.\n",
    "\n",
    "Acurácia e AUC: A acurácia e a Área Sob a Curva ROC (AUC) no conjunto de teste são bastante altas, o que sugere que o modelo tem um bom desempenho geral.\n",
    "\n",
    "Recall e Precision: Os valores de recall e precisão são bastante equilibrados para as previsões no conjunto de validação, indicando que o modelo tem um desempenho bom e equilibrado em relação a ambas as classes.\n",
    "\n",
    "Relatório de Classificação: O relatório de classificação mostra resultados quase simétricos para as classes 0 e 1, com uma precisão, recall e pontuação F1 bastante semelhantes para ambas, o que sugere que o modelo está tratando ambas as classes de forma equitativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 2s 3ms/step\n",
      "Threshold: 0.10, Precision: 0.787, Recall: 0.982, F1 Score: 0.874, Accuracy: 0.858\n",
      "Threshold: 0.11, Precision: 0.793, Recall: 0.981, F1 Score: 0.877, Accuracy: 0.862\n",
      "Threshold: 0.12, Precision: 0.798, Recall: 0.979, F1 Score: 0.879, Accuracy: 0.866\n",
      "Threshold: 0.13, Precision: 0.803, Recall: 0.978, F1 Score: 0.882, Accuracy: 0.869\n",
      "Threshold: 0.14, Precision: 0.807, Recall: 0.977, F1 Score: 0.884, Accuracy: 0.872\n",
      "Threshold: 0.15, Precision: 0.811, Recall: 0.976, F1 Score: 0.886, Accuracy: 0.874\n",
      "Threshold: 0.16, Precision: 0.815, Recall: 0.975, F1 Score: 0.888, Accuracy: 0.877\n",
      "Threshold: 0.17, Precision: 0.820, Recall: 0.974, F1 Score: 0.890, Accuracy: 0.880\n",
      "Threshold: 0.18, Precision: 0.824, Recall: 0.972, F1 Score: 0.892, Accuracy: 0.882\n",
      "Threshold: 0.19, Precision: 0.828, Recall: 0.971, F1 Score: 0.894, Accuracy: 0.885\n",
      "Threshold: 0.20, Precision: 0.832, Recall: 0.970, F1 Score: 0.896, Accuracy: 0.887\n",
      "Threshold: 0.21, Precision: 0.836, Recall: 0.968, F1 Score: 0.897, Accuracy: 0.889\n",
      "Threshold: 0.22, Precision: 0.840, Recall: 0.968, F1 Score: 0.899, Accuracy: 0.892\n",
      "Threshold: 0.23, Precision: 0.842, Recall: 0.967, F1 Score: 0.900, Accuracy: 0.893\n",
      "Threshold: 0.24, Precision: 0.844, Recall: 0.966, F1 Score: 0.901, Accuracy: 0.894\n",
      "Threshold: 0.25, Precision: 0.848, Recall: 0.965, F1 Score: 0.902, Accuracy: 0.896\n",
      "Threshold: 0.26, Precision: 0.851, Recall: 0.964, F1 Score: 0.904, Accuracy: 0.897\n",
      "Threshold: 0.27, Precision: 0.853, Recall: 0.963, F1 Score: 0.905, Accuracy: 0.899\n",
      "Threshold: 0.28, Precision: 0.856, Recall: 0.962, F1 Score: 0.906, Accuracy: 0.900\n",
      "Threshold: 0.29, Precision: 0.858, Recall: 0.961, F1 Score: 0.907, Accuracy: 0.901\n",
      "Threshold: 0.30, Precision: 0.861, Recall: 0.960, F1 Score: 0.908, Accuracy: 0.902\n",
      "Threshold: 0.31, Precision: 0.864, Recall: 0.958, F1 Score: 0.909, Accuracy: 0.904\n",
      "Threshold: 0.32, Precision: 0.865, Recall: 0.957, F1 Score: 0.909, Accuracy: 0.904\n",
      "Threshold: 0.33, Precision: 0.868, Recall: 0.957, F1 Score: 0.910, Accuracy: 0.905\n",
      "Threshold: 0.34, Precision: 0.870, Recall: 0.955, F1 Score: 0.911, Accuracy: 0.906\n",
      "Threshold: 0.35, Precision: 0.873, Recall: 0.954, F1 Score: 0.911, Accuracy: 0.907\n",
      "Threshold: 0.36, Precision: 0.875, Recall: 0.953, F1 Score: 0.912, Accuracy: 0.908\n",
      "Threshold: 0.37, Precision: 0.878, Recall: 0.951, F1 Score: 0.913, Accuracy: 0.909\n",
      "Threshold: 0.38, Precision: 0.879, Recall: 0.949, F1 Score: 0.913, Accuracy: 0.909\n",
      "Threshold: 0.39, Precision: 0.881, Recall: 0.948, F1 Score: 0.914, Accuracy: 0.910\n",
      "Threshold: 0.40, Precision: 0.883, Recall: 0.947, F1 Score: 0.914, Accuracy: 0.911\n",
      "Threshold: 0.41, Precision: 0.885, Recall: 0.946, F1 Score: 0.915, Accuracy: 0.912\n",
      "Threshold: 0.42, Precision: 0.886, Recall: 0.944, F1 Score: 0.914, Accuracy: 0.912\n",
      "Threshold: 0.43, Precision: 0.888, Recall: 0.943, F1 Score: 0.915, Accuracy: 0.912\n",
      "Threshold: 0.44, Precision: 0.890, Recall: 0.942, F1 Score: 0.915, Accuracy: 0.913\n",
      "Threshold: 0.45, Precision: 0.892, Recall: 0.941, F1 Score: 0.916, Accuracy: 0.913\n",
      "Threshold: 0.46, Precision: 0.893, Recall: 0.939, F1 Score: 0.915, Accuracy: 0.913\n",
      "Threshold: 0.47, Precision: 0.894, Recall: 0.939, F1 Score: 0.916, Accuracy: 0.913\n",
      "Threshold: 0.48, Precision: 0.896, Recall: 0.938, F1 Score: 0.916, Accuracy: 0.914\n",
      "Threshold: 0.49, Precision: 0.897, Recall: 0.936, F1 Score: 0.916, Accuracy: 0.914\n",
      "Threshold: 0.50, Precision: 0.899, Recall: 0.935, F1 Score: 0.916, Accuracy: 0.914\n",
      "Threshold: 0.51, Precision: 0.900, Recall: 0.933, F1 Score: 0.916, Accuracy: 0.915\n",
      "Threshold: 0.52, Precision: 0.902, Recall: 0.932, F1 Score: 0.917, Accuracy: 0.915\n",
      "Threshold: 0.53, Precision: 0.903, Recall: 0.930, F1 Score: 0.916, Accuracy: 0.915\n",
      "Threshold: 0.54, Precision: 0.904, Recall: 0.929, F1 Score: 0.917, Accuracy: 0.915\n",
      "Threshold: 0.55, Precision: 0.906, Recall: 0.928, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.56, Precision: 0.907, Recall: 0.927, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.57, Precision: 0.908, Recall: 0.925, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.58, Precision: 0.910, Recall: 0.924, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.59, Precision: 0.911, Recall: 0.922, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.60, Precision: 0.913, Recall: 0.920, F1 Score: 0.917, Accuracy: 0.916\n",
      "Threshold: 0.61, Precision: 0.914, Recall: 0.919, F1 Score: 0.916, Accuracy: 0.916\n",
      "Threshold: 0.62, Precision: 0.915, Recall: 0.917, F1 Score: 0.916, Accuracy: 0.916\n",
      "Threshold: 0.63, Precision: 0.916, Recall: 0.915, F1 Score: 0.915, Accuracy: 0.916\n",
      "Threshold: 0.64, Precision: 0.918, Recall: 0.913, F1 Score: 0.915, Accuracy: 0.916\n",
      "Threshold: 0.65, Precision: 0.919, Recall: 0.911, F1 Score: 0.915, Accuracy: 0.915\n",
      "Threshold: 0.66, Precision: 0.921, Recall: 0.909, F1 Score: 0.915, Accuracy: 0.915\n",
      "Threshold: 0.67, Precision: 0.922, Recall: 0.906, F1 Score: 0.914, Accuracy: 0.915\n",
      "Threshold: 0.68, Precision: 0.924, Recall: 0.905, F1 Score: 0.914, Accuracy: 0.915\n",
      "Threshold: 0.69, Precision: 0.925, Recall: 0.903, F1 Score: 0.914, Accuracy: 0.915\n",
      "Threshold: 0.70, Precision: 0.927, Recall: 0.900, F1 Score: 0.913, Accuracy: 0.914\n",
      "Threshold: 0.71, Precision: 0.928, Recall: 0.897, F1 Score: 0.912, Accuracy: 0.914\n",
      "Threshold: 0.72, Precision: 0.929, Recall: 0.896, F1 Score: 0.912, Accuracy: 0.914\n",
      "Threshold: 0.73, Precision: 0.930, Recall: 0.894, F1 Score: 0.912, Accuracy: 0.913\n",
      "Threshold: 0.74, Precision: 0.932, Recall: 0.892, F1 Score: 0.912, Accuracy: 0.913\n",
      "Threshold: 0.75, Precision: 0.933, Recall: 0.890, F1 Score: 0.911, Accuracy: 0.913\n",
      "Threshold: 0.76, Precision: 0.934, Recall: 0.887, F1 Score: 0.910, Accuracy: 0.912\n",
      "Threshold: 0.77, Precision: 0.935, Recall: 0.885, F1 Score: 0.909, Accuracy: 0.912\n",
      "Threshold: 0.78, Precision: 0.936, Recall: 0.882, F1 Score: 0.908, Accuracy: 0.911\n",
      "Threshold: 0.79, Precision: 0.938, Recall: 0.879, F1 Score: 0.907, Accuracy: 0.910\n",
      "Threshold: 0.80, Precision: 0.939, Recall: 0.876, F1 Score: 0.906, Accuracy: 0.909\n",
      "Threshold: 0.81, Precision: 0.940, Recall: 0.873, F1 Score: 0.905, Accuracy: 0.909\n",
      "Threshold: 0.82, Precision: 0.941, Recall: 0.870, F1 Score: 0.904, Accuracy: 0.908\n",
      "Threshold: 0.83, Precision: 0.942, Recall: 0.866, F1 Score: 0.903, Accuracy: 0.907\n",
      "Threshold: 0.84, Precision: 0.944, Recall: 0.861, F1 Score: 0.900, Accuracy: 0.905\n",
      "Threshold: 0.85, Precision: 0.945, Recall: 0.856, F1 Score: 0.898, Accuracy: 0.903\n",
      "Threshold: 0.86, Precision: 0.947, Recall: 0.851, F1 Score: 0.896, Accuracy: 0.902\n",
      "Threshold: 0.87, Precision: 0.948, Recall: 0.846, F1 Score: 0.894, Accuracy: 0.900\n",
      "Threshold: 0.88, Precision: 0.949, Recall: 0.838, F1 Score: 0.890, Accuracy: 0.897\n",
      "Threshold: 0.89, Precision: 0.950, Recall: 0.832, F1 Score: 0.887, Accuracy: 0.894\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # Carregar o modelo\n",
    "# model = load_model('../models/model_redeht.h5')\n",
    "\n",
    "# # Prever as probabilidades para o conjunto de teste\n",
    "# y_probs = model.predict(X_test)\n",
    "\n",
    "# # Inicialize o valor do threshold que você quer testar\n",
    "# thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# # Para cada threshold, calcule e imprima as métricas\n",
    "# for thresh in thresholds:\n",
    "#     # Converta probabilidades em previsões binárias com base no threshold\n",
    "#     y_pred = (y_probs >= thresh).astype(int)\n",
    "    \n",
    "#     # Calcule as métricas para a classe 1\n",
    "#     precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "#     recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "#     f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     # Imprima as métricas\n",
    "#     print(f'Threshold: {thresh:.2f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# # Escolha o threshold que oferece o melhor equilíbrio entre as métricas que são importantes para o seu caso de uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando características importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('../models/model_redeht_final.h5')\n",
    "\n",
    "# import shap\n",
    "# # Criando o explainer\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # Subconjunto do conjunto de teste para análise\n",
    "# X_test_sample = X_test[:200]  # Ajuste o tamanho da amostra conforme necessário\n",
    "\n",
    "# # Calculando os valores SHAP\n",
    "# shap_values = explainer.shap_values(X_test_sample)\n",
    "# # Plotando um gráfico de resumo\n",
    "# # shap.summary_plot(shap_values, X_test_sample)\n",
    "\n",
    "# # Obter os nomes das colunas numéricas\n",
    "# numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# # Obter os nomes das colunas após a transformação\n",
    "# # Para as características numéricas, permanecem os mesmos\n",
    "# transformed_numeric_features = numeric_features\n",
    "\n",
    "# # Como só tem uma característica categórica:\n",
    "# categories = preprocessor.named_transformers_['cat'].categories_\n",
    "# transformed_categorical_features = [\n",
    "#     f'league_{category}' for category in categories[0][1:]  # drop='first' remove a primeira categoria\n",
    "# ]\n",
    "\n",
    "# # Combina os dois\n",
    "# all_transformed_features = transformed_numeric_features + transformed_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando um gráfico de resumo com nomes de features reais\n",
    "# shap.summary_plot(shap_values, features=X_test_sample, feature_names=all_transformed_features, max_display=X_test_sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
