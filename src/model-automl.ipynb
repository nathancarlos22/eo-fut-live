{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e carregamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import h2o\n",
    "# from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_live_engineer_filtered.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "0    41361\n",
       "1    41361\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['minute', 'homeTeam', 'awayTeam', 'goal_home', 'goal_away',\n",
       "       'shots_home', 'shots_away', 'league', 'corners_home', 'corners_away',\n",
       "       'shotsOffgoal_home', 'shotsOffgoal_away', 'fouls_home', 'fouls_away',\n",
       "       'tackles_home', 'tackles_away', 'result', 'match_id',\n",
       "       'possessiontime_away', 'possessiontime_home', 'f_attack_home',\n",
       "       'f_defensive_away', 'f_defensive_home', 'f_attack_away',\n",
       "       'win_rate_home', 'loss_rate_home', 'draw_rate_home', 'win_rate_away',\n",
       "       'loss_rate_away', 'draw_rate_away', 'shotAccuracy_home',\n",
       "       'shotAccuracy_away', 'attackPressureOverTime_home',\n",
       "       'attackPressureOverTime_away', 'aggrressionOverTime_home',\n",
       "       'aggresssionOverTime_away', 'defensiveEfficacy_home',\n",
       "       'defensiveEfficacy_away', 'taklesOverTime_home', 'taklesOverTime_away',\n",
       "       'possessionControl', 'passRisk_home', 'passRisk_away', '05ht_home',\n",
       "       '05ft_home', '05_home', '05ht_away', '05ft_away', '05_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rapidfuzz import fuzz\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# Função para calcular a similaridade (usando RapidFuzz)\n",
    "# def calculate_similarity_fast(vector, reference):\n",
    "#     return np.array([fuzz.ratio(reference, x) for x in vector])\n",
    "\n",
    "# # String de referência\n",
    "# string_referencia = \"Corinthians\"\n",
    "\n",
    "# # Aplicando a função otimizada\n",
    "# df['similaridade'] = calculate_similarity_fast(df['homeTeam'], string_referencia)\n",
    "\n",
    "# # Encontrando a string com a maior similaridade\n",
    "# string_mais_similar = df.loc[df['similaridade'].idxmax()]\n",
    "\n",
    "# print(string_mais_similar['homeTeam'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    return preprocessor.fit(X)\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "pickle.dump(preprocessor, open('../models/preprocessor.pickle', 'wb'))\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \n",
      "                                                                                \n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "                                                                                \n",
      "                                                                                \n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "                                                                                \n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=3, p=1, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Inicializando TPOT\n",
    "tpot = TPOTClassifier(n_jobs=2, generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Salvando o pipeline otimizado\n",
    "# tpot.export('tpot_exported_pipeline.py')\n",
    "\n",
    "# Salvar o modelo TPOT\n",
    "with open('../models/tpot_model.pkl', 'wb') as file:\n",
    "    pickle.dump(tpot.fitted_pipeline_, file)\n",
    "\n",
    "# Avaliação do Modelo\n",
    "y_pred_prob = tpot.predict_proba(X_test)[:, 1]  # pegar as probabilidades da classe 1\n",
    "y_pred = tpot.predict(X_test)\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Visualizar a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizar a matriz de confusão\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import GridSearchCV\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# # num_negatives = 96859  # Soma da coluna da Classe 0\n",
    "# # num_positives = 31602  # Soma da coluna da Classe 1\n",
    "# num_negatives = 107844  # Soma da coluna da Classe 0\n",
    "# num_positives = 35645  # Soma da coluna da Classe 1\n",
    "\n",
    "# scale_pos_weight = num_negatives / num_positives\n",
    "\n",
    "# xgb_model = XGBClassifier(learning_rate=1.0, \n",
    "#                           max_depth=10, \n",
    "#                           min_child_weight=7, \n",
    "#                           n_estimators=200, \n",
    "#                           n_jobs=-1, \n",
    "#                           subsample=0.6000000000000001, \n",
    "#                           random_state=42, \n",
    "#                         #   scale_pos_weight=scale_pos_weight\n",
    "                          \n",
    "#                           )\n",
    "\n",
    "# # Treinar o modelo ajustado\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Fazer previsões\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# # Avaliar o modelo\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar modelo xgboost\n",
    "# with open('../models/tpot_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(xgb_model, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "# y_pred_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Curva ROC\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Visualizando a curva ROC\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# Matriz de Confusão\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizando a matriz de confusão\n",
    "# plt.figure(figsize=(7, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.show()\n",
    "\n",
    "# Relatório de Classificação\n",
    "# print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Inicializando o modelo XGBClassifier\n",
    "# xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, verbosity=1)\n",
    "\n",
    "# # Definindo os parâmetros para a busca em grade\n",
    "# parameters = {\n",
    "#     'max_depth': [8, 9, 10],\n",
    "#     'learning_rate': [0.1, 0.5, 1],\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "#     'min_child_weight': [1, 5, 10]\n",
    "# }\n",
    "\n",
    "# # Configurando a busca em grade com validação cruzada\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=parameters,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1,\n",
    "#     cv=3,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Executando a busca em grade no conjunto de dados de treino\n",
    "# # X_train, y_train = ...\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Melhores parâmetros e melhor pontuação\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print('Melhores parâmetros:', best_parameters)\n",
    "# print('Melhor pontuação AUC:', best_score)\n",
    "\n",
    "# # Treinar o modelo com os melhores parâmetros encontrados\n",
    "# best_xgb = XGBClassifier(**best_parameters)\n",
    "# best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['result'].head(1699).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_Automl = pickle.load(open('../models/tpot_model.pkl', 'rb'))\n",
    "# model_Automl = pickle.load(open('../models/tpo_model.pkl', 'rb'))\n",
    "\n",
    "# # na prática\n",
    "# Xht = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id']).head(1699).tail(1)\n",
    "# Xht = preprocessor.transform(Xht)\n",
    "# yht = df['result'].head(1699).tail(1)\n",
    "\n",
    "# model_Automl.predict(Xht)[0]  # pegar as probabilidades da classe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_Automl = pickle.load(open('../models/tpot_model.pkl', 'rb'))\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # avaliando treino e teste\n",
    "# y_pred_prob = model_Automl.predict_proba(X_train)[:, 1]  # pegar as probabilidades da classe 1\n",
    "# y_pred = model_Automl.predict(X_train)\n",
    "# print('Acurácia treino:', accuracy_score(y_train, y_pred))\n",
    "\n",
    "# y_pred_prob = model_Automl.predict_proba(X_test)[:, 1]  # pegar as probabilidades da classe 1\n",
    "# y_pred = model_Automl.predict(X_test)\n",
    "# print('Acurácia teste:', accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
