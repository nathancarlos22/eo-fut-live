{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434237, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import h2o\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_balanced.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando características com um modelo geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessamento one hot encode para ligas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados separados em características (X) e variável alvo (y).\n",
      "Preprocessador criado com transformações para características numéricas e categóricas.\n",
      "Preprocessador ajustado aos dados.\n",
      "Preprocessador salvo em '../models/preprocessor.pickle'.\n",
      "Dados transformados pelo preprocessador.\n",
      "Dados divididos em conjuntos de treino e teste.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Função para separar os dados em características e variável alvo\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=['result', 'homeTeam', 'awayTeam', 'match_id'])\n",
    "    y = df['result']\n",
    "    print(\"Dados separados em características (X) e variável alvo (y).\")\n",
    "    return X, y\n",
    "\n",
    "# Função para criar e aplicar o transformador de colunas\n",
    "def create_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    categorical_features = ['league']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Preprocessador criado com transformações para características numéricas e categóricas.\")\n",
    "    return preprocessor.fit(X)\n",
    "\n",
    "# # Preparando os dados\n",
    "X, y = prepare_data(df)\n",
    "preprocessor = create_preprocessor(X)\n",
    "print(\"Preprocessador ajustado aos dados.\")\n",
    "\n",
    "# Salvando o preprocessador para uso futuro\n",
    "with open('../models/preprocessor.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    print(\"Preprocessador salvo em '../models/preprocessor.pickle'.\")\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_transformed = preprocessor.transform(X)\n",
    "print(\"Dados transformados pelo preprocessador.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "print(\"Dados divididos em conjuntos de treino e teste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando modelo geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo geral\n",
      "Média AUC: 0.5546111442010817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Dicionário para armazenar histórico de treinamento e avaliação para cada liga\n",
    "histories = {}\n",
    "\n",
    "# Loop por cada liga para criar, treinar e avaliar um modelo separado\n",
    "print(f\"Treinando modelo geral\")\n",
    "\n",
    "model_randomf = RandomForestClassifier(n_estimators=100, random_state=42, \n",
    "                                        max_depth=10, min_samples_split=5, \n",
    "                                        min_samples_leaf=2)\n",
    "# Validação cruzada\n",
    "cv_scores = cross_val_score(model_randomf, X_transformed, y, cv=5, scoring='roc_auc')\n",
    "print(f\"Média AUC: {cv_scores.mean()}\")\n",
    "\n",
    "# Treinando e avaliando o modelo\n",
    "model_randomf.fit(X_train, y_train)\n",
    "train_auc = roc_auc_score(y_train, model_randomf.predict_proba(X_train)[:, 1])\n",
    "test_auc = roc_auc_score(y_test, model_randomf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "feature_importance = model_randomf.feature_importances_\n",
    "\n",
    "# Armazenando a avaliação em um dicionário\n",
    "histories = {\n",
    "    'cv_auc_mean': cv_scores.mean(),\n",
    "    'train_auc': train_auc,\n",
    "    'test_auc': test_auc,\n",
    "    'feature_importance': feature_importance\n",
    "}\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model_randomf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62      9529\n",
      "         1.0       0.60      0.60      0.60      9015\n",
      "\n",
      "    accuracy                           0.61     18544\n",
      "   macro avg       0.61      0.61      0.61     18544\n",
      "weighted avg       0.61      0.61      0.61     18544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model_randomf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
